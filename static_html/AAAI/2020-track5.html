<!DOCTYPE html>
<html lang="en-US">
<head >
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta name='robots' content='index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1' />
	<style>img:is([sizes="auto" i], [sizes^="auto," i]) { contain-intrinsic-size: 3000px 1500px }</style>
	
	<!-- This site is optimized with the Yoast SEO plugin v23.4 - https://yoast.com/wordpress/plugins/seo/ -->
	<title>Vol. 34 No. 05: AAAI-20 Technical Tracks 5 Archives - AAAI</title>
	<link rel="canonical" href="https://aaai.org/proceeding/vol-34-no-05-aaai-20-technical-tracks-5/" />
	<link rel="next" href="https://aaai.org/proceeding/vol-34-no-05-aaai-20-technical-tracks-5/page/2/" />
	<meta property="og:locale" content="en_US" />
	<meta property="og:type" content="article" />
	<meta property="og:title" content="Vol. 34 No. 05: AAAI-20 Technical Tracks 5 Archives - AAAI" />
	<meta property="og:url" content="https://aaai.org/proceeding/vol-34-no-05-aaai-20-technical-tracks-5/" />
	<meta property="og:site_name" content="AAAI" />
	<meta name="twitter:card" content="summary_large_image" />
	<script type="application/ld+json" class="yoast-schema-graph">{"@context":"https://schema.org","@graph":[{"@type":"CollectionPage","@id":"https://aaai.org/proceeding/vol-34-no-05-aaai-20-technical-tracks-5/","url":"https://aaai.org/proceeding/vol-34-no-05-aaai-20-technical-tracks-5/","name":"Vol. 34 No. 05: AAAI-20 Technical Tracks 5 Archives - AAAI","isPartOf":{"@id":"https://aaai.org/#website"},"breadcrumb":{"@id":"https://aaai.org/proceeding/vol-34-no-05-aaai-20-technical-tracks-5/#breadcrumb"},"inLanguage":"en-US"},{"@type":"BreadcrumbList","@id":"https://aaai.org/proceeding/vol-34-no-05-aaai-20-technical-tracks-5/#breadcrumb","itemListElement":[{"@type":"ListItem","position":1,"name":"Home","item":"https://aaai.org/"},{"@type":"ListItem","position":2,"name":"Papers","item":"https://aaai.org/papers/"},{"@type":"ListItem","position":3,"name":"Proceedings of the AAAI Conference on Artificial Intelligence, 34","item":"https://aaai.org/proceeding/aaai-34-2020/"},{"@type":"ListItem","position":4,"name":"Vol. 34 No. 05: AAAI-20 Technical Tracks 5"}]},{"@type":"WebSite","@id":"https://aaai.org/#website","url":"https://aaai.org/","name":"AAAI","description":"Association for the Advancement of Artificial Intelligence","publisher":{"@id":"https://aaai.org/#organization"},"potentialAction":[{"@type":"SearchAction","target":{"@type":"EntryPoint","urlTemplate":"https://aaai.org/?s={search_term_string}"},"query-input":{"@type":"PropertyValueSpecification","valueRequired":true,"valueName":"search_term_string"}}],"inLanguage":"en-US"},{"@type":"Organization","@id":"https://aaai.org/#organization","name":"AAAI","url":"https://aaai.org/","logo":{"@type":"ImageObject","inLanguage":"en-US","@id":"https://aaai.org/#/schema/logo/image/","url":"https://aaai.org/wp-content/uploads/2023/02/aaai-logo-RGB.jpg","contentUrl":"https://aaai.org/wp-content/uploads/2023/02/aaai-logo-RGB.jpg","width":1051,"height":750,"caption":"AAAI"},"image":{"@id":"https://aaai.org/#/schema/logo/image/"}}]}</script>
	<!-- / Yoast SEO plugin. -->


<link rel='dns-prefetch' href='//fonts.googleapis.com' />
<link href='https://fonts.gstatic.com' crossorigin rel='preconnect' />
<link rel="alternate" type="application/rss+xml" title="AAAI &raquo; Feed" href="https://aaai.org/feed/" />
<link rel="alternate" type="application/rss+xml" title="AAAI &raquo; Comments Feed" href="https://aaai.org/comments/feed/" />
<link rel="alternate" type="application/rss+xml" title="AAAI &raquo; Vol. 34 No. 05: AAAI-20 Technical Tracks 5 Proceeding Feed" href="https://aaai.org/proceeding/vol-34-no-05-aaai-20-technical-tracks-5/feed/" />
<script>
window._wpemojiSettings = {"baseUrl":"https:\/\/s.w.org\/images\/core\/emoji\/15.0.3\/72x72\/","ext":".png","svgUrl":"https:\/\/s.w.org\/images\/core\/emoji\/15.0.3\/svg\/","svgExt":".svg","source":{"concatemoji":"https:\/\/aaai.org\/wp-includes\/js\/wp-emoji-release.min.js?ver=6.7.1"}};
/*! This file is auto-generated */
!function(i,n){var o,s,e;function c(e){try{var t={supportTests:e,timestamp:(new Date).valueOf()};sessionStorage.setItem(o,JSON.stringify(t))}catch(e){}}function p(e,t,n){e.clearRect(0,0,e.canvas.width,e.canvas.height),e.fillText(t,0,0);var t=new Uint32Array(e.getImageData(0,0,e.canvas.width,e.canvas.height).data),r=(e.clearRect(0,0,e.canvas.width,e.canvas.height),e.fillText(n,0,0),new Uint32Array(e.getImageData(0,0,e.canvas.width,e.canvas.height).data));return t.every(function(e,t){return e===r[t]})}function u(e,t,n){switch(t){case"flag":return n(e,"\ud83c\udff3\ufe0f\u200d\u26a7\ufe0f","\ud83c\udff3\ufe0f\u200b\u26a7\ufe0f")?!1:!n(e,"\ud83c\uddfa\ud83c\uddf3","\ud83c\uddfa\u200b\ud83c\uddf3")&&!n(e,"\ud83c\udff4\udb40\udc67\udb40\udc62\udb40\udc65\udb40\udc6e\udb40\udc67\udb40\udc7f","\ud83c\udff4\u200b\udb40\udc67\u200b\udb40\udc62\u200b\udb40\udc65\u200b\udb40\udc6e\u200b\udb40\udc67\u200b\udb40\udc7f");case"emoji":return!n(e,"\ud83d\udc26\u200d\u2b1b","\ud83d\udc26\u200b\u2b1b")}return!1}function f(e,t,n){var r="undefined"!=typeof WorkerGlobalScope&&self instanceof WorkerGlobalScope?new OffscreenCanvas(300,150):i.createElement("canvas"),a=r.getContext("2d",{willReadFrequently:!0}),o=(a.textBaseline="top",a.font="600 32px Arial",{});return e.forEach(function(e){o[e]=t(a,e,n)}),o}function t(e){var t=i.createElement("script");t.src=e,t.defer=!0,i.head.appendChild(t)}"undefined"!=typeof Promise&&(o="wpEmojiSettingsSupports",s=["flag","emoji"],n.supports={everything:!0,everythingExceptFlag:!0},e=new Promise(function(e){i.addEventListener("DOMContentLoaded",e,{once:!0})}),new Promise(function(t){var n=function(){try{var e=JSON.parse(sessionStorage.getItem(o));if("object"==typeof e&&"number"==typeof e.timestamp&&(new Date).valueOf()<e.timestamp+604800&&"object"==typeof e.supportTests)return e.supportTests}catch(e){}return null}();if(!n){if("undefined"!=typeof Worker&&"undefined"!=typeof OffscreenCanvas&&"undefined"!=typeof URL&&URL.createObjectURL&&"undefined"!=typeof Blob)try{var e="postMessage("+f.toString()+"("+[JSON.stringify(s),u.toString(),p.toString()].join(",")+"));",r=new Blob([e],{type:"text/javascript"}),a=new Worker(URL.createObjectURL(r),{name:"wpTestEmojiSupports"});return void(a.onmessage=function(e){c(n=e.data),a.terminate(),t(n)})}catch(e){}c(n=f(s,u,p))}t(n)}).then(function(e){for(var t in e)n.supports[t]=e[t],n.supports.everything=n.supports.everything&&n.supports[t],"flag"!==t&&(n.supports.everythingExceptFlag=n.supports.everythingExceptFlag&&n.supports[t]);n.supports.everythingExceptFlag=n.supports.everythingExceptFlag&&!n.supports.flag,n.DOMReady=!1,n.readyCallback=function(){n.DOMReady=!0}}).then(function(){return e}).then(function(){var e;n.supports.everything||(n.readyCallback(),(e=n.source||{}).concatemoji?t(e.concatemoji):e.wpemoji&&e.twemoji&&(t(e.twemoji),t(e.wpemoji)))}))}((window,document),window._wpemojiSettings);
</script>
<link rel='stylesheet' id='genesis-blocks-style-css-css' href='https://aaai.org/wp-content/plugins/genesis-blocks/dist/style-blocks.build.css?ver=1738785529' media='all' />
<link rel='stylesheet' id='aaai-genesis-child-theme-css' href='https://aaai.org/wp-content/themes/genesis-sample/style.css?ver=3.4.1' media='all' />
<style id='aaai-genesis-child-theme-inline-css'>

		.wp-custom-logo .site-container .custom-logo-link {
			aspect-ratio: 180/42.3;
		}
		
		.wp-custom-logo .site-container .title-area {
			max-width: 180px;
		}
		
		.wp-custom-logo .title-area {
			padding-top: 13.85px;
		}
		
</style>
<style id='wp-emoji-styles-inline-css'>

	img.wp-smiley, img.emoji {
		display: inline !important;
		border: none !important;
		box-shadow: none !important;
		height: 1em !important;
		width: 1em !important;
		margin: 0 0.07em !important;
		vertical-align: -0.1em !important;
		background: none !important;
		padding: 0 !important;
	}
</style>
<link rel='stylesheet' id='wp-block-library-css' href='https://aaai.org/wp-includes/css/dist/block-library/style.min.css?ver=6.7.1' media='all' />
<style id='outermost-icon-block-style-inline-css'>
.wp-block-outermost-icon-block{display:flex;line-height:0}.wp-block-outermost-icon-block.has-border-color{border:none}.wp-block-outermost-icon-block .has-icon-color svg,.wp-block-outermost-icon-block.has-icon-color svg{color:currentColor}.wp-block-outermost-icon-block .has-icon-color:not(.has-no-icon-fill-color) svg,.wp-block-outermost-icon-block.has-icon-color:not(.has-no-icon-fill-color) svg{fill:currentColor}.wp-block-outermost-icon-block .icon-container{box-sizing:border-box}.wp-block-outermost-icon-block a,.wp-block-outermost-icon-block svg{height:100%;transition:transform .1s ease-in-out;width:100%}.wp-block-outermost-icon-block a:hover{transform:scale(1.1)}.wp-block-outermost-icon-block svg{transform:rotate(var(--outermost--icon-block--transform-rotate,0deg)) scaleX(var(--outermost--icon-block--transform-scale-x,1)) scaleY(var(--outermost--icon-block--transform-scale-y,1))}.wp-block-outermost-icon-block .rotate-90,.wp-block-outermost-icon-block.rotate-90{--outermost--icon-block--transform-rotate:90deg}.wp-block-outermost-icon-block .rotate-180,.wp-block-outermost-icon-block.rotate-180{--outermost--icon-block--transform-rotate:180deg}.wp-block-outermost-icon-block .rotate-270,.wp-block-outermost-icon-block.rotate-270{--outermost--icon-block--transform-rotate:270deg}.wp-block-outermost-icon-block .flip-horizontal,.wp-block-outermost-icon-block.flip-horizontal{--outermost--icon-block--transform-scale-x:-1}.wp-block-outermost-icon-block .flip-vertical,.wp-block-outermost-icon-block.flip-vertical{--outermost--icon-block--transform-scale-y:-1}.wp-block-outermost-icon-block .flip-vertical.flip-horizontal,.wp-block-outermost-icon-block.flip-vertical.flip-horizontal{--outermost--icon-block--transform-scale-x:-1;--outermost--icon-block--transform-scale-y:-1}

</style>
<style id='classic-theme-styles-inline-css'>
/*! This file is auto-generated */
.wp-block-button__link{color:#fff;background-color:#32373c;border-radius:9999px;box-shadow:none;text-decoration:none;padding:calc(.667em + 2px) calc(1.333em + 2px);font-size:1.125em}.wp-block-file__button{background:#32373c;color:#fff;text-decoration:none}
</style>
<style id='global-styles-inline-css'>
:root{--wp--preset--aspect-ratio--square: 1;--wp--preset--aspect-ratio--4-3: 4/3;--wp--preset--aspect-ratio--3-4: 3/4;--wp--preset--aspect-ratio--3-2: 3/2;--wp--preset--aspect-ratio--2-3: 2/3;--wp--preset--aspect-ratio--16-9: 16/9;--wp--preset--aspect-ratio--9-16: 9/16;--wp--preset--color--black: #000000;--wp--preset--color--cyan-bluish-gray: #abb8c3;--wp--preset--color--white: #ffffff;--wp--preset--color--pale-pink: #f78da7;--wp--preset--color--vivid-red: #cf2e2e;--wp--preset--color--luminous-vivid-orange: #ff6900;--wp--preset--color--luminous-vivid-amber: #fcb900;--wp--preset--color--light-green-cyan: #7bdcb5;--wp--preset--color--vivid-green-cyan: #00d084;--wp--preset--color--pale-cyan-blue: #8ed1fc;--wp--preset--color--vivid-cyan-blue: #0693e3;--wp--preset--color--vivid-purple: #9b51e0;--wp--preset--color--brand-color-0: #001b37;--wp--preset--color--brand-color-1: #0a00c7;--wp--preset--color--brand-color-2: #003973;--wp--preset--color--brand-color-3: #fab31e;--wp--preset--color--brand-color-4: #0a3bff;--wp--preset--color--brand-color-5: #deeeff;--wp--preset--color--brand-color-6: #000000;--wp--preset--color--brand-color-7: #ffffff;--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple: linear-gradient(135deg,rgba(6,147,227,1) 0%,rgb(155,81,224) 100%);--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan: linear-gradient(135deg,rgb(122,220,180) 0%,rgb(0,208,130) 100%);--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange: linear-gradient(135deg,rgba(252,185,0,1) 0%,rgba(255,105,0,1) 100%);--wp--preset--gradient--luminous-vivid-orange-to-vivid-red: linear-gradient(135deg,rgba(255,105,0,1) 0%,rgb(207,46,46) 100%);--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray: linear-gradient(135deg,rgb(238,238,238) 0%,rgb(169,184,195) 100%);--wp--preset--gradient--cool-to-warm-spectrum: linear-gradient(135deg,rgb(74,234,220) 0%,rgb(151,120,209) 20%,rgb(207,42,186) 40%,rgb(238,44,130) 60%,rgb(251,105,98) 80%,rgb(254,248,76) 100%);--wp--preset--gradient--blush-light-purple: linear-gradient(135deg,rgb(255,206,236) 0%,rgb(152,150,240) 100%);--wp--preset--gradient--blush-bordeaux: linear-gradient(135deg,rgb(254,205,165) 0%,rgb(254,45,45) 50%,rgb(107,0,62) 100%);--wp--preset--gradient--luminous-dusk: linear-gradient(135deg,rgb(255,203,112) 0%,rgb(199,81,192) 50%,rgb(65,88,208) 100%);--wp--preset--gradient--pale-ocean: linear-gradient(135deg,rgb(255,245,203) 0%,rgb(182,227,212) 50%,rgb(51,167,181) 100%);--wp--preset--gradient--electric-grass: linear-gradient(135deg,rgb(202,248,128) 0%,rgb(113,206,126) 100%);--wp--preset--gradient--midnight: linear-gradient(135deg,rgb(2,3,129) 0%,rgb(40,116,252) 100%);--wp--preset--font-size--small: 12px;--wp--preset--font-size--medium: 20px;--wp--preset--font-size--large: 20px;--wp--preset--font-size--x-large: 42px;--wp--preset--font-size--normal: 18px;--wp--preset--font-size--larger: 24px;--wp--preset--spacing--20: 0.44rem;--wp--preset--spacing--30: 0.67rem;--wp--preset--spacing--40: 1rem;--wp--preset--spacing--50: 1.5rem;--wp--preset--spacing--60: 2.25rem;--wp--preset--spacing--70: 3.38rem;--wp--preset--spacing--80: 5.06rem;--wp--preset--shadow--natural: 6px 6px 9px rgba(0, 0, 0, 0.2);--wp--preset--shadow--deep: 12px 12px 50px rgba(0, 0, 0, 0.4);--wp--preset--shadow--sharp: 6px 6px 0px rgba(0, 0, 0, 0.2);--wp--preset--shadow--outlined: 6px 6px 0px -3px rgba(255, 255, 255, 1), 6px 6px rgba(0, 0, 0, 1);--wp--preset--shadow--crisp: 6px 6px 0px rgba(0, 0, 0, 1);}:where(.is-layout-flex){gap: 0.5em;}:where(.is-layout-grid){gap: 0.5em;}body .is-layout-flex{display: flex;}.is-layout-flex{flex-wrap: wrap;align-items: center;}.is-layout-flex > :is(*, div){margin: 0;}body .is-layout-grid{display: grid;}.is-layout-grid > :is(*, div){margin: 0;}:where(.wp-block-columns.is-layout-flex){gap: 2em;}:where(.wp-block-columns.is-layout-grid){gap: 2em;}:where(.wp-block-post-template.is-layout-flex){gap: 1.25em;}:where(.wp-block-post-template.is-layout-grid){gap: 1.25em;}.has-black-color{color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-color{color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-color{color: var(--wp--preset--color--white) !important;}.has-pale-pink-color{color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-color{color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-color{color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-color{color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-color{color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-color{color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-color{color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-color{color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-color{color: var(--wp--preset--color--vivid-purple) !important;}.has-black-background-color{background-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-background-color{background-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-background-color{background-color: var(--wp--preset--color--white) !important;}.has-pale-pink-background-color{background-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-background-color{background-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-background-color{background-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-background-color{background-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-background-color{background-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-background-color{background-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-background-color{background-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-background-color{background-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-background-color{background-color: var(--wp--preset--color--vivid-purple) !important;}.has-black-border-color{border-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-border-color{border-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-border-color{border-color: var(--wp--preset--color--white) !important;}.has-pale-pink-border-color{border-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-border-color{border-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-border-color{border-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-border-color{border-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-border-color{border-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-border-color{border-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-border-color{border-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-border-color{border-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-border-color{border-color: var(--wp--preset--color--vivid-purple) !important;}.has-vivid-cyan-blue-to-vivid-purple-gradient-background{background: var(--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple) !important;}.has-light-green-cyan-to-vivid-green-cyan-gradient-background{background: var(--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan) !important;}.has-luminous-vivid-amber-to-luminous-vivid-orange-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange) !important;}.has-luminous-vivid-orange-to-vivid-red-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-orange-to-vivid-red) !important;}.has-very-light-gray-to-cyan-bluish-gray-gradient-background{background: var(--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray) !important;}.has-cool-to-warm-spectrum-gradient-background{background: var(--wp--preset--gradient--cool-to-warm-spectrum) !important;}.has-blush-light-purple-gradient-background{background: var(--wp--preset--gradient--blush-light-purple) !important;}.has-blush-bordeaux-gradient-background{background: var(--wp--preset--gradient--blush-bordeaux) !important;}.has-luminous-dusk-gradient-background{background: var(--wp--preset--gradient--luminous-dusk) !important;}.has-pale-ocean-gradient-background{background: var(--wp--preset--gradient--pale-ocean) !important;}.has-electric-grass-gradient-background{background: var(--wp--preset--gradient--electric-grass) !important;}.has-midnight-gradient-background{background: var(--wp--preset--gradient--midnight) !important;}.has-small-font-size{font-size: var(--wp--preset--font-size--small) !important;}.has-medium-font-size{font-size: var(--wp--preset--font-size--medium) !important;}.has-large-font-size{font-size: var(--wp--preset--font-size--large) !important;}.has-x-large-font-size{font-size: var(--wp--preset--font-size--x-large) !important;}
:where(.wp-block-post-template.is-layout-flex){gap: 1.25em;}:where(.wp-block-post-template.is-layout-grid){gap: 1.25em;}
:where(.wp-block-columns.is-layout-flex){gap: 2em;}:where(.wp-block-columns.is-layout-grid){gap: 2em;}
:root :where(.wp-block-pullquote){font-size: 1.5em;line-height: 1.6;}
</style>
<link rel='stylesheet' id='aaai-css' href='https://aaai.org/wp-content/plugins/aaai/public/css/aaai-public.css?ver=1.0.0' media='all' />
<link rel='stylesheet' id='cookie-law-info-controls-css' href='https://aaai.org/wp-content/plugins/cookie-law-info-controls/public/css/cookie-law-info-controls-public.css?ver=1.0.0' media='all' />
<link rel='stylesheet' id='cookie-law-info-css' href='https://aaai.org/wp-content/plugins/cookie-law-info/legacy/public/css/cookie-law-info-public.css?ver=3.2.6' media='all' />
<link rel='stylesheet' id='cookie-law-info-gdpr-css' href='https://aaai.org/wp-content/plugins/cookie-law-info/legacy/public/css/cookie-law-info-gdpr.css?ver=3.2.6' media='all' />
<link rel='stylesheet' id='dashicons-css' href='https://aaai.org/wp-includes/css/dashicons.min.css?ver=6.7.1' media='all' />
<link rel='stylesheet' id='ub-extension-style-css-css' href='https://aaai.org/wp-content/plugins/ultimate-blocks/src/extensions/style.css?ver=6.7.1' media='all' />
<link rel='stylesheet' id='taxopress-frontend-css-css' href='https://aaai.org/wp-content/plugins/simple-tags/assets/frontend/css/frontend.css?ver=3.25.1' media='all' />
<link rel='stylesheet' id='aaai-genesis-child-theme-fonts-css' href='https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,400i,600,700&#038;display=swap' media='all' />
<link rel='stylesheet' id='shift-styles-css' href='https://aaai.org/wp-content/themes/genesis-sample/shift-styles.css?ver=1.0' media='all' />
<link rel='stylesheet' id='aaai-genesis-child-theme-gutenberg-css' href='https://aaai.org/wp-content/themes/genesis-sample/lib/gutenberg/front-end.css?ver=3.4.1' media='all' />
<style id='aaai-genesis-child-theme-gutenberg-inline-css'>
.gb-block-post-grid .gb-post-grid-items h2 a:hover {
	color: #0073e5;
}

.site-container .wp-block-button .wp-block-button__link {
	background-color: #0073e5;
}

.wp-block-button .wp-block-button__link:not(.has-background),
.wp-block-button .wp-block-button__link:not(.has-background):focus,
.wp-block-button .wp-block-button__link:not(.has-background):hover {
	color: #ffffff;
}

.site-container .wp-block-button.is-style-outline .wp-block-button__link {
	color: #0073e5;
}

.site-container .wp-block-button.is-style-outline .wp-block-button__link:focus,
.site-container .wp-block-button.is-style-outline .wp-block-button__link:hover {
	color: #2396ff;
}		.site-container .has-small-font-size {
			font-size: 12px;
		}		.site-container .has-normal-font-size {
			font-size: 18px;
		}		.site-container .has-large-font-size {
			font-size: 20px;
		}		.site-container .has-larger-font-size {
			font-size: 24px;
		}		.site-container .has-theme-primary-color,
		.site-container .wp-block-button .wp-block-button__link.has-theme-primary-color,
		.site-container .wp-block-button.is-style-outline .wp-block-button__link.has-theme-primary-color {
			color: #0073e5;
		}

		.site-container .has-theme-primary-background-color,
		.site-container .wp-block-button .wp-block-button__link.has-theme-primary-background-color,
		.site-container .wp-block-pullquote.is-style-solid-color.has-theme-primary-background-color {
			background-color: #0073e5;
		}		.site-container .has-theme-secondary-color,
		.site-container .wp-block-button .wp-block-button__link.has-theme-secondary-color,
		.site-container .wp-block-button.is-style-outline .wp-block-button__link.has-theme-secondary-color {
			color: #0073e5;
		}

		.site-container .has-theme-secondary-background-color,
		.site-container .wp-block-button .wp-block-button__link.has-theme-secondary-background-color,
		.site-container .wp-block-pullquote.is-style-solid-color.has-theme-secondary-background-color {
			background-color: #0073e5;
		}
</style>
<link rel='stylesheet' id='simple-social-icons-font-css' href='https://aaai.org/wp-content/plugins/simple-social-icons/css/style.css?ver=3.0.2' media='all' />
<link rel='stylesheet' id='ubermenu-css' href='https://aaai.org/wp-content/plugins/ubermenu/pro/assets/css/ubermenu.min.css?ver=3.7.8' media='all' />
<link rel='stylesheet' id='ubermenu-grey-white-css' href='https://aaai.org/wp-content/plugins/ubermenu/assets/css/skins/blackwhite.css?ver=6.7.1' media='all' />
<link rel='stylesheet' id='ubermenu-font-awesome-all-css' href='https://aaai.org/wp-content/plugins/ubermenu/assets/fontawesome/css/all.min.css?ver=6.7.1' media='all' />
<link rel='stylesheet' id='essential-blocks-frontend-style-css' href='https://aaai.org/wp-content/plugins/essential-blocks/assets/admin/editor/editor.css?ver=e018e5790bb4c227e7ea' media='all' />
<style id='essential-blocks-frontend-style-inline-css'>

            :root {
                --eb-global-primary-color: #101828;
--eb-global-secondary-color: #475467;
--eb-global-tertiary-color: #98A2B3;
--eb-global-text-color: #475467;
--eb-global-heading-color: #1D2939;
--eb-global-link-color: #444CE7;
--eb-global-background-color: #F9FAFB;
--eb-global-button-text-color: #FFFFFF;
--eb-global-button-background-color: #101828;
--eb-gradient-primary-color: linear-gradient(90deg, hsla(259, 84%, 78%, 1) 0%, hsla(206, 67%, 75%, 1) 100%);
--eb-gradient-secondary-color: linear-gradient(90deg, hsla(18, 76%, 85%, 1) 0%, hsla(203, 69%, 84%, 1) 100%);
--eb-gradient-tertiary-color: linear-gradient(90deg, hsla(248, 21%, 15%, 1) 0%, hsla(250, 14%, 61%, 1) 100%);
--eb-gradient-background-color: linear-gradient(90deg, rgb(250, 250, 250) 0%, rgb(233, 233, 233) 49%, rgb(244, 243, 243) 100%);

                --eb-tablet-breakpoint: 1024px;
--eb-mobile-breakpoint: 767px;

            }
            
            
        
</style>
<link rel='stylesheet' id='eb-reusable-block-style-40900-css' href='https://aaai.org/wp-content/uploads/eb-style/reusable-blocks/eb-reusable-40900.min.css?ver=88ac69f978' media='all' />
<script src="https://aaai.org/wp-includes/js/jquery/jquery.min.js?ver=3.7.1" id="jquery-core-js"></script>
<script src="https://aaai.org/wp-includes/js/jquery/jquery-migrate.min.js?ver=3.4.1" id="jquery-migrate-js"></script>
<script id="aaai-js-extra">
var ajax = {"ajaxurl":"https:\/\/aaai.org\/wp-admin\/admin-ajax.php","redirecturl":"https:\/\/aaai.memberclicks.net\/"};
</script>
<script src="https://aaai.org/wp-content/plugins/aaai/public/js/aaai-public.js?ver=1.0.0" id="aaai-js"></script>
<script id="cookie-law-info-js-extra">
var Cli_Data = {"nn_cookie_ids":[],"cookielist":[],"non_necessary_cookies":[],"ccpaEnabled":"","ccpaRegionBased":"","ccpaBarEnabled":"","strictlyEnabled":["necessary","obligatoire"],"ccpaType":"gdpr","js_blocking":"1","custom_integration":"","triggerDomRefresh":"","secure_cookies":""};
var cli_cookiebar_settings = {"animate_speed_hide":"500","animate_speed_show":"500","background":"#FFF","border":"#b1a6a6c2","border_on":"","button_1_button_colour":"#61a229","button_1_button_hover":"#4e8221","button_1_link_colour":"#fff","button_1_as_button":"1","button_1_new_win":"","button_2_button_colour":"#333","button_2_button_hover":"#292929","button_2_link_colour":"#444","button_2_as_button":"","button_2_hidebar":"","button_3_button_colour":"#dedfe0","button_3_button_hover":"#b2b2b3","button_3_link_colour":"#333333","button_3_as_button":"1","button_3_new_win":"","button_4_button_colour":"#dedfe0","button_4_button_hover":"#b2b2b3","button_4_link_colour":"#333333","button_4_as_button":"1","button_7_button_colour":"#61a229","button_7_button_hover":"#4e8221","button_7_link_colour":"#fff","button_7_as_button":"1","button_7_new_win":"","font_family":"inherit","header_fix":"","notify_animate_hide":"1","notify_animate_show":"","notify_div_id":"#cookie-law-info-bar","notify_position_horizontal":"right","notify_position_vertical":"bottom","scroll_close":"","scroll_close_reload":"","accept_close_reload":"","reject_close_reload":"","showagain_tab":"","showagain_background":"#fff","showagain_border":"#000","showagain_div_id":"#cookie-law-info-again","showagain_x_position":"100px","text":"#333333","show_once_yn":"","show_once":"10000","logging_on":"","as_popup":"","popup_overlay":"1","bar_heading_text":"","cookie_bar_as":"banner","popup_showagain_position":"bottom-right","widget_position":"left"};
var log_object = {"ajax_url":"https:\/\/aaai.org\/wp-admin\/admin-ajax.php"};
</script>
<script src="https://aaai.org/wp-content/plugins/cookie-law-info/legacy/public/js/cookie-law-info-public.js?ver=3.2.6" id="cookie-law-info-js"></script>
<script src="https://aaai.org/wp-content/plugins/simple-tags/assets/frontend/js/frontend.js?ver=3.25.1" id="taxopress-frontend-js-js"></script>
<link rel="https://api.w.org/" href="https://aaai.org/wp-json/" /><link rel="EditURI" type="application/rsd+xml" title="RSD" href="https://aaai.org/xmlrpc.php?rsd" />

<script
  src="https://code.jquery.com/jquery-3.6.3.js"
  integrity="sha256-nQLuAZGRRcILA+6dMBOvcRh5Pe310sBpanc6+QBmyVM="
  crossorigin="anonymous"></script>

<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-MBH24FG');</script>
<!-- End Google Tag Manager -->
<link rel="stylesheet" href="https://use.typekit.net/fpw2eej.css">
<meta name="google-site-verification" content="4TD1LphPTynHUMWOfM1ONR8Lwa1UTj-mT7Hj_JM1Grw" />
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-GLhlTQ8iRABdZLl6O3oVMWSktQOp6b7In1Zl3/Jr59b6EGGoI1aFkw7cmDA6j6gD" crossorigin="anonymous">
<style id="ubermenu-custom-generated-css">
/** Font Awesome 4 Compatibility **/
.fa{font-style:normal;font-variant:normal;font-weight:normal;font-family:FontAwesome;}

/** UberMenu Custom Menu Styles (Customizer) **/
/* main */
 .ubermenu-main { background-color:#001b37; background:-webkit-gradient(linear,left top,left bottom,from(#001b37),to(#001b37)); background:-webkit-linear-gradient(top,#001b37,#001b37); background:-moz-linear-gradient(top,#001b37,#001b37); background:-ms-linear-gradient(top,#001b37,#001b37); background:-o-linear-gradient(top,#001b37,#001b37); background:linear-gradient(top,#001b37,#001b37); }
 .ubermenu-main .ubermenu-item-level-0 > .ubermenu-target { font-size:18px; color:#f7f7f7; }
 .ubermenu.ubermenu-main .ubermenu-item-level-0:hover > .ubermenu-target, .ubermenu-main .ubermenu-item-level-0.ubermenu-active > .ubermenu-target { color:#ffffff; background:#003973; }
 .ubermenu.ubermenu-main .ubermenu-item-level-0 > .ubermenu-target { background:#001b37; }
 .ubermenu-main .ubermenu-item-level-0.ubermenu-current-menu-item > .ubermenu-target, .ubermenu-main .ubermenu-item-level-0.ubermenu-current-menu-parent > .ubermenu-target, .ubermenu-main .ubermenu-item-level-0.ubermenu-current-menu-ancestor > .ubermenu-target { background:#003973; }
 .ubermenu-main .ubermenu-item.ubermenu-item-level-0 > .ubermenu-highlight { background:#084481; }
 .ubermenu-main .ubermenu-submenu.ubermenu-submenu-drop { background-color:#003973; border:1px solid #003973; color:#f7f7f7; }
 .ubermenu-main .ubermenu-submenu .ubermenu-highlight { color:#ffffff; }
 .ubermenu-main .ubermenu-submenu .ubermenu-item-header > .ubermenu-target { color:#ffffff; }
 .ubermenu-main .ubermenu-item-normal > .ubermenu-target { color:#f7f7f7; font-size:16px; }
 .ubermenu.ubermenu-main .ubermenu-item-normal > .ubermenu-target:hover, .ubermenu.ubermenu-main .ubermenu-item-normal.ubermenu-active > .ubermenu-target { color:#ffffff; }


/** UberMenu Custom Menu Item Styles (Menu Item Settings) **/
/* 230 */    .ubermenu .ubermenu-item-230 > .ubermenu-target.ubermenu-item-layout-image_left > .ubermenu-target-text { padding-left:50px; }
/* 40060 */  .ubermenu .ubermenu-item-40060 > .ubermenu-target.ubermenu-item-layout-image_left > .ubermenu-target-text { padding-left:50px; }
/* 518 */    .ubermenu .ubermenu-item-518 > .ubermenu-target.ubermenu-item-layout-image_left > .ubermenu-target-text { padding-left:50px; }
/* 19835 */  .ubermenu .ubermenu-item-19835 > .ubermenu-target.ubermenu-item-layout-image_left > .ubermenu-target-text { padding-left:50px; }
/* 61189 */  .ubermenu .ubermenu-item-61189 > .ubermenu-target.ubermenu-item-layout-image_left > .ubermenu-target-text { padding-left:50px; }
/* 39821 */  .ubermenu .ubermenu-item-39821 > .ubermenu-target.ubermenu-item-layout-image_left > .ubermenu-target-text { padding-left:50px; }
/* 39822 */  .ubermenu .ubermenu-item-39822 > .ubermenu-target.ubermenu-item-layout-image_left > .ubermenu-target-text { padding-left:50px; }
/* 19897 */  .ubermenu .ubermenu-item-19897 > .ubermenu-target.ubermenu-item-layout-image_left > .ubermenu-target-text { padding-left:50px; }
/* 727 */    .ubermenu .ubermenu-item-727 > .ubermenu-target.ubermenu-item-layout-image_left > .ubermenu-target-text { padding-left:50px; }

/* Status: Loaded from Transient */

</style>
	<style></style>

	<style>  /* Brand Color 0 */
  .has-brand-color-0-color {
    color: #001b37 !important;
  }
  .has-brand-color-0-background-color {
    background-color: #001b37 !important;
  }  /* Brand Color 1 */
  .has-brand-color-1-color {
    color: #0a00c7 !important;
  }
  .has-brand-color-1-background-color {
    background-color: #0a00c7 !important;
  }  /* Brand Color 2 */
  .has-brand-color-2-color {
    color: #003973 !important;
  }
  .has-brand-color-2-background-color {
    background-color: #003973 !important;
  }  /* Brand Color 3 */
  .has-brand-color-3-color {
    color: #fab31e !important;
  }
  .has-brand-color-3-background-color {
    background-color: #fab31e !important;
  }  /* Brand Color 4 */
  .has-brand-color-4-color {
    color: #0a3bff !important;
  }
  .has-brand-color-4-background-color {
    background-color: #0a3bff !important;
  }  /* Brand Color 5 */
  .has-brand-color-5-color {
    color: #deeeff !important;
  }
  .has-brand-color-5-background-color {
    background-color: #deeeff !important;
  }  /* Brand Color 6 */
  .has-brand-color-6-color {
    color: #000000 !important;
  }
  .has-brand-color-6-background-color {
    background-color: #000000 !important;
  }  /* Brand Color 7 */
  .has-brand-color-7-color {
    color: #ffffff !important;
  }
  .has-brand-color-7-background-color {
    background-color: #ffffff !important;
  }</style><link rel="icon" href="https://aaai.org/wp-content/uploads/2022/12/cropped-white-logo-32x32.png" sizes="32x32" />
<link rel="icon" href="https://aaai.org/wp-content/uploads/2022/12/cropped-white-logo-192x192.png" sizes="192x192" />
<link rel="apple-touch-icon" href="https://aaai.org/wp-content/uploads/2022/12/cropped-white-logo-180x180.png" />
<meta name="msapplication-TileImage" content="https://aaai.org/wp-content/uploads/2022/12/cropped-white-logo-270x270.png" />
		<style id="wp-custom-css">
			/* hide meta on conference page */
.single-conference p.entry-meta {
	display: none;
}
.single-conference.no-rule .header-rule {
	border-bottom: none;
}
/* remove rule from h1 on conference page */
h1.no-rule {
	border: none;
}
.date-time {
	text-transform: uppercase;
	font-weight: 700;
	font-family: "Rustica", sans-serif;
	letter-spacing: 1px;
}
@media only screen and (max-width: 600px) {
	.hide-on-mobile {
	display: none;
}
}
.hidden{
	display: none;
}
h2 span.subtitle {
	font-size: 75%;
	display: block;
	padding: 10px 0;
}

h1 span.subtitle {
	display: none;
}

.section-hide {
	display: none;
}

/* Shift Collab edits to tabbed content
 * for custom styling
 * 
 * 
 * * */
:root{
	--primary-blue: #003973;
	--primary-yellow: #fab31e;
	--bright-blue: #0a3bff;
	--light-blue: #deeeff;
	--black: #000;
	--white: #fff;
	--dark-blue-bk: #001b37;
	--bright-blue-bk: #0a00c7;
}

.wp-block-ub-tabbed-content-holder.vertical-holder{
	flex-direction: row-reverse;
}

.wp-block-ub-tabbed-content-tab-title-vertical-wrap.active{
	background-image: linear-gradient(to right, #0a3bff , #003973);
}

.wp-block-ub-tabbed-content-tab-title{
	color: #fff;
}
.wp-block-ub-tabbed-content-tabs-content{
	padding:0px;
}
.wp-block-ub-tabbed-content-tab-content-wrap p{
	margin: 0px;
}
.home .site-container{
	background-color: var(--dark-blue-bk);
}

/* Frontpage styles */
.wp-block-ub-tabbed-content .wp-block-ub-tabbed-content-tabs-content{
	border:none;
}
.ten-border-radius{
	border-radius: 10px;
}
.wp-block-ub-tabbed-content-tab-content-wrap{
	position: relative;
}

.wp-block-ub-tabbed-content-tabs-title-vertical-tab{
	display: grid;
	height: 100%;
}
/* turn long list into columns */
.list-has-columns {
    column-count: 3;
    column-width: 220px;
}



/* Button defaults */
.site-container .wp-block-button .wp-block-button__link{
	border-radius: 35px;
	font-weight: 700 !important;
	border-width: 3px !important;
	border-color: var(--bright-blue);
	padding: 5px 35px !important;
	font-size: 18px !important;
}
/* Calendar quick fixes */
@media(min-width: 700px) {
h2.calendar-heading{
	padding-left: 42px;
}
}
@media(min-width: 900px) {
h2.calendar-heading{
	padding-left: 151px;
}
}
@media(max-width: 700px) {
.calendar-event .event-title,
.calendar-event .event-step,
.calendar-event .display-date,
.calendar-event .event-link {
	width: 100% !important;		
	}
}
.citation-generate{
	display:none;
}
.citation-generate-container.show{
	display:block;
}
.italics{
	font-style:italic;
}
.bold{
	font-weight: bold;
}
/* Text safe defaults */
a{
	color: var(--bright-blue);
	text-decoration: none;
} 
a:hover{
	color: var(--primary-blue);
	text-decoration: underline;
}
.dark-background-color a  {
	color: var(--wp--preset--color--brand-color-3);
}
.dark-background-color a:hover,
.dark-background-color a:focus {
	color: var(--wp--preset--color--cyan-bluish-gray);
}
p {
	color: var(--black);
}
h1,h2,h3,h4,h5{
	color: var(--primary-blue);
		font-family: "Rustica", sans-serif;

}
h1, h1.archive-title {
	font-weight: 500;
	font-size: 45px;
	border-bottom: 1px solid var(--wp--preset--color--brand-color-3);
}
h1.entry-title{
	font-weight: 500;
	font-size: 45px;
	border-bottom:0px;
}
.header-rule{
	width: 100%;
    display: block;
    border-bottom: 1px solid var(--wp--preset--color--brand-color-3);
	margin-bottom: 10px
}
.post-subtitle{
	font-size: 33px;
	color: var(--primary-blue);
  font-family: "Rustica", sans-serif;
	margin-bottom: 10px;
}
.intro-text {
	font-size: 22px;
}
hr {
	border: 1px solid var(--wp--preset--color--brand-color-3);
	
}

.site-header{
	background-image: url(https://aaaiprod.wpengine.com/wp-content/uploads/2022/12/header-texture.png);
	background-repeat: no-repeat;
	background-position: center;
	background-size: cover;
}

#close-icon-mobile{
	display:none;
	float:right;
	color:#fff;
	margin-right:30px;
	font-size: 50px;
	height:0;
}
#close-icon{
	color:#fff;
	cursor: pointer;
}
.title-area{
		display:none;
	}

/* Fix for in-page anchors, so the anchor text is not under the header */
.in-page-anchor:before {
    content: '';
    display: block;
    position: relative;
    width: 0;
    height: 4em;
    margin-top: -4em;
	z-index: -10 !important;
}
.in-page-anchor {
	z-index: -10 !important;
	
}


/* temp fix for conference and paper dates */
.conference .entry-header .entry-meta,
.papers .entry-header .entry-meta {
	display: none;
}

@media(max-width: 899px){
	/* Mobile menu styles */
.ubermenu .ubermenu-submenu .ubermenu-target-text {
		width: 100%;
		margin-left: 80px;
	}
	.ubermenu .ubermenu-submenu .ubermenu-submenu .ubermenu-target-text{
		margin-left: 120px;
	}
	.side-menu{
    background-color: var(--dark-blue-bk) !important;
		z-index: 999999 !important;
		padding-top: 5px !important;
}
	
	.wp-block-ub-tabbed-content-tabs-title-vertical-tab > div:not(:last-child){
		border-right:0;
		border-top-left-radius: 0px;
    border-top-right-radius: 0px;
    border-bottom-left-radius: 0px;
    border-bottom-right-radius: 0px;
	}
	
	.wp-block-genesis-blocks-gb-column .gb-block-layout-column-inner .wp-block-button > a{
		width: 100%;
    max-width: 400px;
	}
	.wp-block-button{
		width: 100%;
    max-width: 400px;
	}
.gb-layout-column-wrap{
    grid-template-areas: none;
    grid-template-columns: none;
    grid-gap: 0 1em;
	}
	.wp-container-1{
		flex-direction: column;
		margin-bottom: 15px;
	}
	
	.wp-block-ub-tabbed-content-tabs-title-vertical-tab div:last-child{
		border-top-left-radius: 0px;
    border-top-right-radius: 0px;
    border-bottom-left-radius: 10px;
    border-bottom-right-radius: 10px;
		border-left: 0;
    border-right: 0;
    border-bottom: 0;
	}

	
.wp-block-ub-tabbed-content-holder.vertical-holder {
    display: flex;
    flex-flow: column;
    flex-direction: column-reverse;
}
	
.wp-block-ub-tabbed-content-tab-content-wrap:after {
    content: '';
    position: absolute;
    bottom: 0;
    left: 0;
    right: 0;
    height: 300px;
    background: transparent;
}

.wp-block-ub-tabbed-content-tab-content-wrap:before {
    content: '';
    position: absolute;
    top: 0;
    left: 0;
    right: 0;
    height: 300px;
    z-index: 1;
    background: linear-gradient(0deg, rgba(0,0,0,0), rgba(0,0,0,0.9));
}
	
	.wp-block-ub-tabbed-content-tabs-title-mobile-horizontal-tab{
		display:block;
	}
			.wp-block-ub-tabbed-content-tabs-content, .wp-block-ub-tabbed-content-tab-content-wrap div{
				padding-top:0.5em !important;
				padding-bottom:0em !important;
				
				-webkit-border-top-left-radius: 0px;
			-webkit-border-bottom-right-radius: 0px;
		-webkit-border-bottom-left-radius: 0px;
				-moz-border-radius-topleft: 0px;
		-moz-border-radius-bottomright: 0px;
		-moz-border-radius-bottomleft: 0px;
				border-top-left-radius: 0px;
		border-bottom-right-radius: 0px;
		border-bottom-left-radius: 0px;
		}
}

/* sidebar nav stylings */
.ubermenu-submenu{
    display: flex;
    flex-flow: row wrap;
    align-items: center;
		min-width:220px
}
.ubermenu-skin-grey-white .ubermenu-submenu.ubermenu-submenu-drop{
	background-color: var(--primary-blue);
}
.ubermenu-wrap .ubermenu-submenu > .ubermenu-item{
	color: #fff;
	background-color: var(--primary-blue);
}
.ubermenu-wrap .ubermenu-submenu {
	border-right: 2px solid #084481 !important;
}

.ubermenu-wrap .ubermenu-submenu .ubermenu-submenu,.ubermenu-wrap .ubermenu-submenu .ubermenu-submenu > .ubermenu-item{
	min-width:220px;
	background-color: #084481;
}
.ubermenu-submenu.ubermenu-submenu-type-flyout{
	min-width: 220px;
}
.ubermenu .ubermenu-target{
    display:flex;
}
.ubermenu .ubermenu-target-with-image>.ubermenu-target-text{
    display: flex;
    align-items: center;
}
.ubermenu .ubermenu-submenu .ubermenu-target-text{
	width: 100%;
  padding: 5px 10px;
}
.ubermenu .ubermenu-submenu .ubermenu-target-text:hover, 
.ubermenu .ubermenu-submenu .ubermenu-current-menu-item .ubermenu-target-text {
	background-color: var(--bright-blue);
	border-radius: 5px;
}

.ubermenu .ubermenu-submenu .ubermenu-current-menu-item .ubermenu-submenu .ubermenu-target-text {
	background-color: #084481;
}
.ubermenu .ubermenu-submenu .ubermenu-current-menu-item .ubermenu-submenu .ubermenu-target-text:hover, 
.ubermenu .ubermenu-submenu .ubermenu-current-menu-item .ubermenu-submenu .ubermenu-target-text:focus {
	background-color: var(--bright-blue);	
}

.ubermenu .ubermenu-submenu .ubermenu-current-menu-item > .ubermenu-target {
	color: white;
}
.ubermenu .ubermenu-submenu .ubermenu-target {
	padding: 5px 20px;
}
.author-wrap{
	margin-bottom: 1em;
	display: flex;
}
.author-wrap h4{
	margin: 0;
  justify-self: flex-start;
  flex: 20%; 
}
.author-wrap > div{
	flex: 80%;
	justify-self: flex-start;
  text-align: left;
}
.author-wrap p{
	margin: 0px 0px 2px;
	padding-left: 8em;
}

.paper-section-wrap{
	margin-bottom: 1em;
	display: flex;
}
.paper-section-wrap h4{
	margin: 0;
  justify-self: flex-start;
  flex: 20%; 
}
.paper-section-wrap > div{
	flex: 80%;
	justify-self: flex-start;
  text-align: left;
}
.paper-section-wrap p{
	margin: 0px 0px 2px;
	padding-left: 8em;
}

.paper-section-wrap .pdf-button{
	margin: 0px 0px 2px;
	padding-left: 8em;
}
.bold{
	font-weight: bold;
}
/*.entry-content p:first-child{
	background-color: #DEEEFF;
	border-radius: 10px;
	padding: 20px 15px;
	font-weight: bold;
}
*/
.breadcrumbs{
	margin: 0px 0px 50px;
  padding: 2px 4px;
	text-transform: uppercase !important;
}
.breadcrumbs > a{
	font-size: 16px;
	color: #000;
	text-decoration:none;
}
.breadcrumb {
	font-family: "Roboto", sans-serif;
	font-weight: 400;
	font-size: 16px;
	border-bottom: none;
	margin-top: 0;
	padding-top: 0;
}
.breadcrumb a {
	color: var(--black);
}
.papers-sidebar{
	font-size: 15px;
}
.track-wrap h5{
	margin:0px
}
.papers-author-page{
	display: flex;
  flex-direction: row;
 	justify-content: space-between;
}
.papers-author-page p{
	margin: 0px
}
.papers-author-page p:first-child{
	width: 70%;
}
.paper-wrap{
	margin: 0px 0px 15px;
}
.paper-wrap .wp-block-button{
	font-weight: bold;
	text-decoration:underline;
}
.pdf-button{
	padding: 2em 0em;
  display: inline-block;
}
.pdf-button a{
	border-radius: 35px;
	padding: 5px 20px;
  background-color: transparent;
  border: 2px solid currentColor;
}
#search-form .input-group{
		display: flex;
		align-items: center;
    justify-content: center;
}
#search-form input{
		width: 80%;
		margin-left:10px;
    background: transparent;
    border-width: 0px 0px 2px;
}
#search-input, #search-input::placeholder{
	color: #fff;
}
.fa-search::before{
	color:#fff;
	
}
.text-bubble:before{
	content:url("https://aaaiprod.wpengine.com/wp-content/uploads/2022/12/chat-1.png");
}
.open-book:before{
	content:url("https://aaaiprod.wpengine.com/wp-content/uploads/2022/12/book-open-1.png");
}
.creased-paper:before{
	content:url("https://aaaiprod.wpengine.com/wp-content/uploads/2022/12/file-filled-1.png");
}
.portrait:before{
	content:url("https://aaaiprod.wpengine.com/wp-content/uploads/2022/12/user-square-1.png");
}

.subtitle{
	display:none;
	font-size: 22px;
  padding: 0 0 10px;
}
.blog .subtitle{
	display: block;
}
.dashicons{
	cursor: pointer;
}

.side-menu-header{
	  position: fixed;
    top: 20px;
}
.site-inner{
	min-height:1200px;
	padding-top: 20px;
}

/* Papers styles */
.blue-box{
	background: #DEEEFF;
	border-radius: 10px;
	padding: 20px 15px;
	display: flex;
}
.blue-box img{
	width: auto;
	max-height: 250px;
	float: left;
	padding-right: 20px;
}
.blue-box .blue-box-attributes p{
	margin: 0px;
}
.doi-output p{
	margin: 0px 0px 2px;
  padding-left: 6em;
}
.abstract-output p{
	margin: 0px 0px 2px;
  padding-left: 6em;
}
/* sidemenu styles */
.ubermenu-wrap{
	background-color: var(--dark-blue-bk);
	z-index:9;
	position: sticky;
  padding-top: 0px;
	top: 0px;
}
.menu-control-wrap{
    display:none;
}
.ubermenu .ubermenu-divider hr{
	margin: 0 auto;
  width: 200px;
  background-color: var(--bright-blue);
}
.conf-wrap .site-inner .content-sidebar-wrap .sidebar{
	margin-top: 130px;
		float:left;
	}

.conf-sidebar-wrapper ul {
    padding-left: 0;
    list-style: none;
}

.conf-sidebar-wrapper ul li {
    margin-left: 0;
}

.conf-sidebar-wrapper h4,
.conf-sidebar-wrapper h5 {
	margin-top: 2.5em;
}

@media(min-width:960px){

	.ubermenu-wrap{
		position: fixed;
		height: 100%;
		max-width: 260px;
		top: unset;
	}
	.menu-control-wrap{
		display:block;
	}
	.ubermenu-submenu-type-flyout{
		height:2500px!important;
	}
	.ubermenu-sub-indicator {
    display: none;
	}

	.archive .breadcrumb, 
	.blog .breadcrumb, 
	.single .breadcrumb {
		margin-left: 0;
	}

	.archive .entry-header,
	.blog .entry-header ,
	.single .entry-header {
		margin-left: 0px;
	}
}
.ubermenu .ubermenu-submenu .ubermenu-column-auto{
	min-width: auto;
}

.proceeding-breadcrumb{
	display:flex;
	gap: 10px;
	margin-bottom: 2em;
}

.breadcrumb{
	display:flex;
	gap: 10px;
	margin-bottom: 2em;
}

@media (min-width:960px) and (max-width:1584px){
	.home .site-container .site-inner{
		margin-right: 20px;
    width: calc(100% - 330px);
	}
}


/* evergreen conf styles */
.conference-header-wrap {
  display: flex;
  flex-wrap: wrap;
  justify-content: space-between;
  align-items: center;
	background-color: #003973;
}
.spacer{
	flex-basis:10%;
}
.conference-header-text {
  flex-basis: 50%;
	padding: 0em 1em;
}
.conference-header-text h3{
	color:#fff;
	font-style: normal;
	font-weight: 500;
	font-size: 40px;
	line-height: 45px;
}
.conference-header-text h4{
	color:#fff;
	font-style: normal;
	font-weight: 700;
	font-size: 18px;
	line-height: 30px;
	letter-spacing: 0.05em;
	text-transform: uppercase;
}
.conference-header-image {
  flex-basis: 35%;
	position: relative;
	width: 100%;
}
.conference-header-image::before {
  content: "";
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  background: linear-gradient(to left, rgba(0, 57, 115, 0), #003973);
  z-index: 1;
}
.conference-header-image::after {
  content: "";
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  background: linear-gradient(to bottom, rgba(0, 57, 115, 0.0), #003973);
  z-index: 1;
	display:none;
}
.conference-header-image img {
  width: 100%;
  height: auto;
}

.current-conference-wrap .content{
	width: 100%;
}

.conf-sidebar-wrapper ul > li{
	list-style-type: none;
}
.conference-header-text {
    display: flex;
    align-items: center;
}
.conference-header-logo {
    margin-right: 20px;
	align-self: start;
}

h1.archive-title{
	font-size: 30px;
}
/* current conf page menu styles */
/* Desktop styles */
@media (min-width: 943px) {
    /* Hide mobile menu */
    #current-conference-menu {
        display: none;
    }
    /* Show desktop menu */
    #current-conference-menu.desktop-menu {
        display: block !important;
    }
    #current-conference-menu.desktop-menu .nav-item {
        display: inline-block;
        margin-right: 10px;
    }
}
.navbar ul > li{
	list-style-type: none;
}
.hidden-text > a > span{
	display:none !important;
}
.hidden-text > a > i:before{
	font-size: 2em;
}
/* Mobile styles */
@media (max-width: 942px) {
	/* Hide mobile menu by default */
    #current-conference-menu {
        display: none;
    }
    /* Hide desktop menu */
    #current-conference-menu.desktop-menu {
        display: none !important;
    }
    /* Show mobile menu */
    #current-conference-menu {
        display: block;
    }
    #current-conference-menu .nav-item {
        display: block;
        margin-bottom: 10px;
    }
	.conference-header-wrap{
		flex-flow: column-reverse;
	}
	.conference-header-image::before{
		display:none
	}
	.conference-header-image::after{
		display:block;
	}
	.spacer{
	flex-basis:0%;
}
}

.navbar-toggler{
	   display: flex;
    justify-content: space-between;
    align-items: center;
    width: 100%;
    border: none;
    border-bottom: 2px solid blue;
    border-radius: 0px;
}
.fa-caret-down {
  transform: rotate(180deg);
}

@media (max-width: 768px) {
  .conference-header-text,
  .conference-header-image {
    flex-basis: 100%;
  }
}

.ubermenu-item a{
	padding: 5px 20px;
}
#search-form{
	margin: 0px!important;
}
.ubermenu-target {
	padding: 5px 20px!important;
}

.navbar-nav{
	padding-left: 0px!important;
	border-bottom: 2px solid #DEEEFF;
}
.navbar-nav a{
	color: #0A3BFF;
	font-weight:bold;
	font-family: "Roboto", sans-serif;
}
.nav-item:hover{
	border-bottom: 2px solid blue;
}
.navbar-nav a:hover{
	color: #0A3BFF;
	text-decoration: none;
	padding-bottom: 3px;
}
.navbar-expand-lg .navbar-nav{
	  width: 100%;
    gap: 4%;
}

/* conference menu */
.menu-current-conference-midpage-container, 
.menu-conference-aaai-25-container, 
.menu-conference-aaai-26-container{
	padding-top: 10px
}
@media only screen and (max-width: 959px) {
	.menu-current-conference-midpage-container, 
.menu-conference-aaai-25-container, 
.menu-conference-aaai-26-container{
		width: 100%
	}
  .menu-current-conference-midpage-container ul, 
.menu-conference-aaai-25-container ul, 
.menu-conference-aaai-26-container ul {
    flex-wrap: wrap;
  }

  .menu-current-conference-midpage-container li, 
.menu-conference-aaai-25-container li, 
.menu-conference-aaai-26-container li {
    flex-basis: 10%;
  }
	
	.author-wrap{
		flex-direction: column;
	}
	.author-wrap > div p{
		padding-left: 0px;
	}
	.paper-section-wrap{
		flex-direction: column;
	}
	.paper-section-wrap .pdf-button{
		padding-left: 0px;
	}
	.paper-section-wrap > div p{
		padding-left: 0px;
	}
	.blue-box{
		flex-direction: column;
	}
	.blue-box img{
    max-height: 100%;
	}
}
@media only screen and (min-width: 960px){
	.menu-current-conference-midpage-container, 
.menu-conference-aaai-25-container, 
.menu-conference-aaai-26-container {
		margin-left: -180px;
		margin-right: -180px;
		max-width: calc(100% + 360px);
		width: auto;
	}
}
.menu-current-conference-midpage-container ul, 
.menu-conference-aaai-25-container ul, 
.menu-conference-aaai-26-container ul {
  list-style: none;
  padding: 0;
  margin: 0;
  display: flex;
}

.menu-current-conference-midpage-container ul > li, 
.menu-conference-aaai-25-container ul > li, 
.menu-conference-aaai-26-container ul > li {
  margin-right: 10px;
  min-width: 120px;
	list-style: none;
	text-align: center;
}

.menu-current-conference-midpage-container li:last-child, 
.menu-conference-aaai-25-container li:last-child, 
.menu-conference-aaai-26-container li:last-child {
  margin-right: 0;
}

.menu-current-conference-midpage-container a, 
.menu-conference-aaai-25-container a, 
.menu-conference-aaai-26-container a {
  text-decoration: none;
  display: block;
  padding: 5px 10px;
}

.menu-current-conference-midpage-container a:hover, 
.menu-conference-aaai-25-container a:hover, 
.menu-conference-aaai-26-container a:hover {
  text-decoration: underline;
}



@media (min-width: 943px) {
	.navbar-expand-lg .navbar-nav a:first-of-type{
		padding-left:0px!important;
	}
}
@media (max-width: 943px) {
	.nav-item:hover{
		border-bottom: 0px solid blue;
	}
	.navbar-nav a:hover{
		padding-bottom: 8px;
	}
	.navbar-toggler:hover{
		background-color: #fff;
    border-width: 2px;
    color: grey;
	}
	.navbar-toggler:focus{
		outline: 0px!important;
		box-shadow: none;
	}
}

/* events display */
.event-header-block{
	padding: 10px 10px 0px;
}
.event-date-block > *:nth-child(odd){
	background-color: #E5E5E5;
}
.event-date-block > *:nth-child(even) {
  background-color: #FFFFFF;
}
.program-event-block{
	display:flex;
	align-items: start;
  gap: 1rem; 
  padding: 1rem; 
}
.program-time-block{
	min-width: 150px;
	font-weight: bold;
}
.program-event-block > *:first-child{
	margin-left: 20px;
}
.program-event-block > *:last-child{
	margin-left: 20px;
	flex-basis: 85%;
}
.event-date-block > *:last-child{
  margin-bottom: 20px;
}
@media (max-width: 993px){
	.program-event-block{
		display: block;
		margin-left: 20px
	}
	.program-time-block{
		padding: 20px;
	}
	.program-event-block > *:first-child{
		margin-left: 0px;
		
	}
}

/* Hide the submenu by default */
#menu-current-conference-midpage .sub-menu, 
.menu-conference-aaai-25-container .sub-menu, 
.menu-conference-aaai-26-container .sub-menu {
  height: 0;
  overflow: hidden;
  transition: max-height 0.3s ease;
  position: absolute;
  z-index: 9999;
  background-color: white;
}

#menu-current-conference-midpage li:hover > .sub-menu, 
.menu-conference-aaai-25-container li:hover > .sub-menu, 
.menu-conference-aaai-26-container li:hover > .sub-menu {
  height: auto;
	border: 1px solid blue;
}

#menu-current-conference-midpage .sub-menu li, 
.menu-conference-aaai-25-container .sub-menu li, 
.menu-conference-aaai-26-container .sub-menu li {
  padding: 5px 0;
  list-style: none;
  display: block;
	width: 100%;
}

#menu-current-conference-midpage .sub-menu a, 
.menu-conference-aaai-25-container .sub-menu a, 
.menu-conference-aaai-26-container .sub-menu a {
  color: #000000;
  text-decoration: none;
	text-align: left;
}

#menu-current-conference-midpage .sub-menu, 
.menu-conference-aaai-25-container .sub-menu, 
.menu-conference-aaai-26-container .sub-menu {
  display: block;
  opacity: 0;
}

#menu-current-conference-midpage li:hover > .sub-menu, 
.menu-conference-aaai-25-container li:hover > .sub-menu, 
.menu-conference-aaai-26-container li:hover > .sub-menu {
  opacity: 1;
}
#menu-current-conference-midpage .sub-menu li:hover, 
.menu-conference-aaai-25-container .sub-menu li:hover, 
.menu-conference-aaai-26-container .sub-menu li:hover{
	background-color: #FAFAFA;
}

/* part of the conference template fix 11/22/2023 */
.single-conference .content-sidebar-wrap{
	display: flex;
}
.single-conference .content-sidebar-wrap aside{
	order: -1;
}
.single-conference .content-sidebar-wrap .conf-sidebar-wrapper{
	width: 250px;
	margin-right: 20px;
}

/* 11/22/2023 future conference fix stylings */
.conf-wrap.future-conf .breadcrumb{
	display: none;
}
.conf-wrap.future-conf .entry-meta{
	display: none;
}
.conf-wrap.future-conf .header-rule{
	display: none;
}
.conf-wrap.future-conf .site-inner{
	width: 100%;
	margin-right: auto;
}

.full-width-content .entry-content > .alignwide{
	margin-left: 0px;
}
.menu-current-conference-midpage-container, .menu-conference-aaai-25-container, .menu-conference-aaai-26-container{
	margin-left: 0px;
}

/** conf template update 11/26/2024 for stacking the sidebar **/
@media (max-width: 943px) {
	.single-conference .content-sidebar-wrap{
		flex-direction: column;
	}
	.single-conference .content-sidebar-wrap aside {
    order: 1;
	}
}

@media (min-width: 960px) and (max-width: 1584px) {
    .conf-wrap .site-inner {
        margin-right: auto !important;
        width: calc(100% - 330px);
    }
}

/** gravity forms **/
.gform_wrapper.gravity-theme .gsection {
	border-bottom: none;
	border-top: 1px solid var(--wp--preset--color--brand-color-3);
	padding-top: 1em;
}		</style>
		</head>
<body class="archive tax-proceeding term-vol-34-no-05-aaai-20-technical-tracks-5 term-4558 wp-custom-logo wp-embed-responsive header-full-width content-sidebar genesis-breadcrumbs-hidden genesis-footer-widgets-hidden no-js">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-MBH24FG"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
	<script>
	//<![CDATA[
	(function(){
		var c = document.body.classList;
		c.remove( 'no-js' );
		c.add( 'js' );
	})();
	//]]>
	</script>
	<div class="proceedings-wrap"><ul class="genesis-skip-link"><li><a href="#genesis-content" class="screen-reader-shortcut"> Skip to main content</a></li><li><a href="#genesis-sidebar-primary" class="screen-reader-shortcut"> Skip to primary sidebar</a></li></ul><header class="site-header"><div class="wrap"><div class="title-area"><a href="https://aaai.org/" class="custom-logo-link" rel="home"><img width="1000" height="235" src="https://aaai.org/wp-content/uploads/2024/03/AAAI-Logo-Title-White.png" class="custom-logo" alt="AAAI" decoding="async" fetchpriority="high" srcset="https://aaai.org/wp-content/uploads/2024/03/AAAI-Logo-Title-White.png 1000w, https://aaai.org/wp-content/uploads/2024/03/AAAI-Logo-Title-White-300x71.png 300w, https://aaai.org/wp-content/uploads/2024/03/AAAI-Logo-Title-White-768x180.png 768w" sizes="(max-width: 1000px) 100vw, 1000px" /></a><p class="site-title">AAAI</p><p class="site-description">Association for the Advancement of Artificial Intelligence</p></div>	<div class="menu-control-wrap">
		
<!-- UberMenu [Configuration:main] [Theme Loc:] [Integration:api] -->
<button class="ubermenu-responsive-toggle ubermenu-responsive-toggle-main ubermenu-skin-grey-white ubermenu-loc- ubermenu-responsive-toggle-content-align-left ubermenu-responsive-toggle-align-full " tabindex="0" data-ubermenu-target="ubermenu-main-44"><i class="fas fa-bars" ></i>Menu</button><nav id="ubermenu-main-44" class="ubermenu ubermenu-nojs ubermenu-main ubermenu-menu-44 ubermenu-responsive ubermenu-responsive-default ubermenu-mobile-accordion ubermenu-responsive-collapse ubermenu-vertical ubermenu-transition-none ubermenu-trigger-hover_intent ubermenu-skin-grey-white  ubermenu-bar-align-left ubermenu-items-align-flex ubermenu-bound ubermenu-disable-submenu-scroll ubermenu-sub-indicators ubermenu-retractors-responsive ubermenu-submenu-indicator-closes"><ul id="ubermenu-nav-main-44" class="ubermenu-nav" data-title="Menu Controls"><!-- begin Tabs: [Tabs] 561 --><li id="menu-item-561" class="ubermenu-item ubermenu-tabs ubermenu-item-561 ubermenu-item-level-0 ubermenu-column ubermenu-column-full ubermenu-tab-layout-top ubermenu-tabs-show-default ubermenu-tabs-show-current"><ul  class="ubermenu-tabs-group ubermenu-tabs-group--trigger-mouseover ubermenu-column ubermenu-column-full ubermenu-submenu ubermenu-submenu-id-561 ubermenu-submenu-type-auto ubermenu-submenu-type-tabs-group"  ><li id="menu-item-562" class="ubermenu-item ubermenu-item-type-custom ubermenu-item-object-ubermenu-custom ubermenu-item-562 ubermenu-item-auto ubermenu-item-level-1 ubermenu-column ubermenu-column-auto" ><div class="ubermenu-content-block ubermenu-custom-content ubermenu-custom-content-padded"><i id="close-icon" class="fas fa-bars" style="font-size: 25px;"></i></div></li><li id="menu-item-563" class="ubermenu-item ubermenu-item-type-custom ubermenu-item-object-ubermenu-custom ubermenu-item-563 ubermenu-item-auto ubermenu-item-level-1 ubermenu-column ubermenu-column-auto" ><div class="ubermenu-content-block ubermenu-custom-content ubermenu-custom-content-padded"><div class="custom-title-area">
<a href="https://aaaiprod.wpengine.com/" class="custom-logo-link" rel="home" aria-current="page">
<img width="284" height="43" src="https://aaai.org/wp-content/uploads/2024/03/AAAI-Logo-Title-White.png" class="custom-logo" alt="AAAI">
</a>
<p class="site-title">AAAI</p>
<p class="site-description">Association for the Advancement of Artificial Intelligence</p>
</div></div></li></ul></li><!-- end Tabs: [Tabs] 561 --></ul></nav>
<!-- End UberMenu -->
	</div>
</div></header>	<div class="ubermenu-wrap">
		
<!-- UberMenu [Configuration:main] [Theme Loc:] [Integration:api] -->
<button class="ubermenu-responsive-toggle ubermenu-responsive-toggle-main ubermenu-skin-grey-white ubermenu-loc- ubermenu-responsive-toggle-content-align-left ubermenu-responsive-toggle-align-full " tabindex="0" data-ubermenu-target="ubermenu-main-21"><i class="fas fa-bars" ></i>Menu</button><nav id="ubermenu-main-21" class="ubermenu ubermenu-nojs ubermenu-main ubermenu-menu-21 ubermenu-responsive ubermenu-responsive-default ubermenu-mobile-accordion ubermenu-responsive-collapse ubermenu-vertical ubermenu-transition-none ubermenu-trigger-hover_intent ubermenu-skin-grey-white  ubermenu-bar-align-left ubermenu-items-align-flex ubermenu-bound ubermenu-disable-submenu-scroll ubermenu-sub-indicators ubermenu-retractors-responsive ubermenu-submenu-indicator-closes"><ul id="ubermenu-nav-main-21" class="ubermenu-nav" data-title="upper-nav"><li id="menu-item-61136" class="ubermenu-item ubermenu-item-type-custom ubermenu-item-object-ubermenu-custom ubermenu-item-61136 ubermenu-item-level-0 ubermenu-column ubermenu-column-auto" ><div class="ubermenu-content-block ubermenu-custom-content ubermenu-custom-content-padded"><form role="search" method="get" id="search-form" action="https://aaai.org/" class="input-group mb-3">
  <div class="input-group">
    <input type="search" class="form-control border-0" placeholder="Search" aria-label="search nico" name="s" id="search-input" value="">
      <div class="input-group-append">
         <span class="input-group-append p-0">
          <i class="fas fa-search text-muted"></i>
         </span>
    </div>
  </div>
</form></div></li><li id="menu-item-19835" class="ubermenu-item ubermenu-item-type-post_type ubermenu-item-object-page ubermenu-item-has-children ubermenu-item-19835 ubermenu-item-level-0 ubermenu-column ubermenu-column-auto ubermenu-has-submenu-drop ubermenu-has-submenu-flyout" ><a class="ubermenu-target ubermenu-target-with-image ubermenu-item-layout-default ubermenu-item-layout-image_left" href="https://aaai.org/about-aaai/" tabindex="0"><img class="ubermenu-image ubermenu-image-size-full" src="https://aaai.org/wp-content/uploads/2023/03/aaai-icon_about-line-yellow.png" width="40" height="40" alt="About AAAI"  /><span class="ubermenu-target-title ubermenu-target-text">About AAAI</span><i class='ubermenu-sub-indicator fas fa-angle-down'></i></a><ul  class="ubermenu-submenu ubermenu-submenu-id-19835 ubermenu-submenu-type-flyout ubermenu-submenu-drop ubermenu-submenu-align-left_edge_item"  ><li id="menu-item-39857" class="ubermenu-item ubermenu-item-type-post_type ubermenu-item-object-page ubermenu-current_page_parent ubermenu-item-39857 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-1" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" href="https://aaai.org/news/"><span class="ubermenu-target-title ubermenu-target-text">News</span></a></li><li id="menu-item-40109" class="ubermenu-item ubermenu-item-type-post_type ubermenu-item-object-page ubermenu-item-40109 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-1" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" href="https://aaai.org/about-aaai/aaai-officers-and-committees/"><span class="ubermenu-target-title ubermenu-target-text">Officers and Committees</span></a></li><li id="menu-item-61147" class="ubermenu-item ubermenu-item-type-post_type ubermenu-item-object-page ubermenu-item-61147 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-1" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" href="https://aaai.org/about-aaai/aaai-staff/"><span class="ubermenu-target-title ubermenu-target-text">Staff</span></a></li><li id="menu-item-40941" class="ubermenu-item ubermenu-item-type-post_type ubermenu-item-object-page ubermenu-item-40941 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-1" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" href="https://aaai.org/about-aaai/bylaws-of-aaai/"><span class="ubermenu-target-title ubermenu-target-text">Bylaws</span></a></li><li id="menu-item-724" class="ubermenu-item ubermenu-item-type-post_type ubermenu-item-object-page ubermenu-item-has-children ubermenu-item-724 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-1 ubermenu-has-submenu-drop ubermenu-has-submenu-flyout ubermenu-flyout-full-height" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" href="https://aaai.org/about-aaai/aaai-awards/"><span class="ubermenu-target-title ubermenu-target-text">Awards</span><i class='ubermenu-sub-indicator fas fa-angle-down'></i></a><ul  class="ubermenu-submenu ubermenu-submenu-id-724 ubermenu-submenu-type-flyout ubermenu-submenu-drop ubermenu-submenu-align-vertical_full_height"  ><li id="menu-item-19883" class="ubermenu-item ubermenu-item-type-post_type ubermenu-item-object-page ubermenu-item-19883 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-2" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" href="https://aaai.org/about-aaai/aaai-awards/the-aaai-fellows-program/"><span class="ubermenu-target-title ubermenu-target-text">Fellows Program</span></a></li><li id="menu-item-19884" class="ubermenu-item ubermenu-item-type-post_type ubermenu-item-object-page ubermenu-item-19884 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-2" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" href="https://aaai.org/about-aaai/aaai-awards/aaai-classic-paper-award/"><span class="ubermenu-target-title ubermenu-target-text">Classic Paper Award</span></a></li><li id="menu-item-19885" class="ubermenu-item ubermenu-item-type-post_type ubermenu-item-object-page ubermenu-item-19885 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-2" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" href="https://aaai.org/about-aaai/aaai-awards/aaai-acm-sigai-doctoral-dissertation-award/"><span class="ubermenu-target-title ubermenu-target-text">Dissertation Award</span></a></li><li id="menu-item-19886" class="ubermenu-item ubermenu-item-type-post_type ubermenu-item-object-page ubermenu-item-19886 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-2" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" href="https://aaai.org/about-aaai/aaai-awards/aaai-distinguished-service-award/"><span class="ubermenu-target-title ubermenu-target-text">Distinguished Service Award</span></a></li><li id="menu-item-19887" class="ubermenu-item ubermenu-item-type-custom ubermenu-item-object-custom ubermenu-item-19887 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-2" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" target="_blank" href="http://awards.acm.org/newell/"><span class="ubermenu-target-title ubermenu-target-text">Allen Newell Award</span></a></li><li id="menu-item-19888" class="ubermenu-item ubermenu-item-type-post_type ubermenu-item-object-page ubermenu-item-19888 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-2" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" href="https://aaai.org/about-aaai/aaai-awards/aaai-conference-paper-awards-and-recognition/"><span class="ubermenu-target-title ubermenu-target-text">Outstanding Paper Award</span></a></li><li id="menu-item-19889" class="ubermenu-item ubermenu-item-type-post_type ubermenu-item-object-page ubermenu-item-19889 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-2" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" href="https://aaai.org/about-aaai/aaai-awards/aaai-award-for-artificial-intelligence-for-the-benefit-of-humanity/"><span class="ubermenu-target-title ubermenu-target-text">Award for Artificial Intelligence for the Benefit of Humanity</span></a></li><li id="menu-item-19890" class="ubermenu-item ubermenu-item-type-post_type ubermenu-item-object-page ubermenu-item-19890 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-2" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" href="https://aaai.org/about-aaai/aaai-awards/aaai-feigenbaum-prize/"><span class="ubermenu-target-title ubermenu-target-text">Feigenbaum Prize</span></a></li><li id="menu-item-19891" class="ubermenu-item ubermenu-item-type-post_type ubermenu-item-object-page ubermenu-item-19891 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-2" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" href="https://aaai.org/about-aaai/aaai-awards/aaai-eaai-patrick-henry-winston-outstanding-educator-award/"><span class="ubermenu-target-title ubermenu-target-text">Patrick Henry Winston Outstanding Educator Award</span></a></li><li id="menu-item-19892" class="ubermenu-item ubermenu-item-type-post_type ubermenu-item-object-page ubermenu-item-19892 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-2" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" href="https://aaai.org/about-aaai/aaai-awards/robert-s-engelmore-memorial-lecture-award/"><span class="ubermenu-target-title ubermenu-target-text">Engelmore Award</span></a></li><li id="menu-item-19893" class="ubermenu-item ubermenu-item-type-post_type ubermenu-item-object-page ubermenu-item-19893 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-2" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" href="https://aaai.org/about-aaai/aaai-awards/aaai-isef-awards/"><span class="ubermenu-target-title ubermenu-target-text">AAAI ISEF Awards</span></a></li><li id="menu-item-19894" class="ubermenu-item ubermenu-item-type-post_type ubermenu-item-object-page ubermenu-item-19894 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-2" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" href="https://aaai.org/about-aaai/aaai-awards/aaai-senior-member-status/"><span class="ubermenu-target-title ubermenu-target-text">Senior Member Status</span></a></li><li id="menu-item-19895" class="ubermenu-item ubermenu-item-type-post_type ubermenu-item-object-page ubermenu-item-19895 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-2" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" href="https://aaai.org/about-aaai/aaai-awards/aaai-conference-awards/"><span class="ubermenu-target-title ubermenu-target-text">Conference Awards</span></a></li></ul></li><li id="menu-item-90435" class="ubermenu-item ubermenu-item-type-custom ubermenu-item-object-custom ubermenu-item-90435 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-1" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" href="https://aaai.org/about-aaai/partnerships/"><span class="ubermenu-target-title ubermenu-target-text">Partnerships</span></a></li><li id="menu-item-40939" class="ubermenu-item ubermenu-item-type-post_type ubermenu-item-object-page ubermenu-item-40939 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-1" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" href="https://aaai.org/about-aaai/aaai-resources/"><span class="ubermenu-target-title ubermenu-target-text">Resources</span></a></li><li id="menu-item-61198" class="ubermenu-item ubermenu-item-type-post_type ubermenu-item-object-page ubermenu-item-61198 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-1" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" href="https://aaai.org/about-aaai/mailing-lists/"><span class="ubermenu-target-title ubermenu-target-text">Mailing Lists</span></a></li><li id="menu-item-744" class="ubermenu-item ubermenu-item-type-post_type ubermenu-item-object-page ubermenu-item-744 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-1" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" href="https://aaai.org/about-aaai/past-aaai-presidential-addresses/"><span class="ubermenu-target-title ubermenu-target-text">Past Presidential Addresses</span></a></li><li id="menu-item-72785" class="ubermenu-item ubermenu-item-type-custom ubermenu-item-object-custom ubermenu-item-72785 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-1" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" href="https://aaai.org/about-aaai/aaai-presidential-panel-on-long-term-ai-futures-2008-2009/"><span class="ubermenu-target-title ubermenu-target-text">Presidential Panel on Long-Term AI Futures</span></a></li><li id="menu-item-750" class="ubermenu-item ubermenu-item-type-post_type ubermenu-item-object-page ubermenu-item-has-children ubermenu-item-750 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-1 ubermenu-has-submenu-drop ubermenu-has-submenu-flyout ubermenu-flyout-full-height" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" href="https://aaai.org/about-aaai/ai-science-policy/"><span class="ubermenu-target-title ubermenu-target-text">Past Policy Reports</span><i class='ubermenu-sub-indicator fas fa-angle-down'></i></a><ul  class="ubermenu-submenu ubermenu-submenu-id-750 ubermenu-submenu-type-flyout ubermenu-submenu-drop ubermenu-submenu-align-vertical_full_height"  ><li id="menu-item-19840" class="ubermenu-item ubermenu-item-type-post_type ubermenu-item-object-page ubermenu-item-19840 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-2" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" href="https://aaai.org/about-aaai/ai-science-policy/the-role-of-intelligent-systems-in-the-national-information-infrastructure/"><span class="ubermenu-target-title ubermenu-target-text">The Role of Intelligent Systems in the National Information Infrastructure (1995)</span></a></li><li id="menu-item-749" class="ubermenu-item ubermenu-item-type-post_type ubermenu-item-object-page ubermenu-item-749 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-2" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" href="https://aaai.org/about-aaai/ai-science-policy/a-report-to-arpa-on-twenty-first-century-intelligent-systems/"><span class="ubermenu-target-title ubermenu-target-text">A Report to ARPA on Twenty-First Century Intelligent Systems (1994)</span></a></li></ul></li><li id="menu-item-40945" class="ubermenu-item ubermenu-item-type-post_type ubermenu-item-object-page ubermenu-item-40945 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-1" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" href="https://aaai.org/about-aaai/aaai-logos/"><span class="ubermenu-target-title ubermenu-target-text">Logos</span></a></li></ul></li><li id="menu-item-39822" class="ubermenu-item ubermenu-item-type-post_type ubermenu-item-object-page ubermenu-item-39822 ubermenu-item-level-0 ubermenu-column ubermenu-column-auto ubermenu-align-left" ><a class="ubermenu-target ubermenu-target-with-image ubermenu-item-layout-default ubermenu-item-layout-image_left" href="https://aaai.org/about-aaai/ethics-and-diversity/" tabindex="0"><img class="ubermenu-image ubermenu-image-size-full" src="https://aaai.org/wp-content/uploads/2023/03/aaai-icon_ethics-diversity-line-yellow.png" width="40" height="40" alt="aaai-icon_ethics-diversity-line-yellow"  /><span class="ubermenu-target-title ubermenu-target-text">Ethics &#038; Diversity</span></a></li><li id="menu-item-19897" class="ubermenu-item ubermenu-item-type-post_type ubermenu-item-object-page ubermenu-item-has-children ubermenu-item-19897 ubermenu-item-level-0 ubermenu-column ubermenu-column-auto ubermenu-has-submenu-drop ubermenu-has-submenu-flyout ubermenu-flyout-full-height" ><a class="ubermenu-target ubermenu-target-with-image ubermenu-item-layout-default ubermenu-item-layout-image_left" href="https://aaai.org/aaai-conferences-and-symposia/" tabindex="0"><img class="ubermenu-image ubermenu-image-size-full" src="https://aaai.org/wp-content/uploads/2023/03/aaai-icon_conferences-symposia-line-yellow.png" width="40" height="40" alt="Conference talk bubble"  /><span class="ubermenu-target-title ubermenu-target-text">Conferences &#038; Symposia</span><i class='ubermenu-sub-indicator fas fa-angle-down'></i></a><ul  class="ubermenu-submenu ubermenu-submenu-id-19897 ubermenu-submenu-type-flyout ubermenu-submenu-drop ubermenu-submenu-align-vertical_full_height"  ><li id="menu-item-61221" class="ubermenu-item ubermenu-item-type-custom ubermenu-item-object-custom ubermenu-item-61221 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-1" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" href="/conference/aaai/"><span class="ubermenu-target-title ubermenu-target-text">AAAI Conference</span></a></li><li id="menu-item-61222" class="ubermenu-item ubermenu-item-type-custom ubermenu-item-object-custom ubermenu-item-61222 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-1" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" href="/conference/aies/"><span class="ubermenu-target-title ubermenu-target-text">AIES AAAI/ACM</span></a></li><li id="menu-item-61223" class="ubermenu-item ubermenu-item-type-custom ubermenu-item-object-custom ubermenu-item-61223 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-1" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" href="https://aaai.org/conference/aiide-2/"><span class="ubermenu-target-title ubermenu-target-text">AIIDE</span></a></li><li id="menu-item-90208" class="ubermenu-item ubermenu-item-type-custom ubermenu-item-object-custom ubermenu-item-90208 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-1" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" href="https://aaai.org/conference/eaai/"><span class="ubermenu-target-title ubermenu-target-text">EAAI</span></a></li><li id="menu-item-61226" class="ubermenu-item ubermenu-item-type-custom ubermenu-item-object-custom ubermenu-item-61226 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-1" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" href="/conference/hcomp/"><span class="ubermenu-target-title ubermenu-target-text">HCOMP</span></a></li><li id="menu-item-61225" class="ubermenu-item ubermenu-item-type-custom ubermenu-item-object-custom ubermenu-item-61225 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-1" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" href="/conference/iaai/"><span class="ubermenu-target-title ubermenu-target-text">IAAI</span></a></li><li id="menu-item-61224" class="ubermenu-item ubermenu-item-type-custom ubermenu-item-object-custom ubermenu-item-61224 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-1" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" href="https://aaai.org/conference/icwsm/"><span class="ubermenu-target-title ubermenu-target-text">ICWSM</span></a></li><li id="menu-item-61227" class="ubermenu-item ubermenu-item-type-custom ubermenu-item-object-custom ubermenu-item-61227 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-1" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" href="/conference/spring-symposia/"><span class="ubermenu-target-title ubermenu-target-text">Spring Symposia</span></a></li><li id="menu-item-61228" class="ubermenu-item ubermenu-item-type-custom ubermenu-item-object-custom ubermenu-item-61228 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-1" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" href="https://aaai.org/conference/summer-symposia/"><span class="ubermenu-target-title ubermenu-target-text">Summer Symposia</span></a></li><li id="menu-item-61229" class="ubermenu-item ubermenu-item-type-custom ubermenu-item-object-custom ubermenu-item-61229 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-1" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" href="/conference/fall-symposia/"><span class="ubermenu-target-title ubermenu-target-text">Fall Symposia</span></a></li><li id="menu-item-40935" class="ubermenu-item ubermenu-item-type-post_type ubermenu-item-object-page ubermenu-item-40935 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-1" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" href="https://aaai.org/aaai-conferences-and-symposia/aaai-code-of-conduct-for-conferences-and-events/"><span class="ubermenu-target-title ubermenu-target-text">Code of Conduct for Conferences and Events</span></a></li></ul></li><li id="menu-item-230" class="ubermenu-item ubermenu-item-type-custom ubermenu-item-object-custom ubermenu-item-has-children ubermenu-item-230 ubermenu-item-level-0 ubermenu-column ubermenu-column-auto ubermenu-has-submenu-drop ubermenu-has-submenu-flyout ubermenu-flyout-full-height" ><a class="ubermenu-target ubermenu-target-with-image ubermenu-item-layout-default ubermenu-item-layout-image_left" href="/aaai-publications/" tabindex="0"><img class="ubermenu-image ubermenu-image-size-full" src="https://aaai.org/wp-content/uploads/2023/03/aaai-icon_publications-line-yellow.png" width="40" height="40" alt="Publications"  /><span class="ubermenu-target-title ubermenu-target-text">Publications</span><i class='ubermenu-sub-indicator fas fa-angle-down'></i></a><ul  class="ubermenu-submenu ubermenu-submenu-id-230 ubermenu-submenu-type-flyout ubermenu-submenu-drop ubermenu-submenu-align-vertical_full_height"  ><li id="menu-item-61218" class="ubermenu-item ubermenu-item-type-custom ubermenu-item-object-custom ubermenu-item-61218 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-1" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" href="https://onlinelibrary.wiley.com/journal/23719621"><span class="ubermenu-target-title ubermenu-target-text">AI Magazine</span></a></li><li id="menu-item-61219" class="ubermenu-item ubermenu-item-type-custom ubermenu-item-object-custom ubermenu-item-61219 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-1" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" href="https://aaai.org/aaai-publications/aaai-conference-proceedings/"><span class="ubermenu-target-title ubermenu-target-text">Conference Proceedings</span></a></li><li id="menu-item-40932" class="ubermenu-item ubermenu-item-type-post_type ubermenu-item-object-page ubermenu-item-40932 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-1" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" href="https://aaai.org/aaai-publications/aaai-publication-policies-guidelines/"><span class="ubermenu-target-title ubermenu-target-text">AAAI Publication Policies &#038; Guidelines</span></a></li><li id="menu-item-40928" class="ubermenu-item ubermenu-item-type-post_type ubermenu-item-object-page ubermenu-item-40928 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-1" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" href="https://aaai.org/aaai-publications/request-to-reproduce-copyrighted-materials/"><span class="ubermenu-target-title ubermenu-target-text">Request to Reproduce Copyrighted Materials</span></a></li><li id="menu-item-83926" class="ubermenu-item ubermenu-item-type-post_type ubermenu-item-object-page ubermenu-item-83926 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-1" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" href="https://aaai.org/aaai-publications/contribute/"><span class="ubermenu-target-title ubermenu-target-text">Contribute</span></a></li><li id="menu-item-61220" class="ubermenu-item ubermenu-item-type-custom ubermenu-item-object-custom ubermenu-item-61220 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-1" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" href="https://www.proceedings.com/association-for-the-advancement-of-artificial-intelligence-aaai/"><span class="ubermenu-target-title ubermenu-target-text">Order Proceedings</span></a></li></ul></li><li id="menu-item-40060" class="ubermenu-item ubermenu-item-type-post_type ubermenu-item-object-page ubermenu-item-40060 ubermenu-item-level-0 ubermenu-column ubermenu-column-auto" ><a class="ubermenu-target ubermenu-target-with-image ubermenu-item-layout-default ubermenu-item-layout-image_left" href="https://aaai.org/ai-magazine/" tabindex="0"><img class="ubermenu-image ubermenu-image-size-full" src="https://aaai.org/wp-content/uploads/2023/03/aaai-icon_ai-magazine-line-yellow.png" width="40" height="40" alt="aaai-icon_ai-magazine-line-yellow"  /><span class="ubermenu-target-title ubermenu-target-text">AI Magazine</span></a></li><li id="menu-item-727" class="ubermenu-item ubermenu-item-type-post_type ubermenu-item-object-page ubermenu-item-has-children ubermenu-item-727 ubermenu-item-level-0 ubermenu-column ubermenu-column-auto ubermenu-has-submenu-drop ubermenu-has-submenu-flyout" ><a class="ubermenu-target ubermenu-target-with-image ubermenu-item-layout-default ubermenu-item-layout-image_left" href="https://aaai.org/membership/" tabindex="0"><img class="ubermenu-image ubermenu-image-size-full" src="https://aaai.org/wp-content/uploads/2023/03/aaai-icon_membership-line-yellow.png" width="40" height="40" alt="Membership"  /><span class="ubermenu-target-title ubermenu-target-text">Membership</span><i class='ubermenu-sub-indicator fas fa-angle-down'></i></a><ul  class="ubermenu-submenu ubermenu-submenu-id-727 ubermenu-submenu-type-flyout ubermenu-submenu-drop ubermenu-submenu-align-left_edge_item"  ><li id="menu-item-39825" class="ubermenu-item ubermenu-item-type-custom ubermenu-item-object-custom ubermenu-item-39825 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-1" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" target="_blank" href="https://aaai.memberclicks.net/"><span class="ubermenu-target-title ubermenu-target-text">Member Login</span></a></li><li id="menu-item-729" class="ubermenu-item ubermenu-item-type-post_type ubermenu-item-object-page ubermenu-item-729 ubermenu-item-auto ubermenu-item-normal ubermenu-item-level-1" ><a class="ubermenu-target ubermenu-item-layout-default ubermenu-item-layout-text_only" href="https://aaai.org/membership/aaai-chapter-program/"><span class="ubermenu-target-title ubermenu-target-text">Chapters</span></a></li></ul></li><li class="ubermenu-divider"><hr/></li><li id="menu-item-518" class="ubermenu-item ubermenu-item-type-custom ubermenu-item-object-custom ubermenu-item-518 ubermenu-item-level-0 ubermenu-column ubermenu-column-auto" ><a class="ubermenu-target ubermenu-target-with-image ubermenu-item-layout-default ubermenu-item-layout-image_left" href="https://careers.aaai.org/" tabindex="0"><img class="ubermenu-image ubermenu-image-size-full" src="https://aaai.org/wp-content/uploads/2023/03/aaai-icon_career-line-yellow.png" width="40" height="40" alt="Career Center"  /><span class="ubermenu-target-title ubermenu-target-text">AI Jobs</span></a></li><li id="menu-item-61189" class="ubermenu-item ubermenu-item-type-custom ubermenu-item-object-custom ubermenu-item-61189 ubermenu-item-level-0 ubermenu-column ubermenu-column-auto" ><a class="ubermenu-target ubermenu-target-with-image ubermenu-item-layout-default ubermenu-item-layout-image_left" target="_blank" href="https://aitopics.org/search" tabindex="0"><img class="ubermenu-image ubermenu-image-size-full" src="https://aaai.org/wp-content/uploads/2023/03/aaai-icon_ai-topics-line-yellow.png" width="40" height="40" alt="aaai-icon_ai-topics-line-yellow"  /><span class="ubermenu-target-title ubermenu-target-text">AITopics</span></a></li><li id="menu-item-39821" class="ubermenu-item ubermenu-item-type-post_type ubermenu-item-object-page ubermenu-item-39821 ubermenu-item-level-0 ubermenu-column ubermenu-column-auto" ><a class="ubermenu-target ubermenu-target-with-image ubermenu-item-layout-default ubermenu-content-align-left ubermenu-item-layout-image_left ubermenu-noindicator" href="https://aaai.org/contact-aaai/" tabindex="0"><img class="ubermenu-image ubermenu-image-size-full" src="https://aaai.org/wp-content/uploads/2023/03/aaai-icon_contact-line-yellow.png" width="40" height="40" alt="aaai-icon_contact-line-yellow"  /><span class="ubermenu-target-title ubermenu-target-text">Contact</span></a></li><li class="ubermenu-divider"><hr/></li><li id="menu-item-75334" class="hidden-text ubermenu-item ubermenu-item-type-custom ubermenu-item-object-custom ubermenu-item-75334 ubermenu-item-level-0 ubermenu-column ubermenu-column-1-3 ubermenu-item-mini" ><a class="ubermenu-target ubermenu-target-with-icon ubermenu-item-layout-default ubermenu-item-layout-icon_left" href="https://twitter.com/RealAAAI" tabindex="0"><i class="ubermenu-icon fab fa-twitter-square"  title="twitter"></i><span class="ubermenu-target-title ubermenu-target-text">Twitter</span></a></li><li id="menu-item-75336" class="hidden-text ubermenu-item ubermenu-item-type-custom ubermenu-item-object-custom ubermenu-item-75336 ubermenu-item-level-0 ubermenu-column ubermenu-column-1-3 ubermenu-item-mini" ><a class="ubermenu-target ubermenu-target-with-icon ubermenu-item-layout-default ubermenu-item-layout-icon_left" href="https://www.facebook.com/AAAIOrg/" tabindex="0"><i class="ubermenu-icon fab fa-facebook-square"  title="Facebook"></i><span class="ubermenu-target-title ubermenu-target-text">Facebook</span></a></li><li id="menu-item-75333" class="hidden-text ubermenu-item ubermenu-item-type-custom ubermenu-item-object-custom ubermenu-item-75333 ubermenu-item-level-0 ubermenu-column ubermenu-column-1-3 ubermenu-item-mini" ><a class="ubermenu-target ubermenu-target-with-icon ubermenu-item-layout-default ubermenu-item-layout-icon_left" href="https://www.linkedin.com/company/association-for-the-advancement-of-artificial-intelligence-aaai-/" tabindex="0"><i class="ubermenu-icon fab fa-linkedin"  title="linkedin"></i><span class="ubermenu-target-title ubermenu-target-text">LinkedIn</span></a></li></ul></nav>
<!-- End UberMenu -->
	</div>
<div class="site-inner"><div class="content-sidebar-wrap"><main class="content" id="genesis-content"><div class="proceeding-breadcrumb"><a href="https://aaai.org/">Home </a> / <a href="https://aaai.org/aaai-publications/aaai-conference-proceedings/">Proceedings </a> / <a href="https://aaai.org/proceeding/aaai-34-2020/">Proceedings of the AAAI Conference on Artificial Intelligence, 34</a> / </div><div class="archive-description taxonomy-archive-description taxonomy-description"><h1 class="archive-title">Vol. 34 No. 05: AAAI-20 Technical Tracks 5</h1></div><div class="track-wrap"><h2>AAAI Technical Track: Multiagent Systems</h2><ul><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07269-fair-procedures-for-fair-stable-marriage-outcomes/">Fair Procedures for Fair Stable Marriage Outcomes</a></h5><span class="papers-author-page"><p>Nikolaos Tziavelis, Ioannis Giannakopoulos, Rune Quist Johansen, Katerina Doka, Nectarios Koziris, Panagiotis Karras</p><p>7269-7276</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6218/6218-13-9443-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07195-generative-attention-networks-for-multi-agent-behavioral-modeling/">Generative Attention Networks for Multi-Agent Behavioral Modeling</a></h5><span class="papers-author-page"><p>Guangyu Li, Bo Jiang, Hao Zhu, Zhengping Che, Yan Liu</p><p>7195-7202</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6209/6209-13-9434-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07203-a-variational-perturbative-approach-to-planning-in-graph-based-markov-decision-processes/">A Variational Perturbative Approach to Planning in Graph-Based Markov Decision Processes</a></h5><span class="papers-author-page"><p>Dominik Linzner, Heinz Koeppl</p><p>7203-7210</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6210/6210-13-9435-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07211-multi-agent-game-abstraction-via-graph-attention-neural-network/">Multi-Agent Game Abstraction via Graph Attention Neural Network</a></h5><span class="papers-author-page"><p>Yong Liu, Weixun Wang, Yujing Hu, Jianye Hao, Xingguo Chen, Yang Gao</p><p>7211-7218</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6211/6211-13-9436-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07219-neighborhood-cognition-consistent-multi-agent-reinforcement-learning/">Neighborhood Cognition Consistent Multi-Agent Reinforcement Learning</a></h5><span class="papers-author-page"><p>Hangyu Mao, Wulong Liu, Jianye Hao, Jun Luo, Dong Li, Zhengchao Zhang, Jun Wang, Zhen Xiao</p><p>7219-7226</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6212/6212-13-9437-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07227-multi-objective-multi-agent-planning-for-jointly-discovering-and-tracking-mobile-objects/">Multi-Objective Multi-Agent Planning for Jointly Discovering and Tracking Mobile Objects</a></h5><span class="papers-author-page"><p>Hoa Van Nguyen, Hamid Rezatofighi, Ba-Ngu Vo, Damith C. Ranasinghe</p><p>7227-7235</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6213/6213-13-9438-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07236-multi-agent-actor-critic-with-hierarchical-graph-attention-network/">Multi-Agent Actor-Critic with Hierarchical Graph Attention Network</a></h5><span class="papers-author-page"><p>Heechang Ryu, Hayong Shin, Jinkyoo Park</p><p>7236-7243</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6214/6214-13-9439-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07244-clouseau-generating-communication-protocols-from-commitments/">Clouseau: Generating Communication Protocols from Commitments</a></h5><span class="papers-author-page"><p>Munindar Singh, Amit Chopra</p><p>7244-7252</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6215/6215-13-9440-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07253-arena-a-general-evaluation-platform-and-building-toolkit-for-multi-agent-intelligence/">Arena: A General Evaluation Platform and Building Toolkit for Multi-Agent Intelligence</a></h5><span class="papers-author-page"><p>Yuhang Song, Andrzej Wojcicki, Thomas Lukasiewicz, Jianyi Wang, Abi Aryan, Zhenghua Xu, Mai Xu, Zihan Ding, Lianlong Wu</p><p>7253-7260</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6216/6216-13-9441-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07261-learning-to-communicate-implicitly-by-actions/">Learning to Communicate Implicitly by Actions</a></h5><span class="papers-author-page"><p>Zheng Tian, Shihao Zou, Ian Davies, Tim Warr, Lisheng Wu, Haitham Bou Ammar, Jun Wang</p><p>7261-7268</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6217/6217-13-9442-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07187-improving-policies-via-search-in-cooperative-partially-observable-games/">Improving Policies via Search in Cooperative Partially Observable Games</a></h5><span class="papers-author-page"><p>Adam Lerer, Hengyuan Hu, Jakob Foerster, Noam Brown</p><p>7187-7194</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6208/6208-13-9433-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07277-generalized-and-sub-optimal-bipartite-constraints-for-conflict-based-search/">Generalized and Sub-Optimal Bipartite Constraints for Conflict-Based Search</a></h5><span class="papers-author-page"><p>Thayne T. Walker, Nathan R. Sturtevant, Ariel Felner</p><p>7277-7284</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6219/6219-13-9444-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07285-shapley-q-value-a-local-reward-approach-to-solve-global-reward-games/">Shapley Q-Value: A Local Reward Approach to Solve Global Reward Games</a></h5><span class="papers-author-page"><p>Jianhong Wang, Yuan Zhang, Tae-Kyun Kim, Yunjie Gu</p><p>7285-7292</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6220/6220-13-9445-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07293-from-few-to-more-large-scale-dynamic-multiagent-curriculum-learning/">From Few to More: Large-Scale Dynamic Multiagent Curriculum Learning</a></h5><span class="papers-author-page"><p>Weixun Wang, Tianpei Yang, Yong Liu, Jianye Hao, Xiaotian Hao, Yujing Hu, Yingfeng Chen, Changjie Fan, Yang Gao</p><p>7293-7300</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6221/6221-13-9452-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07301-smix-%ce%bb-enhancing-centralized-value-functions-for-cooperative-multi-agent-reinforcement-learning/">SMIX(λ): Enhancing Centralized Value Functions for Cooperative Multi-Agent Reinforcement Learning</a></h5><span class="papers-author-page"><p>Chao Wen, Xinghu Yao, Yuhui Wang, Xiaoyang Tan</p><p>7301-7308</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6223/6223-13-9447-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07309-optimal-common-contract-with-heterogeneous-agents/">Optimal Common Contract with Heterogeneous Agents</a></h5><span class="papers-author-page"><p>Shenke Xiao, Zihe Wang, Mengjing Chen, Pingzhong Tang, Xiwang Yang</p><p>7309-7316</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6224/6224-13-9448-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07317-cobra-context-aware-bernoulli-neural-networks-for-reputation-assessment/">COBRA: Context-Aware Bernoulli Neural Networks for Reputation Assessment</a></h5><span class="papers-author-page"><p>Leonit Zeynalvand, Tie Luo, Jie Zhang</p><p>7317-7324</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6225/6225-13-9449-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07325-bi-level-actor-critic-for-multi-agent-coordination/">Bi-Level Actor-Critic for Multi-Agent Coordination</a></h5><span class="papers-author-page"><p>Haifeng Zhang, Weizhe Chen, Zeren Huang, Minne Li, Yaodong Yang, Weinan Zhang, Jun Wang</p><p>7325-7332</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6226/6226-13-9450-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07333-beyond-trees-analysis-and-convergence-of-belief-propagation-in-graphs-with-multiple-cycles/">Beyond Trees: Analysis and Convergence of Belief Propagation in Graphs with Multiple Cycles</a></h5><span class="papers-author-page"><p>Roie Zivan, Omer Lev, Rotem Galiki</p><p>7333-7340</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6227/6227-13-9451-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07179-distributed-machine-learning-through-heterogeneous-edge-systems/">Distributed Machine Learning through Heterogeneous Edge Systems</a></h5><span class="papers-author-page"><p>Hanpeng Hu, Dan Wang, Chuan Wu</p><p>7179-7186</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6207/6207-13-9432-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07040-parameterised-resource-bounded-atl/">Parameterised Resource-Bounded ATL</a></h5><span class="papers-author-page"><p>Natasha Alechina, Stéphane Demri, Brian Logan</p><p>7040-7046</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6189/6189-13-9414-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07032-subsidy-allocations-in-the-presence-of-income-shocks/">Subsidy Allocations in the Presence of Income Shocks</a></h5><span class="papers-author-page"><p>Rediet Abebe, Jon Kleinberg, S. Matthew Weinberg</p><p>7032-7039</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6188/6188-13-9413-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07047-partner-selection-for-the-emergence-of-cooperation-in-multi-agent-systems-using-reinforcement-learning/">Partner Selection for the Emergence of Cooperation in Multi-Agent Systems Using Reinforcement Learning</a></h5><span class="papers-author-page"><p>Nicolas Anastassacos, Stephen Hailes, Mirco Musolesi</p><p>7047-7054</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6190/6190-13-9415-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07055-incentive-compatible-classification/">Incentive-Compatible Classification</a></h5><span class="papers-author-page"><p>Yakov Babichenko, Oren Dean, Moshe Tennenholtz</p><p>7055-7062</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6191/6191-13-9416-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07063-learning-the-value-of-teamwork-to-form-efficient-teams/">Learning the Value of Teamwork to Form Efficient Teams</a></h5><span class="papers-author-page"><p>Ryan Beal, Narayan Changder, Timothy Norman, Sarvapali Ramchurn</p><p>7063-7070</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6192/6192-13-9417-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07071-model-checking-temporal-epistemic-logic-under-bounded-recall/">Model Checking Temporal Epistemic Logic under Bounded Recall</a></h5><span class="papers-author-page"><p>Francesco Belardinelli, Alessio Lomuscio, Emily Yu</p><p>7071-7078</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6193/6193-13-9418-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07079-odss-efficient-hybridization-for-optimal-coalition-structure-generation/">ODSS: Efficient Hybridization for Optimal Coalition Structure Generation</a></h5><span class="papers-author-page"><p>Narayan Changder, Samir Aknine, Sarvapali Ramchurn, Animesh Dutta</p><p>7079-7086</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6194/6194-13-9419-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07087-hs-cai-a-hybrid-dcop-algorithm-via-combining-search-with-context-based-inference/">HS-CAI: A Hybrid DCOP Algorithm via Combining Search with Context-Based Inference</a></h5><span class="papers-author-page"><p>Dingding Chen, Yanchen Deng, Ziyu Chen, Wenxing Zhang, Zhongshi He</p><p>7087-7094</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6195/6195-13-9420-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07095-aateam-achieving-the-ad-hoc-teamwork-by-employing-the-attention-mechanism/">AATEAM: Achieving the Ad Hoc Teamwork by Employing the Attention Mechanism</a></h5><span class="papers-author-page"><p>Shuo Chen, Ewa Andrejczuk, Zhiguang Cao, Jie Zhang</p><p>7095-7102</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6196/6196-13-9421-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07103-convergence-of-opinion-diffusion-is-pspace-complete/">Convergence of Opinion Diffusion is PSPACE-Complete</a></h5><span class="papers-author-page"><p>Dmitry Chistikov, Grzegorz Lisowski, Mike Paterson, Paolo Turrini</p><p>7103-7110</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6197/6197-13-9422-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07111-a-particle-swarm-based-algorithm-for-functional-distributed-constraint-optimization-problems/">A Particle Swarm Based Algorithm for Functional Distributed Constraint Optimization Problems</a></h5><span class="papers-author-page"><p>Moumita Choudhury, Saaduddin Mahmud, Md. Mosaddek Khan</p><p>7111-7118</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6198/6198-13-9423-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07119-an-operational-semantics-for-true-concurrency-in-bdi-agent-systems/">An Operational Semantics for True Concurrency in BDI Agent Systems</a></h5><span class="papers-author-page"><p>Lavindra de Silva</p><p>7119-7126</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6199/6199-13-9424-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07127-scalable-decision-theoretic-planning-in-open-and-typed-multiagent-systems/">Scalable Decision-Theoretic Planning in Open and Typed Multiagent Systems</a></h5><span class="papers-author-page"><p>Adam Eck, Maulik Shah, Prashant Doshi, Leen-Kiat Soh</p><p>7127-7134</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6200/6200-13-9425-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07135-parameterized-complexity-of-envy-free-resource-allocation-in-social-networks/">Parameterized Complexity of Envy-Free Resource Allocation in Social Networks</a></h5><span class="papers-author-page"><p>Eduard Eiben, Robert Ganian, Thekla Hamm, Sebastian Ordyniak</p><p>7135-7142</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6201/6201-13-9426-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07143-on-the-convergence-of-model-free-learning-in-mean-field-games/">On the Convergence of Model Free Learning in Mean Field Games</a></h5><span class="papers-author-page"><p>Romuald Elie, Julien Pérolat, Mathieu Laurière, Matthieu Geist, Olivier Pietquin</p><p>7143-7150</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6203/6203-13-9428-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07151-implicit-coordination-using-fond-planning/">Implicit Coordination Using FOND Planning</a></h5><span class="papers-author-page"><p>Thorsten Engesser, Tim Miller</p><p>7151-7159</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6204/6204-13-9429-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07160-communication-learning-via-backpropagation-in-discrete-channels-with-unknown-noise/">Communication Learning via Backpropagation in Discrete Channels with Unknown Noise</a></h5><span class="papers-author-page"><p>Benjamin Freed, Guillaume Sartoretti, Jiaheng Hu, Howie Choset</p><p>7160-7168</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6205/6205-13-9430-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07169-distributed-stochastic-gradient-descent-with-event-triggered-communication/">Distributed Stochastic Gradient Descent with Event-Triggered Communication</a></h5><span class="papers-author-page"><p>Jemin George, Prudhvi Gurram</p><p>7169-7178</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6206/6206-13-9431-1-10-20200516.pdf">PDF</a></li></ul></div><div class="track-wrap"><h2>AAAI Technical Track: Natural Language Processing</h2><ul><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09612-relational-graph-neural-network-with-hierarchical-attention-for-knowledge-graph-completion/">Relational Graph Neural Network with Hierarchical Attention for Knowledge Graph Completion</a></h5><span class="papers-author-page"><p>Zhao Zhang, Fuzhen Zhuang, Hengshu Zhu, Zhiping Shi, Hui Xiong, Qing He</p><p>9612-9619</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6508/6508-13-9733-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09620-distilling-knowledge-from-well-informed-soft-labels-for-neural-relation-extraction/">Distilling Knowledge from Well-Informed Soft Labels for Neural Relation Extraction</a></h5><span class="papers-author-page"><p>Zhenyu Zhang, Xiaobo Shu, Bowen Yu, Tingwen Liu, Jiapeng Zhao, Quangang Li, Li Guo</p><p>9620-9627</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6509/6509-13-9734-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09628-semantics-aware-bert-for-language-understanding/">Semantics-Aware BERT for Language Understanding</a></h5><span class="papers-author-page"><p>Zhuosheng Zhang, Yuwei Wu, Hai Zhao, Zuchao Li, Shuailiang Zhang, Xi Zhou, Xiang Zhou</p><p>9628-9635</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6510/6510-13-9735-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09636-sg-net-syntax-guided-machine-reading-comprehension/">SG-Net: Syntax-Guided Machine Reading Comprehension</a></h5><span class="papers-author-page"><p>Zhuosheng Zhang, Yuwei Wu, Junru Zhou, Sufeng Duan, Hai Zhao, Rui Wang</p><p>9636-9643</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6511/6511-13-9736-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09644-weakly-supervised-opinion-summarization-by-leveraging-external-information/">Weakly-Supervised Opinion Summarization by Leveraging External Information</a></h5><span class="papers-author-page"><p>Chao Zhao, Snigdha Chaturvedi</p><p>9644-9651</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6512/6512-13-9737-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09652-reinforced-curriculum-learning-on-pre-trained-neural-machine-translation-models/">Reinforced Curriculum Learning on Pre-Trained Neural Machine Translation Models</a></h5><span class="papers-author-page"><p>Mingjun Zhao, Haijiang Wu, Di Niu, Xiaoli Wang</p><p>9652-9659</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6513/6513-13-9738-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09660-balancing-quality-and-human-involvement-an-effective-approach-to-interactive-neural-machine-translation/">Balancing Quality and Human Involvement: An Effective Approach to Interactive Neural Machine Translation</a></h5><span class="papers-author-page"><p>Tianxiang Zhao, Lemao Liu, Guoping Huang, Huayang Li, Yingling Liu, Liu GuiQuan, Shuming Shi</p><p>9660-9667</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6514/6514-13-9739-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09668-semi-supervised-text-simplification-with-back-translation-and-asymmetric-denoising-autoencoders/">Semi-Supervised Text Simplification with Back-Translation and Asymmetric Denoising Autoencoders</a></h5><span class="papers-author-page"><p>Yanbin Zhao, Lu Chen, Zhi Chen, Kai Yu</p><p>9668-9675</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6515/6515-13-9740-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09676-dynamic-reward-based-dueling-deep-dyna-q-robust-policy-learning-in-noisy-environments/">Dynamic Reward-Based Dueling Deep Dyna-Q: Robust Policy Learning in Noisy Environments</a></h5><span class="papers-author-page"><p>Yangyang Zhao, Zhenyu Wang, Kai Yin, Rui Zhang, Zhenhua Huang, Pei Wang</p><p>9676-9684</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6516/6516-13-9741-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09685-replicate-walk-and-stop-on-syntax-an-effective-neural-network-model-for-aspect-level-sentiment-classification/">Replicate, Walk, and Stop on Syntax: An Effective Neural Network Model for Aspect-Level Sentiment Classification</a></h5><span class="papers-author-page"><p>Yaowei Zheng, Richong Zhang, Samuel Mensah, Yongyi Mao</p><p>9685-9692</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6517/6517-13-9742-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09693-a-pre-training-based-personalized-dialogue-generation-model-with-persona-sparse-data/">A Pre-Training Based Personalized Dialogue Generation Model with Persona-Sparse Data</a></h5><span class="papers-author-page"><p>Yinhe Zheng, Rongsheng Zhang, Minlie Huang, Xiaoxi Mao</p><p>9693-9700</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6518/6518-13-9743-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09701-jec-qa-a-legal-domain-question-answering-dataset/">JEC-QA: A Legal-Domain Question Answering Dataset</a></h5><span class="papers-author-page"><p>Haoxi Zhong, Chaojun Xiao, Cunchao Tu, Tianyang Zhang, Zhiyuan Liu, Maosong Sun</p><p>9701-9708</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6519/6519-13-9744-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09709-discourse-level-factors-for-sentence-deletion-in-text-simplification/">Discourse Level Factors for Sentence Deletion in Text Simplification</a></h5><span class="papers-author-page"><p>Yang Zhong, Chao Jiang, Wei Xu, Junyi Jessy Li</p><p>9709-9716</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6520/6520-13-9745-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09717-learning-to-compare-for-better-training-and-evaluation-of-open-domain-natural-language-generation-models/">Learning to Compare for Better Training and Evaluation of Open Domain Natural Language Generation Models</a></h5><span class="papers-author-page"><p>Wangchunshu Zhou, Ke Xu</p><p>9717-9724</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6521/6521-13-9746-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09725-co-attention-hierarchical-network-generating-coherent-long-distractors-for-reading-comprehension/">Co-Attention Hierarchical Network: Generating Coherent Long Distractors for Reading Comprehension</a></h5><span class="papers-author-page"><p>Xiaorui Zhou, Senlin Luo, Yunfang Wu</p><p>9725-9732</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6522/6522-13-9747-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09733-evaluating-commonsense-in-pre-trained-language-models/">Evaluating Commonsense in Pre-Trained Language Models</a></h5><span class="papers-author-page"><p>Xuhui Zhou, Yue Zhang, Leyang Cui, Dandan Huang</p><p>9733-9740</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6523/6523-13-9748-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09741-who-did-they-respond-to-conversation-structure-modeling-using-masked-hierarchical-transformer/">Who Did They Respond to? Conversation Structure Modeling Using Masked Hierarchical Transformer</a></h5><span class="papers-author-page"><p>Henghui Zhu, Feng Nan, Zhiguo Wang, Ramesh Nallapati, Bing Xiang</p><p>9741-9748</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6524/6524-13-9749-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09749-multimodal-summarization-with-guidance-of-multimodal-reference/">Multimodal Summarization with Guidance of Multimodal Reference</a></h5><span class="papers-author-page"><p>Junnan Zhu, Yu Zhou, Jiajun Zhang, Haoran Li, Chengqing Zong, Changliang Li</p><p>9749-9756</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6525/6525-13-9750-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09757-latte-latent-type-modeling-for-biomedical-entity-linking/">LATTE: Latent Type Modeling for Biomedical Entity Linking</a></h5><span class="papers-author-page"><p>Ming Zhu, Busra Celikkaya, Parminder Bhatia, Chandan K. Reddy</p><p>9757-9764</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6526/6526-13-9751-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09450-mixpoet-diverse-poetry-generation-via-learning-controllable-mixed-latent-space/">MixPoet: Diverse Poetry Generation via Learning Controllable Mixed Latent Space</a></h5><span class="papers-author-page"><p>Xiaoyuan Yi, Ruoyu Li, Cheng Yang, Wenhao Li, Maosong Sun</p><p>9450-9457</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6488/6488-13-9713-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09458-phasen-a-phase-and-harmonics-aware-speech-enhancement-network/">PHASEN: A Phase-and-Harmonics-Aware Speech Enhancement Network</a></h5><span class="papers-author-page"><p>Dacheng Yin, Chong Luo, Zhiwei Xiong, Wenjun Zeng</p><p>9458-9465</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6489/6489-13-9714-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09466-meta-cotgan-a-meta-cooperative-training-paradigm-for-improving-adversarial-text-generation/">Meta-CoTGAN: A Meta Cooperative Training Paradigm for Improving Adversarial Text Generation</a></h5><span class="papers-author-page"><p>Haiyan Yin, Dingcheng Li, Xu Li, Ping Li</p><p>9466-9473</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6490/6490-13-9715-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09474-dialog-state-tracking-with-reinforced-data-augmentation/">Dialog State Tracking with Reinforced Data Augmentation</a></h5><span class="papers-author-page"><p>Yichun Yin, Lifeng Shang, Xin Jiang, Xiao Chen, Qun Liu</p><p>9474-9481</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6491/6491-13-9716-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09482-enhancing-pointer-network-for-sentence-ordering-with-pairwise-ordering-predictions/">Enhancing Pointer Network for Sentence Ordering with Pairwise Ordering Predictions</a></h5><span class="papers-author-page"><p>Yongjing Yin, Fandong Meng, Jinsong Su, Yubin Ge, Lingeng Song, Jie Zhou, Jiebo Luo</p><p>9482-9489</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6492/6492-13-9717-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09490-automatic-generation-of-headlines-for-online-math-questions/">Automatic Generation of Headlines for Online Math Questions</a></h5><span class="papers-author-page"><p>Ke Yuan, Dafang He, Zhuoren Jiang, Liangcai Gao, Zhi Tang, C. Lee Giles</p><p>9490-9497</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6493/6493-13-9718-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09498-improving-context-aware-neural-machine-translation-using-self-attentive-sentence-embedding/">Improving Context-Aware Neural Machine Translation Using Self-Attentive Sentence Embedding</a></h5><span class="papers-author-page"><p>Hyeongu Yun, Yongkeun Hwang, Kyomin Jung</p><p>9498-9506</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6494/6494-13-9719-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09507-copymtl-copy-mechanism-for-joint-extraction-of-entities-and-relations-with-multi-task-learning/">CopyMTL: Copy Mechanism for Joint Extraction of Entities and Relations with Multi-Task Learning</a></h5><span class="papers-author-page"><p>Daojian Zeng, Haoran Zhang, Qianying Liu</p><p>9507-9514</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6495/6495-13-9720-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09515-neural-simile-recognition-with-cyclic-multitask-learning-and-local-attention/">Neural Simile Recognition with Cyclic Multitask Learning and Local Attention</a></h5><span class="papers-author-page"><p>Jiali Zeng, Linfeng Song, Jinsong Su, Jun Xie, Wei Song, Jiebo Luo</p><p>9515-9522</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6496/6496-13-9721-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09523-span-model-for-open-information-extraction-on-accurate-corpus/">Span Model for Open Information Extraction on Accurate Corpus</a></h5><span class="papers-author-page"><p>Junlang Zhan, Hai Zhao</p><p>9523-9530</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6497/6497-13-9722-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09531-multi-point-semantic-representation-for-intent-classification/">Multi-Point Semantic Representation for Intent Classification</a></h5><span class="papers-author-page"><p>Jinghan Zhang, Yuxiao Ye, Yue Zhang, Likun Qiu, Bin Fu, Yang Li, Zhenglu Yang, Jian Sun</p><p>9531-9538</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6498/6498-13-9723-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09539-graph-lstm-with-context-gated-mechanism-for-spoken-language-understanding/">Graph LSTM with Context-Gated Mechanism for Spoken Language Understanding</a></h5><span class="papers-author-page"><p>Linhao Zhang, Dehong Ma, Xiaodong Zhang, Xiaohui Yan, Houfeng Wang</p><p>9539-9546</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6499/6499-13-9724-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09547-exploiting-cross-lingual-subword-similarities-in-low-resource-document-classification/">Exploiting Cross-Lingual Subword Similarities in Low-Resource Document Classification</a></h5><span class="papers-author-page"><p>Mozhi Zhang, Yoshinari Fujinuma, Jordan Boyd-Graber</p><p>9547-9554</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6500/6500-13-9725-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09555-structure-learning-for-headline-generation/">Structure Learning for Headline Generation</a></h5><span class="papers-author-page"><p>Ruqing Zhang, Jiafeng Guo, Yixing Fan, Yanyan Lan, Xueqi Cheng</p><p>9555-9562</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6501/6501-13-9726-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09563-dcmn-dual-co-matching-network-for-multi-choice-reading-comprehension/">DCMN+: Dual Co-Matching Network for Multi-Choice Reading Comprehension</a></h5><span class="papers-author-page"><p>Shuailiang Zhang, Hai Zhao, Yuwei Wu, Zhuosheng Zhang, Xi Zhou, Xiang Zhou</p><p>9563-9570</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6502/6502-13-9727-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09571-learning-long-and-short-term-user-literal-preference-with-multimodal-hierarchical-transformer-network-for-personalized-image-caption/">Learning Long- and Short-Term User Literal-Preference with Multimodal Hierarchical Transformer Network for Personalized Image Caption</a></h5><span class="papers-author-page"><p>Wei Zhang, Yue Ying, Pan Lu, Hongyuan Zha</p><p>9571-9578</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6503/6503-13-9728-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09579-learning-conceptual-contextual-embeddings-for-medical-text/">Learning Conceptual-Contextual Embeddings for Medical Text</a></h5><span class="papers-author-page"><p>Xiao Zhang, Dejing Dou, Ji Wu</p><p>9579-9586</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6504/6504-13-9729-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09587-filling-conversation-ellipsis-for-better-social-dialog-understanding/">Filling Conversation Ellipsis for Better Social Dialog Understanding</a></h5><span class="papers-author-page"><p>Xiyuan Zhang, Chengxi Li, Dian Yu, Samuel Davidson, Zhou Yu</p><p>9587-9595</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6505/6505-13-9730-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09596-cfgnn-cross-flow-graph-neural-networks-for-question-answering-on-complex-tables/">CFGNN: Cross Flow Graph Neural Networks for Question Answering on Complex Tables</a></h5><span class="papers-author-page"><p>Xuanyu Zhang</p><p>9596-9603</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6506/6506-13-9731-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09604-task-oriented-dialog-systems-that-consider-multiple-appropriate-responses-under-the-same-context/">Task-Oriented Dialog Systems That Consider Multiple Appropriate Responses under the Same Context</a></h5><span class="papers-author-page"><p>Yichi Zhang, Zhijian Ou, Zhou Yu</p><p>9604-9611</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6507/6507-13-9732-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09290-a-dataset-for-low-resource-stylized-sequence-to-sequence-generation/">A Dataset for Low-Resource Stylized Sequence-to-Sequence Generation</a></h5><span class="papers-author-page"><p>Yu Wu, Yunli Wang, Shujie Liu</p><p>9290-9297</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6468/6468-13-9693-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09298-latent-opinions-transfer-network-for-target-oriented-opinion-words-extraction/">Latent Opinions Transfer Network for Target-Oriented Opinion Words Extraction</a></h5><span class="papers-author-page"><p>Zhen Wu, Fei Zhao, Xin-Yu Dai, Shujian Huang, Jiajun Chen</p><p>9298-9305</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6469/6469-13-9694-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09306-copy-or-rewrite-hybrid-summarization-with-hierarchical-reinforcement-learning/">Copy or Rewrite: Hybrid Summarization with Hierarchical Reinforcement Learning</a></h5><span class="papers-author-page"><p>Liqiang Xiao, Lu Wang, Hao He, Yaohui Jin</p><p>9306-9313</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6470/6470-13-9695-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09314-joint-entity-and-relation-extraction-with-a-hybrid-transformer-and-reinforcement-learning-based-model/">Joint Entity and Relation Extraction with a Hybrid Transformer and Reinforcement Learning Based Model</a></h5><span class="papers-author-page"><p>Ya Xiao, Chengxiang Tan, Zhijie Fan, Qian Xu, Wenye Zhu</p><p>9314-9321</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6471/6471-13-9696-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09322-attentive-user-engaged-adversarial-neural-network-for-community-question-answering/">Attentive User-Engaged Adversarial Neural Network for Community Question Answering</a></h5><span class="papers-author-page"><p>Yuexiang Xie, Ying Shen, Yaliang Li, Min Yang, Kai Lei</p><p>9322-9329</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6472/6472-13-9697-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09330-hashing-based-answer-selection/">Hashing Based Answer Selection</a></h5><span class="papers-author-page"><p>Dong Xu, Wu-Jun Li</p><p>9330-9337</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6473/6473-13-9698-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09338-knowledge-graph-grounded-goal-planning-for-open-domain-conversation-generation/">Knowledge Graph Grounded Goal Planning for Open-Domain Conversation Generation</a></h5><span class="papers-author-page"><p>Jun Xu, Haifeng Wang, Zhengyu Niu, Hua Wu, Wanxiang Che</p><p>9338-9345</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6474/6474-13-9699-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09346-the-value-of-paraphrase-for-knowledge-base-predicates/">The Value of Paraphrase for Knowledge Base Predicates</a></h5><span class="papers-author-page"><p>Bingcong Xue, Sen Hu, Lei Zou, Jiashu Cheng</p><p>9346-9353</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6475/6475-13-9700-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09354-coordinated-reasoning-for-cross-lingual-knowledge-graph-alignment/">Coordinated Reasoning for Cross-Lingual Knowledge Graph Alignment</a></h5><span class="papers-author-page"><p>Kun Xu, Linfeng Song, Yansong Feng, Yan Song, Dong Yu</p><p>9354-9361</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6476/6476-13-9701-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09362-improving-domain-adapted-sentiment-classification-by-deep-adversarial-mutual-learning/">Improving Domain-Adapted Sentiment Classification by Deep Adversarial Mutual Learning</a></h5><span class="papers-author-page"><p>Qianming Xue, Wei Zhang, Hongyuan Zha</p><p>9362-9369</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6477/6477-13-9702-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09370-knowledge-and-cross-pair-pattern-guided-semantic-matching-for-question-answering/">Knowledge and Cross-Pair Pattern Guided Semantic Matching for Question Answering</a></h5><span class="papers-author-page"><p>Zihan Xu, Hai-Tao Zheng, Shaopeng Zhai, Dong Wang</p><p>9370-9377</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6478/6478-13-9703-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09378-towards-making-the-most-of-bert-in-neural-machine-translation/">Towards Making the Most of BERT in Neural Machine Translation</a></h5><span class="papers-author-page"><p>Jiacheng Yang, Mingxuan Wang, Hao Zhou, Chengqi Zhao, Weinan Zhang, Yong Yu, Lei Li</p><p>9378-9385</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6479/6479-13-9704-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09386-alternating-language-modeling-for-cross-lingual-pre-training/">Alternating Language Modeling for Cross-Lingual Pre-Training</a></h5><span class="papers-author-page"><p>Jian Yang, Shuming Ma, Dongdong Zhang, ShuangZhi Wu, Zhoujun Li, Ming Zhou</p><p>9386-9393</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6480/6480-13-9705-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09394-generalize-sentence-representation-with-self-inference/">Generalize Sentence Representation with Self-Inference</a></h5><span class="papers-author-page"><p>Kai-Chou Yang, Hung-Yu Kao</p><p>9394-9401</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6481/6481-13-9706-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09402-end-to-end-bootstrapping-neural-network-for-entity-set-expansion/">End-to-End Bootstrapping Neural Network for Entity Set Expansion</a></h5><span class="papers-author-page"><p>Lingyong Yan, Xianpei Han, Ben He, Le Sun</p><p>9402-9409</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6482/6482-13-9707-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09410-be-relevant-non-redundant-and-timely-deep-reinforcement-learning-for-real-time-event-summarization/">Be Relevant, Non-Redundant, and Timely: Deep Reinforcement Learning for Real-Time Event Summarization</a></h5><span class="papers-author-page"><p>Min Yang, Chengming Li, Fei Sun, Zhou Zhao, Ying Shen, Chenglin Wu</p><p>9410-9417</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6483/6483-13-9708-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09418-visual-agreement-regularized-training-for-multi-modal-machine-translation/">Visual Agreement Regularized Training for Multi-Modal Machine Translation</a></h5><span class="papers-author-page"><p>Pengcheng Yang, Boxing Chen, Pei Zhang, Xu Sun</p><p>9418-9425</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6484/6484-13-9709-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09426-causally-denoise-word-embeddings-using-half-sibling-regression/">Causally Denoise Word Embeddings Using Half-Sibling Regression</a></h5><span class="papers-author-page"><p>Zekun Yang, Tianlin Liu</p><p>9426-9433</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6485/6485-13-9710-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09434-a-causal-inference-method-for-reducing-gender-bias-in-word-embedding-relations/">A Causal Inference Method for Reducing Gender Bias in Word Embedding Relations</a></h5><span class="papers-author-page"><p>Zekun Yang, Juan Feng</p><p>9434-9441</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6486/6486-13-9711-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09442-integrating-relation-constraints-with-neural-relation-extractors/">Integrating Relation Constraints with Neural Relation Extractors</a></h5><span class="papers-author-page"><p>Yuan Ye, Yansong Feng, Bingfeng Luo, Yuxuan Lai, Dongyan Zhao</p><p>9442-9449</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6487/6487-13-9712-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09130-unsupervised-neural-dialect-translation-with-commonality-and-diversity-modeling/">Unsupervised Neural Dialect Translation with Commonality and Diversity Modeling</a></h5><span class="papers-author-page"><p>Yu Wan, Baosong Yang, Derek F. Wong, Lidia S. Chao, Haihua Du, Ben C.H. Ao</p><p>9130-9137</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6448/6448-13-9673-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09138-neural-question-generation-with-answer-pivot/">Neural Question Generation with Answer Pivot</a></h5><span class="papers-author-page"><p>Bingning Wang, Xiaochuan Wang, Ting Tao, Qi Zhang, Jingfang Xu</p><p>9138-9145</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6449/6449-13-9674-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09146-reco-a-large-scale-chinese-reading-comprehension-dataset-on-opinion/">ReCO: A Large Scale Chinese Reading Comprehension Dataset on Opinion</a></h5><span class="papers-author-page"><p>Bingning Wang, Ting Yao, Qi Zhang, Jingfang Xu, Xiaochuan Wang</p><p>9146-9153</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6450/6450-13-9675-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09154-neural-machine-translation-with-byte-level-subwords/">Neural Machine Translation with Byte-Level Subwords</a></h5><span class="papers-author-page"><p>Changhan Wang, Kyunghyun Cho, Jiatao Gu</p><p>9154-9160</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6451/6451-13-9676-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09161-bridging-the-gap-between-pre-training-and-fine-tuning-for-end-to-end-speech-translation/">Bridging the Gap between Pre-Training and Fine-Tuning for End-to-End Speech Translation</a></h5><span class="papers-author-page"><p>Chengyi Wang, Yu Wu, Shujie Liu, Zhenglu Yang, Ming Zhou</p><p>9161-9168</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6452/6452-13-9677-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09169-improving-knowledge-aware-dialogue-generation-via-knowledge-base-question-answering/">Improving Knowledge-Aware Dialogue Generation via Knowledge Base Question Answering</a></h5><span class="papers-author-page"><p>Jian Wang, Junhao Liu, Wei Bi, Xiaojiang Liu, Kejing He, Ruifeng Xu, Min Yang</p><p>9169-9176</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6453/6453-13-9678-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09177-sentiment-classification-in-customer-service-dialogue-with-topic-aware-multi-task-learning/">Sentiment Classification in Customer Service Dialogue with Topic-Aware Multi-Task Learning</a></h5><span class="papers-author-page"><p>Jiancheng Wang, Jingjing Wang, Changlong Sun, Shoushan Li, Xiaozhong Liu, Luo Si, Min Zhang, Guodong Zhou</p><p>9177-9184</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6454/6454-13-9679-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09185-storytelling-from-an-image-stream-using-scene-graphs/">Storytelling from an Image Stream Using Scene Graphs</a></h5><span class="papers-author-page"><p>Ruize Wang, Zhongyu Wei, Piji Li, Qi Zhang, Xuanjing Huang</p><p>9185-9192</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6455/6455-13-9680-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09193-multi-task-self-supervised-learning-for-disfluency-detection/">Multi-Task Self-Supervised Learning for Disfluency Detection</a></h5><span class="papers-author-page"><p>Shaolei Wang, Wangxiang Che, Qi Liu, Pengda Qin, Ting Liu, William Yang Wang</p><p>9193-9200</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6456/6456-13-9681-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09201-probing-brain-activation-patterns-by-dissociating-semantics-and-syntax-in-sentences/">Probing Brain Activation Patterns by Dissociating Semantics and Syntax in Sentences</a></h5><span class="papers-author-page"><p>Shaonan Wang, Jiajun Zhang, Nan Lin, Chengqing Zong</p><p>9201-9208</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6457/6457-13-9682-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09209-multi-level-head-wise-match-and-aggregation-in-transformer-for-textual-sequence-matching/">Multi-Level Head-Wise Match and Aggregation in Transformer for Textual Sequence Matching</a></h5><span class="papers-author-page"><p>Shuohang Wang, Yunshi Lan, Yi Tay, Jing Jiang, Jingjing Liu</p><p>9209-9216</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6458/6458-13-9683-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09217-masking-orchestration-multi-task-pretraining-for-multi-role-dialogue-representation-learning/">Masking Orchestration: Multi-Task Pretraining for Multi-Role Dialogue Representation Learning</a></h5><span class="papers-author-page"><p>Tianyi Wang, Yating Zhang, Xiaozhong Liu, Changlong Sun, Qiong Zhang</p><p>9217-9224</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6459/6459-13-9684-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09225-integrating-deep-learning-with-logic-fusion-for-information-extraction/">Integrating Deep Learning with Logic Fusion for Information Extraction</a></h5><span class="papers-author-page"><p>Wenya Wang, Sinno Jialin Pan</p><p>9225-9232</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6460/6460-13-9685-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09233-go-from-the-general-to-the-particular-multi-domain-translation-with-domain-transformation-networks/">Go From the General to the Particular: Multi-Domain Translation with Domain Transformation Networks</a></h5><span class="papers-author-page"><p>Yong Wang, Longyue Wang, Shuming Shi, Victor O.K. Li, Zhaopeng Tu</p><p>9233-9241</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6461/6461-13-9686-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09242-textnas-a-neural-architecture-search-space-tailored-for-text-representation/">TextNAS: A Neural Architecture Search Space Tailored for Text Representation</a></h5><span class="papers-author-page"><p>Yujing Wang, Yaming Yang, Yiren Chen, Jing Bai, Ce Zhang, Guinan Su, Xiaoyu Kou, Yunhai Tong, Mao Yang, Lidong Zhou</p><p>9242-9249</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6462/6462-13-9687-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09250-learning-multi-level-dependencies-for-robust-word-recognition/">Learning Multi-Level Dependencies for Robust Word Recognition</a></h5><span class="papers-author-page"><p>Zhiwei Wang, Hui Liu, Jiliang Tang, Songfan Yang, Gale Yan Huang, Zitao Liu</p><p>9250-9257</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6463/6463-13-9688-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09258-gret-global-representation-enhanced-transformer/">GRET: Global Representation Enhanced Transformer</a></h5><span class="papers-author-page"><p>Rongxiang Weng, Haoran Wei, Shujian Huang, Heng Yu, Lidong Bing, Weihua Luo, Jiajun Chen</p><p>9258-9265</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6464/6464-13-9689-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09266-acquiring-knowledge-from-pre-trained-model-to-neural-machine-translation/">Acquiring Knowledge from Pre-Trained Model to Neural Machine Translation</a></h5><span class="papers-author-page"><p>Rongxiang Weng, Heng Yu, Shujian Huang, Shanbo Cheng, Weihua Luo</p><p>9266-9273</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6465/6465-13-9690-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09274-enhanced-meta-learning-for-cross-lingual-named-entity-recognition-with-minimal-resources/">Enhanced Meta-Learning for Cross-Lingual Named Entity Recognition with Minimal Resources</a></h5><span class="papers-author-page"><p>Qianhui Wu, Zijia Lin, Guoxin Wang, Hui Chen, Börje F. Karlsson, Biqing Huang, Chin-Yew Lin</p><p>9274-9281</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6466/6466-13-9691-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09282-importance-aware-learning-for-neural-headline-editing/">Importance-Aware Learning for Neural Headline Editing</a></h5><span class="papers-author-page"><p>Qingyang Wu, Lei Li, Hao Zhou, Ying Zeng, Zhou Yu</p><p>9282-9289</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6467/6467-13-9692-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08968-ernie-2-0-a-continual-pre-training-framework-for-language-understanding/">ERNIE 2.0: A Continual Pre-Training Framework for Language Understanding</a></h5><span class="papers-author-page"><p>Yu Sun, Shuohuan Wang, Yukun Li, Shikun Feng, Hao Tian, Hua Wu, Haifeng Wang</p><p>8968-8975</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6428/6428-13-9653-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08976-generating-diverse-translation-by-manipulating-multi-head-attention/">Generating Diverse Translation by Manipulating Multi-Head Attention</a></h5><span class="papers-author-page"><p>Zewei Sun, Shujian Huang, Hao-Ran Wei, Xin-yu Dai, Jiajun Chen</p><p>8976-8983</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6429/6429-13-9654-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08984-treegen-a-tree-based-transformer-architecture-for-code-generation/">TreeGen: A Tree-Based Transformer Architecture for Code Generation</a></h5><span class="papers-author-page"><p>Zeyu Sun, Qihao Zhu, Yingfei Xiong, Yican Sun, Lili Mou, Lu Zhang</p><p>8984-8991</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6430/6430-13-9655-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08992-learning-relationships-between-text-audio-and-video-via-deep-canonical-correlation-for-multimodal-language-analysis/">Learning Relationships between Text, Audio, and Video via Deep Canonical Correlation for Multimodal Language Analysis</a></h5><span class="papers-author-page"><p>Zhongkai Sun, Prathusha Sarma, William Sethares, Yingyu Liang</p><p>8992-8999</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6431/6431-13-9656-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09000-distributed-representations-for-arithmetic-word-problems/">Distributed Representations for Arithmetic Word Problems</a></h5><span class="papers-author-page"><p>Sowmya S Sundaram, Deepak P, Savitha Sam Abraham</p><p>9000-9007</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6432/6432-13-9657-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09008-adapting-language-models-for-non-parallel-author-stylized-rewriting/">Adapting Language Models for Non-Parallel Author-Stylized Rewriting</a></h5><span class="papers-author-page"><p>Bakhtiyar Syed, Gaurav Verma, Balaji Vasan Srinivasan, Anandhavelu Natarajan, Vasudeva Varma</p><p>9008-9015</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6433/6433-13-9658-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09016-boundary-enhanced-neural-span-classification-for-nested-named-entity-recognition/">Boundary Enhanced Neural Span Classification for Nested Named Entity Recognition</a></h5><span class="papers-author-page"><p>Chuanqi Tan, Wei Qiu, Mosha Chen, Rui Wang, Fei Huang</p><p>9016-9023</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6434/6434-13-9659-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09024-multi-label-patent-categorization-with-non-local-attention-based-graph-convolutional-network/">Multi-Label Patent Categorization with Non-Local Attention-Based Graph Convolutional Network</a></h5><span class="papers-author-page"><p>Pingjie Tang, Meng Jiang, Bryan (Ning) Xia, Jed W. Pitera, Jeffrey Welser, Nitesh V. Chawla</p><p>9024-9031</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6435/6435-13-9660-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09032-capturing-sentence-relations-for-answer-sentence-selection-with-multi-perspective-graph-encoding/">Capturing Sentence Relations for Answer Sentence Selection with Multi-Perspective Graph Encoding</a></h5><span class="papers-author-page"><p>Zhixing Tian, Yuanzhe Zhang, Xinwei Feng, Wenbin Jiang, Yajuan Lyu, Kang Liu, Jun Zhao</p><p>9032-9039</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6436/6436-13-9661-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09040-image-enhanced-event-detection-in-news-articles/">Image Enhanced Event Detection in News Articles</a></h5><span class="papers-author-page"><p>Meihan Tong, Shuai Wang, Yixin Cao, Bin Xu, Juanzi Li, Lei Hou, Tat-Seng Chua</p><p>9040-9047</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6437/6437-13-9662-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09048-fine-grained-argument-unit-recognition-and-classification/">Fine-Grained Argument Unit Recognition and Classification</a></h5><span class="papers-author-page"><p>Dietrich Trautmann, Johannes Daxenberger, Christian Stab, Hinrich Schütze, Iryna Gurevych</p><p>9048-9056</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6438/6438-13-9663-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09057-sentence-generation-for-entity-description-with-content-plan-attention/">Sentence Generation for Entity Description with Content-Plan Attention</a></h5><span class="papers-author-page"><p>Bayu Trisedya, Jianzhong Qi, Rui Zhang</p><p>9057-9064</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6439/6439-13-9664-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09065-capturing-greater-context-for-question-generation/">Capturing Greater Context for Question Generation</a></h5><span class="papers-author-page"><p>Luu Anh Tuan, Darsh Shah, Regina Barzilay</p><p>9065-9072</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6440/6440-13-9665-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09073-select-answer-and-explain-interpretable-multi-hop-reading-comprehension-over-multiple-documents/">Select, Answer and Explain: Interpretable Multi-Hop Reading Comprehension over Multiple Documents</a></h5><span class="papers-author-page"><p>Ming Tu, Kevin Huang, Guangtao Wang, Jing Huang, Xiaodong He, Bowen Zhou</p><p>9073-9080</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6441/6441-13-9666-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09081-an-annotated-corpus-of-reference-resolution-for-interpreting-common-grounding/">An Annotated Corpus of Reference Resolution for Interpreting Common Grounding</a></h5><span class="papers-author-page"><p>Takuma Udagawa, Akiko Aizawa</p><p>9081-9089</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6442/6442-13-9667-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09090-a-comparison-of-architectures-and-pretraining-methods-for-contextualized-multilingual-word-embeddings/">A Comparison of Architectures and Pretraining Methods for Contextualized Multilingual Word Embeddings</a></h5><span class="papers-author-page"><p>Niels van der Heijden, Samira Abnar, Ekaterina Shutova</p><p>9090-9097</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6443/6443-13-9668-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09098-a-joint-model-for-definition-extraction-with-syntactic-connection-and-semantic-consistency/">A Joint Model for Definition Extraction with Syntactic Connection and Semantic Consistency</a></h5><span class="papers-author-page"><p>Amir Veyseh, Franck Dernoncourt, Dejing Dou, Thien Nguyen</p><p>9098-9105</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6444/6444-13-9669-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09106-multi-view-consistency-for-relation-extraction-via-mutual-information-and-structure-prediction/">Multi-View Consistency for Relation Extraction via Mutual Information and Structure Prediction</a></h5><span class="papers-author-page"><p>Amir Veyseh, Franck Dernoncourt, My Thai, Dejing Dou, Thien Nguyen</p><p>9106-9113</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6445/6445-13-9670-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09114-parsing-as-pretraining/">Parsing as Pretraining</a></h5><span class="papers-author-page"><p>David Vilares, Michalina Strzyz, Anders Søgaard, Carlos Gómez-Rodríguez</p><p>9114-9121</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6446/6446-13-9671-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/09122-target-aspect-sentiment-joint-detection-for-aspect-based-sentiment-analysis/">Target-Aspect-Sentiment Joint Detection for Aspect-Based Sentiment Analysis</a></h5><span class="papers-author-page"><p>Hai Wan, Yufei Yang, Jianfeng Du, Yanan Liu, Kunxun Qi, Jeff Z. Pan</p><p>9122-9129</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6447/6447-13-9672-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08807-graph-based-transformer-with-cross-candidate-verification-for-semantic-parsing/">Graph-Based Transformer with Cross-Candidate Verification for Semantic Parsing</a></h5><span class="papers-author-page"><p>Bo Shao, Yeyun Gong, Weizhen Qi, Guihong Cao, Jianshu Ji, Xiaola Lin</p><p>8807-8814</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6408/6408-13-9633-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08815-q-bert-hessian-based-ultra-low-precision-quantization-of-bert/">Q-BERT: Hessian Based Ultra Low Precision Quantization of BERT</a></h5><span class="papers-author-page"><p>Sheng Shen, Zhen Dong, Jiayu Ye, Linjian Ma, Zhewei Yao, Amir Gholami, Michael W. Mahoney, Kurt Keutzer</p><p>8815-8821</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6409/6409-13-9634-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08822-on-the-generation-of-medical-question-answer-pairs/">On the Generation of Medical Question-Answer Pairs</a></h5><span class="papers-author-page"><p>Sheng Shen, Yaliang Li, Nan Du, Xian Wu, Yusheng Xie, Shen Ge, Tao Yang, Kai Wang, Xingzheng Liang, Wei Fan</p><p>8822-8829</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6410/6410-13-9635-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08830-introvnmt-an-introspective-model-for-variational-neural-machine-translation/">IntroVNMT: An Introspective Model for Variational Neural Machine Translation</a></h5><span class="papers-author-page"><p>Xin Sheng, Linli Xu, Junliang Guo, Jingchang Liu, Ruoyu Zhao, Yinlong Xu</p><p>8830-8837</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6411/6411-13-9636-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08838-understanding-medical-conversations-with-scattered-keyword-attention-and-weak-supervision-from-responses/">Understanding Medical Conversations with Scattered Keyword Attention and Weak Supervision from Responses</a></h5><span class="papers-author-page"><p>Xiaoming Shi, Haifeng Hu, Wanxiang Che, Zhongqian Sun, Ting Liu, Junzhou Huang</p><p>8838-8845</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6412/6412-13-9637-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08846-latent-variable-non-autoregressive-neural-machine-translation-with-deterministic-inference-using-a-delta-posterior/">Latent-Variable Non-Autoregressive Neural Machine Translation with Deterministic Inference Using a Delta Posterior</a></h5><span class="papers-author-page"><p>Raphael Shu, Jason Lee, Hideki Nakayama, Kyunghyun Cho</p><p>8846-8853</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6413/6413-13-9638-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08854-evaluating-the-cross-lingual-effectiveness-of-massively-multilingual-neural-machine-translation/">Evaluating the Cross-Lingual Effectiveness of Massively Multilingual Neural Machine Translation</a></h5><span class="papers-author-page"><p>Aditya Siddhant, Melvin Johnson, Henry Tsai, Naveen Ari, Jason Riesa, Ankur Bapna, Orhan Firat, Karthik Raman</p><p>8854-8861</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6414/6414-13-9639-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08862-low-resource-sequence-tagging-with-weak-labels/">Low Resource Sequence Tagging with Weak Labels</a></h5><span class="papers-author-page"><p>Edwin Simpson, Jonas Pfeiffer, Iryna Gurevych</p><p>8862-8869</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6415/6415-13-9640-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08870-modelling-form-meaning-systematicity-with-linguistic-and-visual-features/">Modelling Form-Meaning Systematicity with Linguistic and Visual Features</a></h5><span class="papers-author-page"><p>Arie Soeteman, Dario Gutierrez, Elia Bruni, Ekaterina Shutova</p><p>8870-8877</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6416/6416-13-9641-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08878-generating-persona-consistent-dialogues-by-exploiting-natural-language-inference/">Generating Persona Consistent Dialogues by Exploiting Natural Language Inference</a></h5><span class="papers-author-page"><p>Haoyu Song, Wei-Nan Zhang, Jingwen Hu, Ting Liu</p><p>8878-8885</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6417/6417-13-9642-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08886-alignment-enhanced-transformer-for-constraining-nmt-with-pre-specified-translations/">Alignment-Enhanced Transformer for Constraining NMT with Pre-Specified Translations</a></h5><span class="papers-author-page"><p>Kai Song, Kun Wang, Heng Yu, Yue Zhang, Zhongqiang Huang, Weihua Luo, Xiangyu Duan, Min Zhang</p><p>8886-8893</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6418/6418-13-9643-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08894-joint-parsing-and-generation-for-abstractive-summarization/">Joint Parsing and Generation for Abstractive Summarization</a></h5><span class="papers-author-page"><p>Kaiqiang Song, Logan Lebanoff, Qipeng Guo, Xipeng Qiu, Xiangyang Xue, Chen Li, Dong Yu, Fei Liu</p><p>8894-8901</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6419/6419-13-9644-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08902-controlling-the-amount-of-verbatim-copying-in-abstractive-summarization/">Controlling the Amount of Verbatim Copying in Abstractive Summarization</a></h5><span class="papers-author-page"><p>Kaiqiang Song, Bingqing Wang, Zhe Feng, Ren Liu, Fei Liu</p><p>8902-8909</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6420/6420-13-9645-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08910-attractive-or-faithful-popularity-reinforced-learning-for-inspired-headline-generation/">Attractive or Faithful? Popularity-Reinforced Learning for Inspired Headline Generation</a></h5><span class="papers-author-page"><p>Yun-Zhu Song, Hong-Han Shuai, Sung-Lin Yeh, Yi-Lun Wu, Lun-Wei Ku, Wen-Chih Peng</p><p>8910-8917</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6421/6421-13-9646-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08918-assessing-the-benchmarking-capacity-of-machine-reading-comprehension-datasets/">Assessing the Benchmarking Capacity of Machine Reading Comprehension Datasets</a></h5><span class="papers-author-page"><p>Saku Sugawara, Pontus Stenetorp, Kentaro Inui, Akiko Aizawa</p><p>8918-8927</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6422/6422-13-9647-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08928-relation-extraction-with-convolutional-network-over-learnable-syntax-transport-graph/">Relation Extraction with Convolutional Network over Learnable Syntax-Transport Graph</a></h5><span class="papers-author-page"><p>Kai Sun, Richong Zhang, Yongyi Mao, Samuel Mensah, Xudong Liu</p><p>8928-8935</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6423/6423-13-9648-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08936-learning-sparse-sharing-architectures-for-multiple-tasks/">Learning Sparse Sharing Architectures for Multiple Tasks</a></h5><span class="papers-author-page"><p>Tianxiang Sun, Yunfan Shao, Xiaonan Li, Pengfei Liu, Hang Yan, Xipeng Qiu, Xuanjing Huang</p><p>8936-8943</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6424/6424-13-9649-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08944-history-adaption-knowledge-incorporation-mechanism-for-multi-turn-dialogue-system/">History-Adaption Knowledge Incorporation Mechanism for Multi-Turn Dialogue System</a></h5><span class="papers-author-page"><p>Yajing Sun, Yue Hu, Luxi Xing, Jing Yu, Yuqiang Xie</p><p>8944-8951</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6425/6425-13-9650-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08952-sparqa-skeleton-based-semantic-parsing-for-complex-questions-over-knowledge-bases/">SPARQA: Skeleton-Based Semantic Parsing for Complex Questions over Knowledge Bases</a></h5><span class="papers-author-page"><p>Yawei Sun, Lingling Zhang, Gong Cheng, Yuzhong Qu</p><p>8952-8959</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6426/6426-13-9651-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08960-neural-semantic-parsing-in-low-resource-settings-with-back-translation-and-meta-learning/">Neural Semantic Parsing in Low-Resource Settings with Back-Translation and Meta-Learning</a></h5><span class="papers-author-page"><p>Yibo Sun, Duyu Tang, Nan Duan, Yeyun Gong, Xiaocheng Feng, Bing Qin, Daxin Jiang</p><p>8960-8967</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6427/6427-13-9652-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08640-solving-sequential-text-classification-as-board-game-playing/">Solving Sequential Text Classification as Board-Game Playing</a></h5><span class="papers-author-page"><p>Chen Qian, Fuli Feng, Lijie Wen, Zhenpeng Chen, Li Lin, Yanan Zheng, Tat-Seng Chua</p><p>8640-8648</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6388/6388-13-9613-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08649-lexical-simplification-with-pretrained-encoders/">Lexical Simplification with Pretrained Encoders</a></h5><span class="papers-author-page"><p>Jipeng Qiang, Yun Li, Yi Zhu, Yunhao Yuan, Xindong Wu</p><p>8649-8656</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6389/6389-13-9614-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08657-dynamic-knowledge-routing-network-for-target-guided-open-domain-conversation/">Dynamic Knowledge Routing Network for Target-Guided Open-Domain Conversation</a></h5><span class="papers-author-page"><p>Jinghui Qin, Zheng Ye, Jianheng Tang, Xiaodan Liang</p><p>8657-8664</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6390/6390-13-9615-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08665-dcr-net-a-deep-co-interactive-relation-network-for-joint-dialog-act-recognition-and-sentiment-classification/">DCR-Net: A Deep Co-Interactive Relation Network for Joint Dialog Act Recognition and Sentiment Classification</a></h5><span class="papers-author-page"><p>Libo Qin, Wanxiang Che, Yangming Li, Mingheng Ni, Ting Liu</p><p>8665-8672</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6391/6391-13-9616-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08673-generative-adversarial-zero-shot-relational-learning-for-knowledge-graphs/">Generative Adversarial Zero-Shot Relational Learning for Knowledge Graphs</a></h5><span class="papers-author-page"><p>Pengda Qin, Xin Wang, Wenhu Chen, Chunyun Zhang, Weiran Xu, William Yang Wang</p><p>8673-8680</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6392/6392-13-9617-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08681-entrainment2vec-embedding-entrainment-for-multi-party-dialogues/">Entrainment2Vec: Embedding Entrainment for Multi-Party Dialogues</a></h5><span class="papers-author-page"><p>Zahra Rahimi, Diane Litman</p><p>8681-8688</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6393/6393-13-9618-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08689-towards-scalable-multi-domain-conversational-agents-the-schema-guided-dialogue-dataset/">Towards Scalable Multi-Domain Conversational Agents: The Schema-Guided Dialogue Dataset</a></h5><span class="papers-author-page"><p>Abhinav Rastogi, Xiaoxue Zang, Srinivas Sunkara, Raghav Gupta, Pranav Khaitan</p><p>8689-8696</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6394/6394-13-9619-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08697-thinking-globally-acting-locally-distantly-supervised-global-to-local-knowledge-selection-for-background-based-conversation/">Thinking Globally, Acting Locally: Distantly Supervised Global-to-Local Knowledge Selection for Background Based Conversation</a></h5><span class="papers-author-page"><p>Pengjie Ren, Zhumin Chen, Christof Monz, Jun Ma, Maarten de Rijke</p><p>8697-8704</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6395/6395-13-9620-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08705-multi-task-learning-with-generative-adversarial-training-for-multi-passage-machine-reading-comprehension/">Multi-Task Learning with Generative Adversarial Training for Multi-Passage Machine Reading Comprehension</a></h5><span class="papers-author-page"><p>Qiyu Ren, Xiang Cheng, Sen Su</p><p>8705-8712</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6396/6396-13-9621-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08713-probing-natural-language-inference-models-through-semantic-fragments/">Probing Natural Language Inference Models through Semantic Fragments</a></h5><span class="papers-author-page"><p>Kyle Richardson, Hai Hu, Lawrence Moss, Ashish Sabharwal</p><p>8713-8721</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6397/6397-13-9622-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08722-getting-closer-to-ai-complete-question-answering-a-set-of-prerequisite-real-tasks/">Getting Closer to AI Complete Question Answering: A Set of Prerequisite Real Tasks</a></h5><span class="papers-author-page"><p>Anna Rogers, Olga Kovaleva, Matthew Downey, Anna Rumshisky</p><p>8722-8731</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6398/6398-13-9623-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08732-winogrande-an-adversarial-winograd-schema-challenge-at-scale/">WinoGrande: An Adversarial Winograd Schema Challenge at Scale</a></h5><span class="papers-author-page"><p>Keisuke Sakaguchi, Ronan Le Bras, Chandra Bhagavatula, Yejin Choi</p><p>8732-8740</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6399/6399-13-9624-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08741-hierarchical-reinforcement-learning-for-open-domain-dialog/">Hierarchical Reinforcement Learning for Open-Domain Dialog</a></h5><span class="papers-author-page"><p>Abdelrhman Saleh, Natasha Jaques, Asma Ghandeharioun, Judy Shen, Rosalind Picard</p><p>8741-8748</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6400/6400-13-9625-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08749-casie-extracting-cybersecurity-event-information-from-text/">CASIE: Extracting Cybersecurity Event Information from Text</a></h5><span class="papers-author-page"><p>Taneeya Satyapanich, Francis Ferraro, Tim Finin</p><p>8749-8757</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6401/6401-13-9626-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08758-sensembert-context-enhanced-sense-embeddings-for-multilingual-word-sense-disambiguation/">SensEmBERT: Context-Enhanced Sense Embeddings for Multilingual Word Sense Disambiguation</a></h5><span class="papers-author-page"><p>Bianca Scarlini, Tommaso Pasini, Roberto Navigli</p><p>8758-8765</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6402/6402-13-9627-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08766-rare-words-a-major-problem-for-contextualized-embeddings-and-how-to-fix-it-by-attentive-mimicking/">Rare Words: A Major Problem for Contextualized Embeddings and How to Fix it by Attentive Mimicking</a></h5><span class="papers-author-page"><p>Timo Schick, Hinrich Schütze</p><p>8766-8774</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6403/6403-13-9628-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08775-can-embeddings-adequately-represent-medical-terminology-new-large-scale-medical-term-similarity-datasets-have-the-answer/">Can Embeddings Adequately Represent Medical Terminology? New Large-Scale Medical Term Similarity Datasets Have the Answer!</a></h5><span class="papers-author-page"><p>Claudia Schulz, Damir Juric</p><p>8775-8782</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6404/6404-13-9629-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08783-interpretable-rumor-detection-in-microblogs-by-attending-to-user-interactions/">Interpretable Rumor Detection in Microblogs by Attending to User Interactions</a></h5><span class="papers-author-page"><p>Ling Min Serena Khoo, Hai Leong Chieu, Zhong Qian, Jing Jiang</p><p>8783-8790</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6405/6405-13-9630-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08791-automatic-fact-guided-sentence-modification/">Automatic Fact-Guided Sentence Modification</a></h5><span class="papers-author-page"><p>Darsh Shah, Tal Schuster, Regina Barzilay</p><p>8791-8798</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6406/6406-13-9631-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08799-are-noisy-sentences-useless-for-distant-supervised-relation-extraction/">Are Noisy Sentences Useless for Distant Supervised Relation Extraction?</a></h5><span class="papers-author-page"><p>Yuming Shang, He-Yan Huang, Xian-Ling Mao, Xin Sun, Wei Wei</p><p>8799-8806</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6407/6407-13-9632-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08480-robust-named-entity-recognition-with-truecasing-pretraining/">Robust Named Entity Recognition with Truecasing Pretraining</a></h5><span class="papers-author-page"><p>Stephen Mayhew, Gupta Nitish, Dan Roth</p><p>8480-8487</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6368/6368-13-9593-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08488-simplify-then-translate-automatic-preprocessing-for-black-box-translation/">Simplify-Then-Translate: Automatic Preprocessing for Black-Box Translation</a></h5><span class="papers-author-page"><p>Sneha Mehta, Bahareh Azarnoush, Boris Chen, Avneesh Saluja, Vinith Misra, Ballav Bihani, Ritwik Kumar</p><p>8488-8495</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6369/6369-13-9594-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08496-refnet-a-reference-aware-network-for-background-based-conversation/">RefNet: A Reference-Aware Network for Background Based Conversation</a></h5><span class="papers-author-page"><p>Chuan Meng, Pengjie Ren, Zhumin Chen, Christof Monz, Jun Ma, Maarten de Rijke</p><p>8496-8503</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6370/6370-13-9595-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08504-enhancing-natural-language-inference-using-new-and-expanded-training-data-sets-and-new-learning-models/">Enhancing Natural Language Inference Using New and Expanded Training Data Sets and New Learning Models</a></h5><span class="papers-author-page"><p>Arindam Mitra, Ishan Shrivastava, Chitta Baral</p><p>8504-8511</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6371/6371-13-9596-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08512-trendnert-a-benchmark-for-trend-and-downtrend-detection-in-a-scientific-domain/">TRENDNERT: A Benchmark for Trend and Downtrend Detection in a Scientific Domain</a></h5><span class="papers-author-page"><p>Alena Moiseeva, Hinrich Schütze</p><p>8512-8519</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6372/6372-13-9597-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08520-conclusion-supplement-answer-generation-for-non-factoid-questions/">Conclusion-Supplement Answer Generation for Non-Factoid Questions</a></h5><span class="papers-author-page"><p>Makoto Nakatsuji, Sohei Okui</p><p>8520-8527</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6373/6373-13-9598-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08528-effective-modeling-of-encoder-decoder-architecture-for-joint-entity-and-relation-extraction/">Effective Modeling of Encoder-Decoder Architecture for Joint Entity and Relation Extraction</a></h5><span class="papers-author-page"><p>Tapas Nayak, Hwee Tou Ng</p><p>8528-8535</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6374/6374-13-9599-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08536-merging-weak-and-active-supervision-for-semantic-parsing/">Merging Weak and Active Supervision for Semantic Parsing</a></h5><span class="papers-author-page"><p>Ansong Ni, Pengcheng Yin, Graham Neubig</p><p>8536-8543</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6375/6375-13-9600-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08544-message-passing-attention-networks-for-document-understanding/">Message Passing Attention Networks for Document Understanding</a></h5><span class="papers-author-page"><p>Giannis Nikolentzos, Antoine Tixier, Michalis Vazirgiannis</p><p>8544-8551</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6376/6376-13-9601-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08552-deep-residual-dense-lattice-network-for-speech-enhancement/">Deep Residual-Dense Lattice Network for Speech Enhancement</a></h5><span class="papers-author-page"><p>Mohammad Nikzad, Aaron Nicolson, Yongsheng Gao, Jun Zhou, Kuldip K. Paliwal, Fanhua Shang</p><p>8552-8559</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6377/6377-13-9602-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08560-avgout-a-simple-output-probability-measure-to-eliminate-dull-responses/">AvgOut: A Simple Output-Probability Measure to Eliminate Dull Responses</a></h5><span class="papers-author-page"><p>Tong Niu, Mohit Bansal</p><p>8560-8567</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6378/6378-13-9603-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08568-controlling-neural-machine-translation-formality-with-synthetic-supervision/">Controlling Neural Machine Translation Formality with Synthetic Supervision</a></h5><span class="papers-author-page"><p>Xing Niu, Marine Carpuat</p><p>8568-8575</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6379/6379-13-9604-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08576-fine-grained-entity-typing-for-domain-independent-entity-linking/">Fine-Grained Entity Typing for Domain Independent Entity Linking</a></h5><span class="papers-author-page"><p>Yasumasa Onoe, Greg Durrett</p><p>8576-8583</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6380/6380-13-9605-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08584-mask-focus-conversation-modelling-by-learning-concepts/">Mask &#038; Focus: Conversation Modelling by Learning Concepts</a></h5><span class="papers-author-page"><p>Gaurav Pandey, Dinesh Raghu, Sachindra Joshi</p><p>8584-8591</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6381/6381-13-9606-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08592-associating-natural-language-comment-and-source-code-entities/">Associating Natural Language Comment and Source Code Entities</a></h5><span class="papers-author-page"><p>Sheena Panthaplackel, Milos Gligoric, Raymond J. Mooney, Junyi Jessy Li</p><p>8592-8599</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6382/6382-13-9607-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08600-knowing-what-how-and-why-a-near-complete-solution-for-aspect-based-sentiment-analysis/">Knowing What, How and Why: A Near Complete Solution for Aspect-Based Sentiment Analysis</a></h5><span class="papers-author-page"><p>Haiyun Peng, Lu Xu, Lidong Bing, Fei Huang, Wei Lu, Luo Si</p><p>8600-8607</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6383/6383-13-9608-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08608-mtss-learn-from-multiple-domain-teachers-and-become-a-multi-domain-dialogue-expert/">MTSS: Learn from Multiple Domain Teachers and Become a Multi-Domain Dialogue Expert</a></h5><span class="papers-author-page"><p>Shuke Peng, Feng Ji, Zehao Lin, Shaobo Cui, Haiqing Chen, Yin Zhang</p><p>8608-8615</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6384/6384-13-9609-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08616-verb-class-induction-with-partial-supervision/">Verb Class Induction with Partial Supervision</a></h5><span class="papers-author-page"><p>Daniel Peterson, Susan Brown, Martha Palmer</p><p>8616-8623</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6385/6385-13-9610-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08624-towards-building-a-multilingual-sememe-knowledge-base-predicting-sememes-for-babelnet-synsets/">Towards Building a Multilingual Sememe Knowledge Base: Predicting Sememes for BabelNet Synsets</a></h5><span class="papers-author-page"><p>Fanchao Qi, Liang Chang, Maosong Sun, Sicong Ouyang, Zhiyuan Liu</p><p>8624-8631</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6386/6386-13-9611-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08632-translation-based-matching-adversarial-network-for-cross-lingual-natural-language-inference/">Translation-Based Matching Adversarial Network for Cross-Lingual Natural Language Inference</a></h5><span class="papers-author-page"><p>Kunxun Qi, Jianfeng Du</p><p>8632-8639</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6387/6387-13-9612-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08319-global-greedy-dependency-parsing/">Global Greedy Dependency Parsing</a></h5><span class="papers-author-page"><p>Zuchao Li, Hai Zhao, Kevin Parnow</p><p>8319-8326</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6348/6348-13-9573-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08327-moss-end-to-end-dialog-system-framework-with-modular-supervision/">MOSS: End-to-End Dialog System Framework with Modular Supervision</a></h5><span class="papers-author-page"><p>Weixin Liang, Youzhi Tian, Chengcai Chen, Zhou Yu</p><p>8327-8335</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6349/6349-13-9574-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08336-embedding-compression-with-isotropic-iterative-quantization/">Embedding Compression with Isotropic Iterative Quantization</a></h5><span class="papers-author-page"><p>Siyu Liao, Jie Chen, Yanzhi Wang, Qinru Qiu, Bo Yuan</p><p>8336-8343</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6350/6350-13-9575-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08344-semi-supervised-learning-on-meta-structure-multi-task-tagging-and-parsing-in-low-resource-scenarios/">Semi-Supervised Learning on Meta Structure: Multi-Task Tagging and Parsing in Low-Resource Scenarios</a></h5><span class="papers-author-page"><p>KyungTae Lim, Jay Yoon Lee, Jaime Carbonell, Thierry Poibeau</p><p>8344-8351</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6351/6351-13-9576-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08352-hierarchical-attention-network-with-pairwise-loss-for-chinese-zero-pronoun-resolution/">Hierarchical Attention Network with Pairwise Loss for Chinese Zero Pronoun Resolution</a></h5><span class="papers-author-page"><p>Peiqin Lin, Meng Yang</p><p>8352-8359</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6352/6352-13-9577-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08360-discovering-new-intents-via-constrained-deep-adaptive-clustering-with-cluster-refinement/">Discovering New Intents via Constrained Deep Adaptive Clustering with Cluster Refinement</a></h5><span class="papers-author-page"><p>Ting-En Lin, Hua Xu, Hanlei Zhang</p><p>8360-8367</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6353/6353-13-9578-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08368-integrating-linguistic-knowledge-to-sentence-paraphrase-generation/">Integrating Linguistic Knowledge to Sentence Paraphrase Generation</a></h5><span class="papers-author-page"><p>Zibo Lin, Ziran Li, Ning Ding, Hai-Tao Zheng, Ying Shen, Wei Wang, Cong-Zhi Zhao</p><p>8368-8375</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6354/6354-13-9579-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08376-revision-in-continuous-space-unsupervised-text-style-transfer-without-adversarial-learning/">Revision in Continuous Space: Unsupervised Text Style Transfer without Adversarial Learning</a></h5><span class="papers-author-page"><p>Dayiheng Liu, Jie Fu, Yidan Zhang, Chris Pal, Jiancheng Lv</p><p>8376-8383</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6355/6355-13-9580-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08384-joint-character-level-word-embedding-and-adversarial-stability-training-to-defend-adversarial-text/">Joint Character-Level Word Embedding and Adversarial Stability Training to Defend Adversarial Text</a></h5><span class="papers-author-page"><p>Hui Liu, Yongzheng Zhang, Yipeng Wang, Zheng Lin, Yige Chen</p><p>8384-8391</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6356/6356-13-9581-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08392-a-robust-adversarial-training-approach-to-machine-reading-comprehension/">A Robust Adversarial Training Approach to Machine Reading Comprehension</a></h5><span class="papers-author-page"><p>Kai Liu, Xin Liu, An Yang, Jing Liu, Jinsong Su, Sujian Li, Qiaoqiao She</p><p>8392-8400</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6357/6357-13-9582-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08401-hamner-headword-amplified-multi-span-distantly-supervised-method-for-domain-specific-named-entity-recognition/">HAMNER: Headword Amplified Multi-Span Distantly Supervised Method for Domain Specific Named Entity Recognition</a></h5><span class="papers-author-page"><p>Shifeng Liu, Yifang Sun, Bing Li, Wei Wang, Xiang Zhao</p><p>8401-8408</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6358/6358-13-9583-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08409-tensor-graph-convolutional-networks-for-text-classification/">Tensor Graph Convolutional Networks for Text Classification</a></h5><span class="papers-author-page"><p>Xien Liu, Xinxin You, Xiao Zhang, Ji Wu, Ping Lv</p><p>8409-8416</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6359/6359-13-9584-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08417-synchronous-speech-recognition-and-speech-to-text-translation-with-interactive-decoding/">Synchronous Speech Recognition and Speech-to-Text Translation with Interactive Decoding</a></h5><span class="papers-author-page"><p>Yuchen Liu, Jiajun Zhang, Hao Xiong, Long Zhou, Zhongjun He, Hua Wu, Haifeng Wang, Chengqing Zong</p><p>8417-8424</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6360/6360-13-9585-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08425-catgan-category-aware-generative-adversarial-networks-with-hierarchical-evolutionary-learning-for-category-text-generation/">CatGAN: Category-Aware Generative Adversarial Networks with Hierarchical Evolutionary Learning for Category Text Generation</a></h5><span class="papers-author-page"><p>Zhiyue Liu, Jiahai Wang, Zhiwei Liang</p><p>8425-8432</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6361/6361-13-9586-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08433-attention-informed-mixed-language-training-for-zero-shot-cross-lingual-task-oriented-dialogue-systems/">Attention-Informed Mixed-Language Training for Zero-Shot Cross-Lingual Task-Oriented Dialogue Systems</a></h5><span class="papers-author-page"><p>Zihan Liu, Genta Indra Winata, Zhaojiang Lin, Peng Xu, Pascale Fung</p><p>8433-8440</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6362/6362-13-9587-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08441-hierarchical-contextualized-representation-for-named-entity-recognition/">Hierarchical Contextualized Representation for Named Entity Recognition</a></h5><span class="papers-author-page"><p>Ying Luo, Fengshun Xiao, Hai Zhao</p><p>8441-8448</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6363/6363-13-9588-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08449-graph-based-reasoning-over-heterogeneous-external-knowledge-for-commonsense-question-answering/">Graph-Based Reasoning over Heterogeneous External Knowledge for Commonsense Question Answering</a></h5><span class="papers-author-page"><p>Shangwen Lv, Daya Guo, Jingjing Xu, Duyu Tang, Nan Duan, Ming Gong, Linjun Shou, Daxin Jiang, Guihong Cao, Songlin Hu</p><p>8449-8456</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6364/6364-13-9589-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08457-fpets-fully-parallel-end-to-end-text-to-speech-system/">FPETS: Fully Parallel End-to-End Text-to-Speech System</a></h5><span class="papers-author-page"><p>Dabiao Ma, Zhiba Su, Wenxuan Wang, Yuhao Lu</p><p>8457-8463</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6365/6365-13-9590-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08464-improving-question-generation-with-sentence-level-semantic-matching-and-answer-position-inferring/">Improving Question Generation with Sentence-Level Semantic Matching and Answer Position Inferring</a></h5><span class="papers-author-page"><p>Xiyao Ma, Qile Zhu, Yanlin Zhou, Xiaolin Li</p><p>8464-8471</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6366/6366-13-9591-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08472-cawa-an-attention-network-for-credit-attribution/">CAWA: An Attention-Network for Credit Attribution</a></h5><span class="papers-author-page"><p>Saurav Manchanda, George Karypis</p><p>8472-8479</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6367/6367-13-9592-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08155-aloha-artificial-learning-of-human-attributes-for-dialogue-agents/">ALOHA: Artificial Learning of Human Attributes for Dialogue Agents</a></h5><span class="papers-author-page"><p>Aaron W. Li, Veronica Jiang, Steven Y. Feng, Julia Sprague, Wei Zhou, Jesse Hoey</p><p>8155-8163</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6328/6328-13-9553-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08164-recursively-binary-modification-model-for-nested-named-entity-recognition/">Recursively Binary Modification Model for Nested Named Entity Recognition</a></h5><span class="papers-author-page"><p>Bing Li, Shifeng Liu, Yifang Sun, Wei Wang, Xiang Zhao</p><p>8164-8171</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6329/6329-13-9554-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08172-grapher-token-centric-entity-resolution-with-graph-convolutional-neural-networks/">GraphER: Token-Centric Entity Resolution with Graph Convolutional Neural Networks</a></h5><span class="papers-author-page"><p>Bing Li, Wei Wang, Yifang Sun, Linhan Zhang, Muhammad Asif Ali, Yi Wang</p><p>8172-8179</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6330/6330-13-9555-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08180-icd-coding-from-clinical-text-using-multi-filter-residual-convolutional-neural-network/">ICD Coding from Clinical Text Using Multi-Filter Residual Convolutional Neural Network</a></h5><span class="papers-author-page"><p>Fei Li, Hong Yu</p><p>8180-8187</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6331/6331-13-9556-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08188-aspect-aware-multimodal-summarization-for-chinese-e-commerce-products/">Aspect-Aware Multimodal Summarization for Chinese E-Commerce Products</a></h5><span class="papers-author-page"><p>Haoran Li, Peng Yuan, Song Xu, Youzheng Wu, Xiaodong He, Bowen Zhou</p><p>8188-8195</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6332/6332-13-9557-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08196-keywords-guided-abstractive-sentence-summarization/">Keywords-Guided Abstractive Sentence Summarization</a></h5><span class="papers-author-page"><p>Haoran Li, Junnan Zhu, Jiajun Zhang, Chengqing Zong, Xiaodong He</p><p>8196-8203</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6333/6333-13-9558-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08204-neuron-interaction-based-representation-composition-for-neural-machine-translation/">Neuron Interaction Based Representation Composition for Neural Machine Translation</a></h5><span class="papers-author-page"><p>Jian Li, Xing Wang, Baosong Yang, Shuming Shi, Michael R. Lyu, Zhaopeng Tu</p><p>8204-8211</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6334/6334-13-9559-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08212-cross-lingual-low-resource-set-to-description-retrieval-for-global-e-commerce/">Cross-Lingual Low-Resource Set-to-Description Retrieval for Global E-Commerce</a></h5><span class="papers-author-page"><p>Juntao Li, Chang Liu, Jian Wang, Lidong Bing, Hongsong Li, Xiaozhong Liu, Dongyan Zhao, Rui Yan</p><p>8212-8219</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6335/6335-13-9560-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08220-simultaneous-learning-of-pivots-and-representations-for-cross-domain-sentiment-classification/">Simultaneous Learning of Pivots and Representations for Cross-Domain Sentiment Classification</a></h5><span class="papers-author-page"><p>Liang Li, Weirui Ye, Mingsheng Long, Yateng Tang, Jin Xu, Jianmin Wang</p><p>8220-8227</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6336/6336-13-9561-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08228-robutrans-a-robust-transformer-based-text-to-speech-model/">RobuTrans: A Robust Transformer-Based Text-to-Speech Model</a></h5><span class="papers-author-page"><p>Naihan Li, Yanqing Liu, Yu Wu, Shujie Liu, Sheng Zhao, Ming Liu</p><p>8228-8235</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6337/6337-13-9562-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08236-why-attention-analyze-bilstm-deficiency-and-its-remedies-in-the-case-of-ner/">Why Attention? Analyze BiLSTM Deficiency and Its Remedies in the Case of NER</a></h5><span class="papers-author-page"><p>Peng-Hsuan Li, Tsu-Jui Fu, Wei-Yun Ma</p><p>8236-8244</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6338/6338-13-9563-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08245-metamt-a-meta-learning-method-leveraging-multiple-domain-data-for-low-resource-machine-translation/">MetaMT, a Meta Learning Method Leveraging Multiple Domain Data for Low Resource Machine Translation</a></h5><span class="papers-author-page"><p>Rumeng Li, Xun Wang, Hong Yu</p><p>8245-8252</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6339/6339-13-9564-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08253-relevance-promoting-language-model-for-short-text-conversation/">Relevance-Promoting Language Model for Short-Text Conversation</a></h5><span class="papers-author-page"><p>Xin Li, Piji Li, Wei Bi, Xiaojiang Liu, Wai Lam</p><p>8253-8260</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6340/6340-13-9565-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08261-towards-zero-shot-learning-for-automatic-phonemic-transcription/">Towards Zero-Shot Learning for Automatic Phonemic Transcription</a></h5><span class="papers-author-page"><p>Xinjian Li, Siddharth Dalmia, David Mortensen, Juncheng Li, Alan Black, Florian Metze</p><p>8261-8268</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6341/6341-13-9566-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08269-self-attention-enhanced-selective-gate-with-entity-aware-embedding-for-distantly-supervised-relation-extraction/">Self-Attention Enhanced Selective Gate with Entity-Aware Embedding for Distantly Supervised Relation Extraction</a></h5><span class="papers-author-page"><p>Yang Li, Guodong Long, Tao Shen, Tianyi Zhou, Lina Yao, Huan Huo, Jing Jiang</p><p>8269-8276</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6342/6342-13-9567-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08277-span-based-neural-buffer-towards-efficient-and-effective-utilization-of-long-distance-context-for-neural-sequence-models/">Span-Based Neural Buffer: Towards Efficient and Effective Utilization of Long-Distance Context for Neural Sequence Models</a></h5><span class="papers-author-page"><p>Yangming Li, Kaisheng Yao, Libo Qin, Shuang Peng, Yijia Liu, Xiaolong Li</p><p>8277-8284</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6343/6343-13-9568-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08285-neural-machine-translation-with-joint-representation/">Neural Machine Translation with Joint Representation</a></h5><span class="papers-author-page"><p>Yanyang Li, Qiang Wang, Tong Xiao, Tongran Liu, Jingbo Zhu</p><p>8285-8292</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6344/6344-13-9569-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08293-end-to-end-trainable-non-collaborative-dialog-system/">End-to-End Trainable Non-Collaborative Dialog System</a></h5><span class="papers-author-page"><p>Yu Li, Kun Qian, Weiyan Shi, Zhou Yu</p><p>8293-8302</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6345/6345-13-9570-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08303-complementary-auxiliary-classifiers-for-label-conditional-text-generation/">Complementary Auxiliary Classifiers for Label-Conditional Text Generation</a></h5><span class="papers-author-page"><p>Yuan Li, Chunyuan Li, Yizhe Zhang, Xiujun Li, Guoqing Zheng, Lawrence Carin, Jianfeng Gao</p><p>8303-8310</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6346/6346-13-9571-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08311-explicit-sentence-compression-for-neural-machine-translation/">Explicit Sentence Compression for Neural Machine Translation</a></h5><span class="papers-author-page"><p>Zuchao Li, Rui Wang, Kehai Chen, Masao Utiyama, Eiichiro Sumita, Zhuosheng Zhang, Hai Zhao</p><p>8311-8318</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6347/6347-13-9572-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07994-bayes-adaptive-monte-carlo-planning-and-learning-for-goal-oriented-dialogues/">Bayes-Adaptive Monte-Carlo Planning and Learning for Goal-Oriented Dialogues</a></h5><span class="papers-author-page"><p>Youngsoo Jang, Jongmin Lee, Kee-Eung Kim</p><p>7994-8001</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6308/6308-13-9533-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08002-real-time-emotion-recognition-via-attention-gated-hierarchical-memory-network/">Real-Time Emotion Recognition via Attention Gated Hierarchical Memory Network</a></h5><span class="papers-author-page"><p>Wenxiang Jiao, Michael Lyu, Irwin King</p><p>8002-8009</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6309/6309-13-9534-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08010-mmm-multi-stage-multi-task-learning-for-multi-choice-reading-comprehension/">MMM: Multi-Stage Multi-Task Learning for Multi-Choice Reading Comprehension</a></h5><span class="papers-author-page"><p>Di Jin, Shuyang Gao, Jiun-Yu Kao, Tagyoung Chung, Dilek Hakkani-tur</p><p>8010-8017</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6310/6310-13-9535-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08018-is-bert-really-robust-a-strong-baseline-for-natural-language-attack-on-text-classification-and-entailment/">Is BERT Really Robust? A Strong Baseline for Natural Language Attack on Text Classification and Entailment</a></h5><span class="papers-author-page"><p>Di Jin, Zhijing Jin, Joey Tianyi Zhou, Peter Szolovits</p><p>8018-8025</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6311/6311-13-9536-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08026-semsum-semantic-dependency-guided-neural-abstractive-summarization/">SemSUM: Semantic Dependency Guided Neural Abstractive Summarization</a></h5><span class="papers-author-page"><p>Hanqi Jin, Tianming Wang, Xiaojun Wan</p><p>8026-8033</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6312/6312-13-9537-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08034-relation-extraction-exploiting-full-dependency-forests/">Relation Extraction Exploiting Full Dependency Forests</a></h5><span class="papers-author-page"><p>Lifeng Jin, Linfeng Song, Yue Zhang, Kun Xu, Wei-Yun Ma, Dong Yu</p><p>8034-8041</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6313/6313-13-9538-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08042-monolingual-transfer-learning-via-bilingual-translators-for-style-sensitive-paraphrase-generation/">Monolingual Transfer Learning via Bilingual Translators for Style-Sensitive Paraphrase Generation</a></h5><span class="papers-author-page"><p>Tomoyuki Kajiwara, Biwa Miura, Yuki Arase</p><p>8042-8049</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6314/6314-13-9539-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08050-syntactically-look-ahead-attention-network-for-sentence-compression/">Syntactically Look-Ahead Attention Network for Sentence Compression</a></h5><span class="papers-author-page"><p>Hidetaka Kamigaito, Manabu Okumura</p><p>8050-8057</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6315/6315-13-9540-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08058-learning-to-learn-morphological-inflection-for-resource-poor-languages/">Learning to Learn Morphological Inflection for Resource-Poor Languages</a></h5><span class="papers-author-page"><p>Katharina Kann, Samuel R. Bowman, Kyunghyun Cho</p><p>8058-8065</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6316/6316-13-9541-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08066-weakly-supervised-pos-taggers-perform-poorly-on-em-truly-em-low-resource-languages/">Weakly Supervised POS Taggers Perform Poorly on <em>Truly</em> Low-Resource Languages</a></h5><span class="papers-author-page"><p>Katharina Kann, Ophélie Lacroix, Anders Søgaard</p><p>8066-8073</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6317/6317-13-9542-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08074-infusing-knowledge-into-the-textual-entailment-task-using-graph-convolutional-networks/">Infusing Knowledge into the Textual Entailment Task Using Graph Convolutional Networks</a></h5><span class="papers-author-page"><p>Pavan Kapanipathi, Veronika Thost, Siva Sankalp Patel, Spencer Whitehead, Ibrahim Abdelaziz, Avinash Balakrishnan, Maria Chang, Kshitij Fadnis, Chulaka Gunasekara, Bassem Makni, Nicholas Mattei, Kartik Talamadupula, Achille Fokoue</p><p>8074-8081</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6318/6318-13-9543-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08082-qasc-a-dataset-for-question-answering-via-sentence-composition/">QASC: A Dataset for Question Answering via Sentence Composition</a></h5><span class="papers-author-page"><p>Tushar Khot, Peter Clark, Michal Guerquin, Peter Jansen, Ashish Sabharwal</p><p>8082-8090</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6319/6319-13-9544-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08091-modality-balanced-models-for-visual-dialogue/">Modality-Balanced Models for Visual Dialogue</a></h5><span class="papers-author-page"><p>Hyounghun Kim, Hao Tan, Mohit Bansal</p><p>8091-8098</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6320/6320-13-9545-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08099-top-down-rst-parsing-utilizing-granularity-levels-in-documents/">Top-Down RST Parsing Utilizing Granularity Levels in Documents</a></h5><span class="papers-author-page"><p>Naoki Kobayashi, Tsutomu Hirao, Hidetaka Kamigaito, Manabu Okumura, Masaaki Nagata</p><p>8099-8106</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6321/6321-13-9546-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08107-ma-dst-multi-attention-based-scalable-dialog-state-tracking/">MA-DST: Multi-Attention-Based Scalable Dialog State Tracking</a></h5><span class="papers-author-page"><p>Adarsh Kumar, Peter Ku, Anuj Goyal, Angeliki Metallinou, Dilek Hakkani-Tur</p><p>8107-8114</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6322/6322-13-9547-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08115-deep-attentive-ranking-networks-for-learning-to-order-sentences/">Deep Attentive Ranking Networks for Learning to Order Sentences</a></h5><span class="papers-author-page"><p>Pawan Kumar, Dhanajit Brahma, Harish Karnick, Piyush Rai</p><p>8115-8122</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6323/6323-13-9548-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08123-csi-a-coarse-sense-inventory-for-85-word-sense-disambiguation/">CSI: A Coarse Sense Inventory for 85% Word Sense Disambiguation</a></h5><span class="papers-author-page"><p>Caterina Lacerra, Michele Bevilacqua, Tommaso Pasini, Roberto Navigli</p><p>8123-8130</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6324/6324-13-9549-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08131-a-general-framework-for-implicit-and-explicit-debiasing-of-distributional-word-vector-spaces/">A General Framework for Implicit and Explicit Debiasing of Distributional Word Vector Spaces</a></h5><span class="papers-author-page"><p>Anne Lauscher, Goran Glavaš, Simone Paolo Ponzetto, Ivan Vulić</p><p>8131-8138</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6325/6325-13-9550-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08139-multi-task-learning-for-metaphor-detection-with-graph-convolutional-neural-networks-and-word-sense-disambiguation/">Multi-Task Learning for Metaphor Detection with Graph Convolutional Neural Networks and Word Sense Disambiguation</a></h5><span class="papers-author-page"><p>Duong Le, My Thai, Thien Nguyen</p><p>8139-8146</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6326/6326-13-9551-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/08147-segment-then-rank-non-factoid-question-answering-on-instructional-videos/">Segment-Then-Rank: Non-Factoid Question Answering on Instructional Videos</a></h5><span class="papers-author-page"><p>Kyungjae Lee, Nan Duan, Lei Ji, Jason Li, Seung-won Hwang</p><p>8147-8154</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6327/6327-13-9552-1-10-20200517.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07830-multi-source-domain-adaptation-for-text-classification-via-distancenet-bandits/">Multi-Source Domain Adaptation for Text Classification via DistanceNet-Bandits</a></h5><span class="papers-author-page"><p>Han Guo, Ramakanth Pasunuru, Mohit Bansal</p><p>7830-7838</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6288/6288-13-9513-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07839-fine-tuning-by-curriculum-learning-for-non-autoregressive-neural-machine-translation/">Fine-Tuning by Curriculum Learning for Non-Autoregressive Neural Machine Translation</a></h5><span class="papers-author-page"><p>Junliang Guo, Xu Tan, Linli Xu, Tao Qin, Enhong Chen, Tie-Yan Liu</p><p>7839-7846</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6289/6289-13-9514-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07847-multi-scale-self-attention-for-text-classification/">Multi-Scale Self-Attention for Text Classification</a></h5><span class="papers-author-page"><p>Qipeng Guo, Xipeng Qiu, Pengfei Liu, Xiangyang Xue, Zheng Zhang</p><p>7847-7854</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6290/6290-13-9515-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07855-fact-aware-sentence-split-and-rephrase-with-permutation-invariant-training/">Fact-Aware Sentence Split and Rephrase with Permutation Invariant Training</a></h5><span class="papers-author-page"><p>Yinuo Guo, Tao Ge, Furu Wei</p><p>7855-7862</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6291/6291-13-9516-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07863-p-sif-document-embeddings-using-partition-averaging/">P-SIF: Document Embeddings Using Partition Averaging</a></h5><span class="papers-author-page"><p>Vivek Gupta, Ankit Saw, Pegah Nokhiz, Praneeth Netrapalli, Piyush Rai, Partha Talukdar</p><p>7863-7870</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6292/6292-13-9517-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07871-case-context-aware-semantic-expansion/">CASE: Context-Aware Semantic Expansion</a></h5><span class="papers-author-page"><p>Jialong Han, Aixin Sun, Haisong Zhang, Chenliang Li, Shuming Shi</p><p>7871-7878</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6293/6293-13-9518-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07879-manymodalqa-modality-disambiguation-and-qa-over-diverse-inputs/">ManyModalQA: Modality Disambiguation and QA over Diverse Inputs</a></h5><span class="papers-author-page"><p>Darryl Hannan, Akshay Jain, Mohit Bansal</p><p>7879-7886</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6294/6294-13-9519-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07887-what-do-you-mean-why-resolving-sluices-in-conversations/">What Do You Mean ‘Why?’: Resolving Sluices in Conversations</a></h5><span class="papers-author-page"><p>Victor Petrén Bach Hansen, Anders Søgaard</p><p>7887-7894</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6295/6295-13-9520-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07895-one-homonym-per-translation/">One Homonym per Translation</a></h5><span class="papers-author-page"><p>Bradley Hauer, Grzegorz Kondrak</p><p>7895-7902</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6296/6296-13-9521-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07903-interactive-fiction-games-a-colossal-adventure/">Interactive Fiction Games: A Colossal Adventure</a></h5><span class="papers-author-page"><p>Matthew Hausknecht, Prithviraj Ammanabrolu, Marc-Alexandre Côté, Xingdi Yuan</p><p>7903-7910</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6297/6297-13-9522-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07911-latent-relation-language-models/">Latent Relation Language Models</a></h5><span class="papers-author-page"><p>Hiroaki Hayashi, Zecong Hu, Chenyan Xiong, Graham Neubig</p><p>7911-7918</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6298/6298-13-9523-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07919-knowledge-graph-augmented-word-representations-for-named-entity-recognition/">Knowledge-Graph Augmented Word Representations for Named Entity Recognition</a></h5><span class="papers-author-page"><p>Qizhen He, Liang Wu, Yida Yin, Heming Cai</p><p>7919-7926</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6299/6299-13-9524-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07927-improving-neural-relation-extraction-with-positive-and-unlabeled-learning/">Improving Neural Relation Extraction with Positive and Unlabeled Learning</a></h5><span class="papers-author-page"><p>Zhengqiu He, Wenliang Chen, Yuyi Wang, Wei Zhang, Guanchun Wang, Min Zhang</p><p>7927-7934</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6300/6300-13-9525-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07935-emu-enhancing-multilingual-sentence-embeddings-with-semantic-specialization/">Emu: Enhancing Multilingual Sentence Embeddings with Semantic Specialization</a></h5><span class="papers-author-page"><p>Wataru Hirota, Yoshihiko Suhara, Behzad Golshan, Wang-Chiew Tan</p><p>7935-7943</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6301/6301-13-9526-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07944-unsupervised-interlingual-semantic-representations-from-sentence-embeddings-for-zero-shot-cross-lingual-transfer/">Unsupervised Interlingual Semantic Representations from Sentence Embeddings for Zero-Shot Cross-Lingual Transfer</a></h5><span class="papers-author-page"><p>Channy Hong, Jaeyeon Lee, Jungkwon Lee</p><p>7944-7951</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6302/6302-13-9527-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07952-knowledge-enriched-visual-storytelling/">Knowledge-Enriched Visual Storytelling</a></h5><span class="papers-author-page"><p>Chao-Chun Hsu, Zi-Yuan Chen, Chi-Yang Hsu, Chih-Chia Li, Tzu-Yuan Lin, Ting-Hao Huang, Lun-Wei Ku</p><p>7952-7960</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6303/6303-13-9528-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07961-leveraging-multi-token-entities-in-document-level-named-entity-recognition/">Leveraging Multi-Token Entities in Document-Level Named Entity Recognition</a></h5><span class="papers-author-page"><p>Anwen Hu, Zhicheng Dou, Jian-Yun Nie, Ji-Rong Wen</p><p>7961-7968</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6304/6304-13-9529-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07969-what-makes-a-good-story-designing-composite-rewards-for-visual-storytelling/">What Makes A Good Story? Designing Composite Rewards for Visual Storytelling</a></h5><span class="papers-author-page"><p>Junjie Hu, Yu Cheng, Zhe Gan, Jingjing Liu, Jianfeng Gao, Graham Neubig</p><p>7969-7976</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6305/6305-13-9530-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07977-mala-cross-domain-dialogue-generation-with-action-learning/">MALA: Cross-Domain Dialogue Generation with Action Learning</a></h5><span class="papers-author-page"><p>Xinting Huang, Jianzhong Qi, Yu Sun, Rui Zhang</p><p>7977-7984</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6306/6306-13-9531-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07985-privacy-enhanced-multimodal-neural-representations-for-emotion-recognition/">Privacy Enhanced Multimodal Neural Representations for Emotion Recognition</a></h5><span class="papers-author-page"><p>Mimansa Jaiswal, Emily Mower Provost</p><p>7985-7993</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6307/6307-13-9532-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07667-asymmetrical-hierarchical-networks-with-attentive-interactions-for-interpretable-review-based-recommendation/">Asymmetrical Hierarchical Networks with Attentive Interactions for Interpretable Review-Based Recommendation</a></h5><span class="papers-author-page"><p>Xin Dong, Jingchao Ni, Wei Cheng, Zhengzhang Chen, Bo Zong, Dongjin Song, Yanchi Liu, Haifeng Chen, Gerard de Melo</p><p>7667-7674</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6268/6268-13-9493-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07675-detecting-asks-in-social-engineering-attacks-impact-of-linguistic-and-structural-knowledge/">Detecting Asks in Social Engineering Attacks: Impact of Linguistic and Structural Knowledge</a></h5><span class="papers-author-page"><p>Bonnie Dorr, Archna Bhatia, Adam Dalton, Brodie Mather, Bryanna Hebenstreit, Sashank Santhanam, Zhuo Cheng, Samira Shaikh, Alan Zemel, Tomek Strzalkowski</p><p>7675-7682</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6269/6269-13-9494-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07683-corpus-wide-argument-mining-a-working-solution/">Corpus Wide Argument Mining—A Working Solution</a></h5><span class="papers-author-page"><p>Liat Ein-Dor, Eyal Shnarch, Lena Dankin, Alon Halfon, Benjamin Sznajder, Ariel Gera, Carlos Alzate, Martin Gleize, Leshem Choshen, Yufang Hou, Yonatan Bilu, Ranit Aharonov, Noam Slonim</p><p>7683-7691</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6270/6270-13-9495-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07692-latent-emotion-memory-for-multi-label-emotion-classification/">Latent Emotion Memory for Multi-Label Emotion Classification</a></h5><span class="papers-author-page"><p>Hao Fei, Yue Zhang, Yafeng Ren, Donghong Ji</p><p>7692-7699</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6271/6271-13-9496-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07700-translucent-answer-predictions-in-multi-hop-reading-comprehension/">Translucent Answer Predictions in Multi-Hop Reading Comprehension</a></h5><span class="papers-author-page"><p>G P Shrivatsa Bhargav, Michael Glass, Dinesh Garg, Shirish Shevade, Saswati Dana, Dinesh Khandelwal, L Venkata Subramaniam, Alfio Gliozzo</p><p>7700-7707</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6272/6272-13-9497-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07708-posterior-gan-towards-informative-and-coherent-response-generation-with-posterior-generative-adversarial-network/">Posterior-GAN: Towards Informative and Coherent Response Generation with Posterior Generative Adversarial Network</a></h5><span class="papers-author-page"><p>Shaoxiong Feng, Hongshen Chen, Kan Li, Dawei Yin</p><p>7708-7715</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6273/6273-13-9498-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07716-learning-to-select-bi-aspect-information-for-document-scale-text-content-manipulation/">Learning to Select Bi-Aspect Information for Document-Scale Text Content Manipulation</a></h5><span class="papers-author-page"><p>Xiaocheng Feng, Yawei Sun, Bing Qin, Heng Gong, Yibo Sun, Wei Bi, XiaoJiang Liu, Ting Liu</p><p>7716-7723</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6274/6274-13-9499-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07724-discontinuous-constituent-parsing-with-pointer-networks/">Discontinuous Constituent Parsing with Pointer Networks</a></h5><span class="papers-author-page"><p>Daniel Fernández-González, Carlos Gómez-Rodríguez</p><p>7724-7731</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6275/6275-13-9500-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07732-rethinking-generalization-of-neural-models-a-named-entity-recognition-case-study/">Rethinking Generalization of Neural Models: A Named Entity Recognition Case Study</a></h5><span class="papers-author-page"><p>Jinlan Fu, Pengfei Liu, Qi Zhang</p><p>7732-7739</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6276/6276-13-9501-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07740-document-summarization-with-vhtm-variational-hierarchical-topic-aware-mechanism/">Document Summarization with VHTM: Variational Hierarchical Topic-Aware Mechanism</a></h5><span class="papers-author-page"><p>Xiyan Fu, Jun Wang, Jinghan Zhang, Jinmao Wei, Zhenglu Yang</p><p>7740-7747</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6277/6277-13-9502-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07748-open-domain-event-text-generation/">Open Domain Event Text Generation</a></h5><span class="papers-author-page"><p>Zihao Fu, Lidong Bing, Wai Lam</p><p>7748-7755</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6278/6278-13-9503-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07756-absent-cross-lingual-sentence-representation-mapping-with-bidirectional-gans/">ABSent: Cross-Lingual Sentence Representation Mapping with Bidirectional GANs</a></h5><span class="papers-author-page"><p>Zuohui Fu, Yikun Xian, Shijie Geng, Yingqiang Ge, Yuting Wang, Xin Dong, Guang Wang, Gerard de Melo</p><p>7756-7763</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6279/6279-13-9504-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07764-likelihood-ratios-and-generative-classifiers-for-unsupervised-out-of-domain-detection-in-task-oriented-dialog/">Likelihood Ratios and Generative Classifiers for Unsupervised Out-of-Domain Detection in Task Oriented Dialog</a></h5><span class="papers-author-page"><p>Varun Gangal, Abhinav Arora, Arash Einolghozati, Sonal Gupta</p><p>7764-7771</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6280/6280-13-9505-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07772-neural-snowball-for-few-shot-relation-learning/">Neural Snowball for Few-Shot Relation Learning</a></h5><span class="papers-author-page"><p>Tianyu Gao, Xu Han, Ruobing Xie, Zhiyuan Liu, Fen Lin, Leyu Lin, Maosong Sun</p><p>7772-7779</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6281/6281-13-9506-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07780-tanda-transfer-and-adapt-pre-trained-transformer-models-for-answer-sentence-selection/">TANDA: Transfer and Adapt Pre-Trained Transformer Models for Answer Sentence Selection</a></h5><span class="papers-author-page"><p>Siddhant Garg, Thuy Vu, Alessandro Moschitti</p><p>7780-7788</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6282/6282-13-9507-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07789-predictive-engagement-an-efficient-metric-for-automatic-evaluation-of-open-domain-dialogue-systems/">Predictive Engagement: An Efficient Metric for Automatic Evaluation of Open-Domain Dialogue Systems</a></h5><span class="papers-author-page"><p>Sarik Ghazarian, Ralph Weischedel, Aram Galstyan, Nanyun Peng</p><p>7789-7796</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6283/6283-13-9508-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07797-two-level-transformer-and-auxiliary-coherence-modeling-for-improved-text-segmentation/">Two-Level Transformer and Auxiliary Coherence Modeling for Improved Text Segmentation</a></h5><span class="papers-author-page"><p>Goran Glavaš, Swapna Somasundaran</p><p>7797-7804</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6284/6284-13-9509-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07805-a-large-scale-dataset-for-argument-quality-ranking-construction-and-analysis/">A Large-Scale Dataset for Argument Quality Ranking: Construction and Analysis</a></h5><span class="papers-author-page"><p>Shai Gretz, Roni Friedman, Edo Cohen-Karlik, Assaf Toledo, Dan Lahav, Ranit Aharonov, Noam Slonim</p><p>7805-7813</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6285/6285-13-9510-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07814-two-birds-with-one-stone-investigating-invertible-neural-networks-for-inverse-problems-in-morphology/">Two Birds with One Stone: Investigating Invertible Neural Networks for Inverse Problems in Morphology</a></h5><span class="papers-author-page"><p>Gözde Gül Şahin, Iryna Gurevych</p><p>7814-7821</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6286/6286-13-9511-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07822-working-memory-driven-neural-networks-with-a-novel-knowledge-enhancement-paradigm-for-implicit-discourse-relation-recognition/">Working Memory-Driven Neural Networks with a Novel Knowledge Enhancement Paradigm for Implicit Discourse Relation Recognition</a></h5><span class="papers-author-page"><p>Fengyu Guo, Ruifang He, Jianwu Dang, Jian Wang</p><p>7822-7829</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6287/6287-13-9512-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07504-dmrm-a-dual-channel-multi-hop-reasoning-model-for-visual-dialog/">DMRM: A Dual-Channel Multi-Hop Reasoning Model for Visual Dialog</a></h5><span class="papers-author-page"><p>Feilong Chen, Fandong Meng, Jiaming Xu, Peng Li, Bo Xu, Jie Zhou</p><p>7504-7511</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6248/6248-13-9473-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07512-sequence-generation-with-optimal-transport-enhanced-reinforcement-learning/">Sequence Generation with Optimal-Transport-Enhanced Reinforcement Learning</a></h5><span class="papers-author-page"><p>Liqun Chen, Ke Bai, Chenyang Tao, Yizhe Zhang, Guoyin Wang, Wenlin Wang, Ricardo Henao, Lawrence Carin</p><p>7512-7520</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6249/6249-13-9474-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07521-schema-guided-multi-domain-dialogue-state-tracking-with-graph-attention-neural-networks/">Schema-Guided Multi-Domain Dialogue State Tracking with Graph Attention Neural Networks</a></h5><span class="papers-author-page"><p>Lu Chen, Boer Lv, Chi Wang, Su Zhu, Bowen Tan, Kai Yu</p><p>7521-7528</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6250/6250-13-9475-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07529-improving-entity-linking-by-modeling-latent-entity-type-information/">Improving Entity Linking by Modeling Latent Entity Type Information</a></h5><span class="papers-author-page"><p>Shuang Chen, Jinpeng Wang, Feng Jiang, Chin-Yew Lin</p><p>7529-7537</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6251/6251-13-9476-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07538-tempest-soft-template-based-personalized-edm-subject-generation-through-collaborative-summarization/">TemPEST: Soft Template-Based Personalized EDM Subject Generation through Collaborative Summarization</a></h5><span class="papers-author-page"><p>Yu-Hsiu Chen, Pin-Yu Chen, Hong-Han Shuai, Wen-Chih Peng</p><p>7538-7545</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6252/6252-13-9477-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07546-learning-to-map-frequent-phrases-to-sub-structures-of-meaning-representation-for-neural-semantic-parsing/">Learning to Map Frequent Phrases to Sub-Structures of Meaning Representation for Neural Semantic Parsing</a></h5><span class="papers-author-page"><p>Bo Chen, Xianpei Han, Ben He, Le Sun</p><p>7546-7553</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6253/6253-13-9478-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07554-attending-to-entities-for-better-text-understanding/">Attending to Entities for Better Text Understanding</a></h5><span class="papers-author-page"><p>Pengxiang Cheng, Katrin Erk</p><p>7554-7561</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6254/6254-13-9479-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07562-dynamic-embedding-on-textual-networks-via-a-gaussian-process/">Dynamic Embedding on Textual Networks via a Gaussian Process</a></h5><span class="papers-author-page"><p>Pengyu Cheng, Yitong Li, Xinyuan Zhang, Liqun Chen, David Carlson, Lawrence Carin</p><p>7562-7569</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6255/6255-13-9480-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07570-cross-lingual-natural-language-generation-via-pre-training/">Cross-Lingual Natural Language Generation via Pre-Training</a></h5><span class="papers-author-page"><p>Zewen Chi, Li Dong, Furu Wei, Wenhui Wang, Xian-Ling Mao, Heyan Huang</p><p>7570-7577</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6256/6256-13-9481-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07578-an-empirical-study-of-content-understanding-in-conversational-question-answering/">An Empirical Study of Content Understanding in Conversational Question Answering</a></h5><span class="papers-author-page"><p>Ting-Rui Chiang, Hao-Tong Ye, Yun-Nung Chen</p><p>7578-7585</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6257/6257-13-9482-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07586-how-to-ask-better-questions-a-large-scale-multi-domain-dataset-for-rewriting-ill-formed-questions/">How to Ask Better Questions? A Large-Scale Multi-Domain Dataset for Rewriting Ill-Formed Questions</a></h5><span class="papers-author-page"><p>Zewei Chu, Mingda Chen, Jing Chen, Miaosen Wang, Kevin Gimpel, Manaal Faruqui, Xiance Si</p><p>7586-7593</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6258/6258-13-9483-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07594-guiding-attention-in-sequence-to-sequence-models-for-dialogue-act-prediction/">Guiding Attention in Sequence-to-Sequence Models for Dialogue Act Prediction</a></h5><span class="papers-author-page"><p>Pierre Colombo, Emile Chapuis, Matteo Manica, Emmanuel Vignon, Giovanna Varni, Chloe Clavel</p><p>7594-7601</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6259/6259-13-9484-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07602-discriminative-sentence-modeling-for-story-ending-prediction/">Discriminative Sentence Modeling for Story Ending Prediction</a></h5><span class="papers-author-page"><p>Yiming Cui, Wanxiang Che, Wei-Nan Zhang, Ting Liu, Shijin Wang, Guoping Hu</p><p>7602-7609</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6260/6260-13-9485-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07610-multiple-positional-self-attention-network-for-text-classification/">Multiple Positional Self-Attention Network for Text Classification</a></h5><span class="papers-author-page"><p>Biyun Dai, Jinlong Li, Ruoyi Xu</p><p>7610-7617</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6261/6261-13-9486-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07618-adversarial-training-based-multi-source-unsupervised-domain-adaptation-for-sentiment-analysis/">Adversarial Training Based Multi-Source Unsupervised Domain Adaptation for Sentiment Analysis</a></h5><span class="papers-author-page"><p>Yong Dai, Jian Liu, Xiancong Ren, Zenglin Xu</p><p>7618-7625</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6262/6262-13-9487-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07626-hypernym-detection-using-strict-partial-order-networks/">Hypernym Detection Using Strict Partial Order Networks</a></h5><span class="papers-author-page"><p>Sarthak Dash, Md Faisal Mahbub Chowdhury, Alfio Gliozzo, Nandana Mihindukulasooriya, Nicolas Rodolfo Fauceglia</p><p>7626-7633</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6263/6263-13-9488-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07634-just-add-functions-a-neural-symbolic-language-model/">Just Add Functions: A Neural-Symbolic Language Model</a></h5><span class="papers-author-page"><p>David Demeter, Doug Downey</p><p>7634-7642</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6264/6264-13-9489-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07643-an-iterative-polishing-framework-based-on-quality-aware-masked-language-model-for-chinese-poetry-generation/">An Iterative Polishing Framework Based on Quality Aware Masked Language Model for Chinese Poetry Generation</a></h5><span class="papers-author-page"><p>Liming Deng, Jie Wang, Hangming Liang, Hui Chen, Zhiqiang Xie, Bojin Zhuang, Shaojun Wang, Jing Xiao</p><p>7643-7650</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6265/6265-13-9490-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07651-joint-learning-of-answer-selection-and-answer-summary-generation-in-community-question-answering/">Joint Learning of Answer Selection and Answer Summary Generation in Community Question Answering</a></h5><span class="papers-author-page"><p>Yang Deng, Wai Lam, Yuexiang Xie, Daoyuan Chen, Yaliang Li, Min Yang, Ying Shen</p><p>7651-7658</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6266/6266-13-9491-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07659-on-measuring-and-mitigating-biased-inferences-of-word-embeddings/">On Measuring and Mitigating Biased Inferences of Word Embeddings</a></h5><span class="papers-author-page"><p>Sunipa Dev, Tao Li, Jeff M. Phillips, Vivek Srikumar</p><p>7659-7666</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6267/6267-13-9492-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07342-ledeepchef-deep-reinforcement-learning-agent-for-families-of-text-based-games/">LeDeepChef Deep Reinforcement Learning Agent for Families of Text-Based Games</a></h5><span class="papers-author-page"><p>Leonard Adolphs, Thomas Hofmann</p><p>7342-7349</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6228/6228-13-9453-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07350-knowledge-distillation-from-internal-representations/">Knowledge Distillation from Internal Representations</a></h5><span class="papers-author-page"><p>Gustavo Aguilar, Yuan Ling, Yu Zhang, Benjamin Yao, Xing Fan, Chenlei Guo</p><p>7350-7357</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6229/6229-13-9454-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07358-modelling-sentence-pairs-via-reinforcement-learning-an-actor-critic-approach-to-learn-the-irrelevant-words/">Modelling Sentence Pairs via Reinforcement Learning: An Actor-Critic Approach to Learn the Irrelevant Words</a></h5><span class="papers-author-page"><p>Mahtab Ahmed, Robert E. Mercer</p><p>7358-7366</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6230/6230-13-9455-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07367-end-to-end-argumentation-knowledge-graph-construction/">End-to-End Argumentation Knowledge Graph Construction</a></h5><span class="papers-author-page"><p>Khalid Al-Khatib, Yufang Hou, Henning Wachsmuth, Charles Jochim, Francesca Bonin, Benno Stein</p><p>7367-7374</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6231/6231-13-9456-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07375-story-realization-expanding-plot-events-into-sentences/">Story Realization: Expanding Plot Events into Sentences</a></h5><span class="papers-author-page"><p>Prithviraj Ammanabrolu, Ethan Tien, Wesley Cheung, Zhaochen Luo, William Ma, Lara J. Martin, Mark O. Riedl</p><p>7375-7382</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6232/6232-13-9457-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07383-do-not-have-enough-data-deep-learning-to-the-rescue/">Do Not Have Enough Data? Deep Learning to the Rescue!</a></h5><span class="papers-author-page"><p>Ateret Anaby-Tavor, Boaz Carmeli, Esther Goldbraich, Amir Kantor, George Kour, Segev Shlomov, Naama Tepper, Naama Zwerdling</p><p>7383-7390</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6233/6233-13-9458-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07391-fine-grained-named-entity-typing-over-distantly-supervised-data-based-on-refined-representations/">Fine-Grained Named Entity Typing over Distantly Supervised Data Based on Refined Representations</a></h5><span class="papers-author-page"><p>Muhammad Asif Ali, Yifang Sun, Bing Li, Wei Wang</p><p>7391-7398</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6234/6234-13-9459-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07399-understanding-the-semantic-content-of-sparse-word-embeddings-using-a-commonsense-knowledge-base/">Understanding the Semantic Content of Sparse Word Embeddings Using a Commonsense Knowledge Base</a></h5><span class="papers-author-page"><p>Vanda Balogh, Gábor Berend, Dimitrios I. Diochnos, György Turán</p><p>7399-7406</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6235/6235-13-9460-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07407-simultaneously-linking-entities-and-extracting-relations-from-biomedical-text-without-mention-level-supervision/">Simultaneously Linking Entities and Extracting Relations from Biomedical Text without Mention-Level Supervision</a></h5><span class="papers-author-page"><p>Trapit Bansal, Pat Verga, Neha Choudhary, Andrew McCallum</p><p>7407-7414</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6236/6236-13-9461-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07415-zero-resource-cross-lingual-named-entity-recognition/">Zero-Resource Cross-Lingual Named Entity Recognition</a></h5><span class="papers-author-page"><p>M Saiful Bari, Shafiq Joty, Prathyusha Jwalapuram</p><p>7415-7423</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6237/6237-13-9462-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07424-generating-well-formed-answers-by-machine-reading-with-stochastic-selector-networks/">Generating Well-Formed Answers by Machine Reading with Stochastic Selector Networks</a></h5><span class="papers-author-page"><p>Bin Bi, Chen Wu, Ming Yan, Wei Wang, Jiangnan Xia, Chenliang Li</p><p>7424-7431</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6238/6238-13-9463-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07432-piqa-reasoning-about-physical-commonsense-in-natural-language/">PIQA: Reasoning about Physical Commonsense in Natural Language</a></h5><span class="papers-author-page"><p>Yonatan Bisk, Rowan Zellers, Ronan Le bras, Jianfeng Gao, Yejin Choi</p><p>7432-7439</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6239/6239-13-9464-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07440-back-to-the-future-temporal-adaptation-of-text-representations/">Back to the Future – Temporal Adaptation of Text Representations</a></h5><span class="papers-author-page"><p>Johannes Bjerva, Wouter Kouw, Isabelle Augenstein</p><p>7440-7447</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6240/6240-13-9465-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07448-modelling-semantic-categories-using-conceptual-neighborhood/">Modelling Semantic Categories Using Conceptual Neighborhood</a></h5><span class="papers-author-page"><p>Zied Bouraoui, Jose Camacho-Collados, Luis Espinosa-Anke, Steven Schockaert</p><p>7448-7455</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6241/6241-13-9466-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07456-inducing-relational-knowledge-from-bert/">Inducing Relational Knowledge from BERT</a></h5><span class="papers-author-page"><p>Zied Bouraoui, Jose Camacho-Collados, Steven Schockaert</p><p>7456-7463</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6242/6242-13-9467-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07464-graph-transformer-for-graph-to-sequence-learning/">Graph Transformer for Graph-to-Sequence Learning</a></h5><span class="papers-author-page"><p>Deng Cai, Wai Lam</p><p>7464-7471</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6243/6243-13-9468-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07472-learning-from-easy-to-complex-adaptive-multi-curricula-learning-for-neural-dialogue-generation/">Learning from Easy to Complex: Adaptive Multi-Curricula Learning for Neural Dialogue Generation</a></h5><span class="papers-author-page"><p>Hengyi Cai, Hongshen Chen, Cheng Zhang, Yonghao Song, Xiaofang Zhao, Yangxi Li, Dongsheng Duan, Dawei Yin</p><p>7472-7479</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6244/6244-13-9469-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07480-unsupervised-domain-adaptation-on-reading-comprehension/">Unsupervised Domain Adaptation on Reading Comprehension</a></h5><span class="papers-author-page"><p>Yu Cao, Meng Fang, Baosheng Yu, Joey Tianyi Zhou</p><p>7480-7487</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6245/6245-13-9470-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07488-zero-shot-text-to-sql-learning-with-auxiliary-task/">Zero-Shot Text-to-SQL Learning with Auxiliary Task</a></h5><span class="papers-author-page"><p>Shuaichen Chang, Pengfei Liu, Yun Tang, Jing Huang, Xiaodong He, Bowen Zhou</p><p>7488-7495</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6246/6246-13-9471-1-10-20200516.pdf">PDF</a></li><li class="paper-wrap"><h5><a href="https://aaai.org/papers/07496-hyperbolic-interaction-model-for-hierarchical-multi-label-classification/">Hyperbolic Interaction Model for Hierarchical Multi-Label Classification</a></h5><span class="papers-author-page"><p>Boli Chen, Xin Huang, Lin Xiao, Zixin Cai, Liping Jing</p><p>7496-7503</p></span><a class="wp-block-button" target="_blank" href="https://cdn.aaai.org/ojs/6247/6247-13-9472-1-10-20200516.pdf">PDF</a></li></ul></div></main><aside class="sidebar sidebar-primary widget-area" role="complementary" aria-label="Primary Sidebar" id="genesis-sidebar-primary"><h2 class="genesis-sidebar-title screen-reader-text">Primary Sidebar</h2></aside></div></div><footer class="site-footer"><div class="wrap"></div></footer><div class="proceedings-wrap"></div><!--googleoff: all-->
<script>
$(document).ready(function(){
	$('#close-icon').click(function(e) {
		e.preventDefault();
		$(".ubermenu-wrap").animate({width:'toggle'},350);
		$(this).toggleClass("dashicons-no-alt");
		$(this).toggleClass("dashicons-menu-alt3");
	});
	var currentUrl = window.location.href;
    if (currentUrl != 'https://aaai.org/') {
		if ($(window).width() > 959) {
        	$('.ubermenu-wrap').hide();
		}
    }
	$(window).resize(function() {
		if ($(window).width() > 959) {
			$('.ubermenu-wrap').hide();
		} else {
			$('.ubermenu-wrap').show();
		}
	});
});
</script>

	<script type="text/javascript">
		function genesisBlocksShare( url, title, w, h ){
			var left = ( window.innerWidth / 2 )-( w / 2 );
			var top  = ( window.innerHeight / 2 )-( h / 2 );
			return window.open(url, title, 'toolbar=no, location=no, directories=no, status=no, menubar=no, scrollbars=no, resizable=no, copyhistory=no, width=600, height=600, top='+top+', left='+left);
		}
	</script>
	<style type="text/css" media="screen"></style><script id="essential-blocks-blocks-localize-js-extra">
var eb_conditional_localize = [];
var EssentialBlocksLocalize = {"eb_plugins_url":"https:\/\/aaai.org\/wp-content\/plugins\/essential-blocks\/","image_url":"https:\/\/aaai.org\/wp-content\/plugins\/essential-blocks\/assets\/images","eb_wp_version":"6.7","eb_version":"5.0.0","eb_admin_url":"https:\/\/aaai.org\/wp-admin\/","rest_rootURL":"https:\/\/aaai.org\/wp-json\/","ajax_url":"https:\/\/aaai.org\/wp-admin\/admin-ajax.php","nft_nonce":"26f33cbdd3","post_grid_pagination_nonce":"91a475d4f0","placeholder_image":"https:\/\/aaai.org\/wp-content\/plugins\/essential-blocks\/assets\/images\/placeholder.png","is_pro_active":"false","upgrade_pro_url":"https:\/\/essential-blocks.com\/upgrade","responsiveBreakpoints":{"tablet":1024,"mobile":767}};
</script>
<script src="https://aaai.org/wp-content/plugins/essential-blocks/assets/js/eb-blocks-localize.js?ver=31d6cfe0d16ae931b73c" id="essential-blocks-blocks-localize-js"></script>
<script src="https://aaai.org/wp-content/plugins/cookie-law-info-controls/public/js/cookie-law-info-controls-public.js?ver=1.0.0" id="cookie-law-info-controls-js"></script>
<script src="https://aaai.org/wp-content/plugins/genesis-blocks/dist/assets/js/dismiss.js?ver=1738785528" id="genesis-blocks-dismiss-js-js"></script>
<script src="https://aaai.org/wp-includes/js/hoverIntent.min.js?ver=1.10.2" id="hoverIntent-js"></script>
<script src="https://aaai.org/wp-content/themes/genesis/lib/js/menu/superfish.min.js?ver=1.7.10" id="superfish-js"></script>
<script src="https://aaai.org/wp-content/themes/genesis/lib/js/menu/superfish.args.min.js?ver=3.5.0" id="superfish-args-js"></script>
<script src="https://aaai.org/wp-content/themes/genesis/lib/js/skip-links.min.js?ver=3.5.0" id="skip-links-js"></script>
<script id="genesis-sample-responsive-menu-js-extra">
var genesis_responsive_menu = {"mainMenu":"Menu","menuIconClass":"dashicons-before dashicons-menu","subMenu":"Submenu","subMenuIconClass":"dashicons-before dashicons-arrow-down-alt2","menuClasses":{"others":[".nav-primary"]}};
</script>
<script src="https://aaai.org/wp-content/themes/genesis/lib/js/menu/responsive-menus.min.js?ver=1.1.3" id="genesis-sample-responsive-menu-js"></script>
<script id="ubermenu-js-extra">
var ubermenu_data = {"remove_conflicts":"on","reposition_on_load":"off","intent_delay":"300","intent_interval":"100","intent_threshold":"7","scrollto_offset":"50","scrollto_duration":"1000","responsive_breakpoint":"959","accessible":"on","retractor_display_strategy":"responsive","touch_off_close":"on","submenu_indicator_close_mobile":"on","collapse_after_scroll":"on","v":"3.7.8","configurations":["main"],"ajax_url":"https:\/\/aaai.org\/wp-admin\/admin-ajax.php","plugin_url":"https:\/\/aaai.org\/wp-content\/plugins\/ubermenu\/","disable_mobile":"off","prefix_boost":"","use_core_svgs":"off","aria_role_navigation":"off","aria_nav_label":"off","aria_expanded":"off","aria_hidden":"off","aria_controls":"","aria_responsive_toggle":"off","icon_tag":"i","esc_close_mobile":"on","theme_locations":{"primary":"Header Menu","secondary":"Footer Menu"}};
</script>
<script src="https://aaai.org/wp-content/plugins/ubermenu/assets/js/ubermenu.min.js?ver=3.7.8" id="ubermenu-js"></script>
</body></html>
